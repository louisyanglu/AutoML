<div style="page-break-after:always"></div>

------

### 第1章  机器学习基本概念与建模流程

#### 1.1  机器学习基本概念

>   线性回归模型是诞生于是统计学领域的一类模型，同时也是整个线性类模型大类的基础模型。
>
>   使用传统的统计学方法构建线性回归模型其实并不简单，如果要构建一个统计学意义的线性回归模型，则我们至少需要掌握随机变量的基本分布、变量相关性与独立性、方差分析等基本统计学知识，才能够上手构建线性回归模型。
>
>   从机器学习的角度出发，所谓线性回归，指的是自变量（特征）加权求和汇总求得因变量（标签）的过程。

##### 1.1.1  连续变量与离散变量

-   所谓**连续变量**，指的是随机变量能够取得连续数值。
-   而**离散变量**则指的是随机变量只允许取得离散的整数。
    -   对于离散型变量，还可以进一步细分为名义型变量和顺序性变量。所谓**名义变量**，指的是随机变量取得不同离散值时，取值大小本身没有数值意义，只有指代意义。例如，用0/1代表男女。
    -   但所谓**顺序变量**，则有大小方面的数值意义，例如使用0/1/2代表高中/本科/研究生学历。

##### 1.1.2  分类问题与回归问题

-   如果是围绕离散型标签进行建模预测，则称任务为分类预测任务，该模型为解决分类任务的分类（classification）模型。
-   而如果是围绕连续型标签进行建模预测，则称该任务为回归预测任务，该模型为解决回归问题的回归类（regression）模型。

#### 1.2  机器学习建模流程

##### 1.2.1  从简单线性回归出发

简单线性回归$y = wx+b$，用 $x_i$ 表示某条数据第$i$个特征的取值，用 $x^{(j)}$ 表示第 $j$ 条数据，用 $y$ 作为某条数据的标签取值，使用 $\hat y$ 表示某条数据带入模型之后模型输出结果。

1.   模型训练

     模型参数是影响模型输出的关键变量，不同参数组对应不同的输出。**模型训练就是指对模型参数进行有效调整**，找到一组最优参数。

     |    数据特征     | 参数组  | 模型输出 | 数据标签 |
     | :-------------: | :-----: | :------: | :------: |
     | Whole weight(x) | $(w,b)$ | $\hat y$ | Rings(y) |
     |        1        | (1, -1) |    0     |    2     |
     |        3        | (1, -1) |    2     |    4     |
     |        1        | (1, 0)  |    1     |    2     |
     |        3        | (1, 0)  |    3     |    4     |

2.   模型评估指标与损失函数

     >   **简单地说：损失函数带超参、评估指标是超参确定后计算得到的**

     -   **模型评估指标**是评估模型输出结果“好与坏”的标量计算结果，其结果一般由模型**预测值 $\hat y$ 和真实值 $y$** 共同计算得出。
     -   模型的**损失函数**是关于**模型参数**的函数，是带参数的计算方程，而模型评估指标是给定参数后的计算结果。

     两者的区别：

     -   对于很多模型（尤其是分类模型）来说，模型评估指标和模型损失函数的**计算过程并不一致**，例如准确率就很难转化为一个以参数为变量的函数表达式。
     -   模型评估指标和损失函数构建的**目标不同**，模型评估指标的计算目标是给模型性能一个标量计算结果，而损失函数的构建则是为了找到一组最优的参数结果。

3.   参数求解

     **损失函数的核心作用**：搭建参数求解的桥梁，构建一个协助模型求解参数的方程。通过损失函数的构建，我们可以将求解模型最优参数的问题转化为求解损失函数最小值的问题。

     一旦损失函数构建完成，我们就可以去寻找损失函数的最小值，以及求出损失函数取得最小值时函数自变量（也就是模型参数）的取值，此时参数的取值就是原模型中参数的最优取值结果。

     -   **凸优化**

         >   很多机器学习模型所构建的损失函数都是凸函数，因此关于凸函数的优化方法（找到最小值的方法）也就成了机器学习建模过程中最常用的优化方法。
         >
         >   **凸函数的最小值点其实是根据边界点和驻点（导数为0的点）决定**：
         >
         >   1.   如果没有边界点且没有驻点，则函数没有最小值（例如$y=x$）
         >   2.   如果存在边界点，但没有驻点，则边界点的一侧就是最小值点
         >   3.   如果存在驻点（且左右两边单调性相反），则驻点就是最小值点（例如$ y = x^2 $）
         >
         >   ⚠️注意：拐点特指左右两边函数凹凸性发生变化的点。

         首先给出凸函数的一般定义，对于任意一个函数，如果函数$$f(x)$$上存在任意两个点，$x_1, x_2$，且$\frac{f(x_1) + f(x_2)}{2} >= f(\frac{x_1 + x_2}{2}) $   ，

         我们就判定，这个函数是凸函数。

         对于一个凸函数来说，全域最小值明显存在。求解凸函数的最小值有很多种方法，其中最为基础的方法叫做**最小二乘法**。

     -   **最小二乘法**

         >   **简单地说，最小二乘法就是在找到能够令损失函数偏导数取值都为零的一组超参数**

         1.   对于一元函数，如果存在导数为0的点，则该点就是最小值点；
         2.   对于多元函数，如果存在某一点，使得函数的各个自变量的偏导数都为0，则该点就是最小值点。

##### 1.2.2  机器学习建模一般流程

-   Step 1：提出基本模型  

    在**提出模型**时，我们往往会预设好一些影响模型结构或者实际判别性能的参数，如简单线性回归中的$w$和$b$。

-   Step 2：确定损失函数

    围绕建模的目标构建**评估指标**，并且围绕评估指标设置**损失函数**

-   Step 3：根据损失函数性质，选择**优化方法**

    损失函数既承载了我们优化的目标（让预测值和真实值尽可能接近），同时也是包含了模型参数的函数，当我们围绕目标函数求解最小值时，也就完成了模型参数的求解。当然，这个过程本质上就是一个数学的最优化过程，求解目标函数最小值本质上也就是一个最优化问题，而要解决这个问题，我们就需要灵活适用一些最优化方法。

-   Step 4.利用优化算法进行**损失函数求解**

<div style="page-break-after:always"></div>

------

### 第2章  矩阵求导与最小二乘法

#### 2.1  矩阵基础

##### 2.1.1  array与matrix的区别

关于`np.array`和`np.mat`两种对象类型的选取，此处进行简单说明：    

-   NumPy中的matrix类型对象和MATLAB中的matrix类型等价，和NumPy中数组类型对象底层基本结构不同；    
-   在NumPy中，针对大规模数据，**数组**类型对象的**计算速度要快**于矩阵类型对象；
-   矩阵类型对象可以通过运算符直接进行矩阵乘法，而二维数组要进行矩阵乘法（及其他矩阵运算），则必须要使用包括`linalg`（线性代数运算）模块在内的相关函数。

##### 2.1.2  几种特殊矩阵构造

|   **函数**   |         **描述**          |
| :----------: | :-----------------------: |
|    `a.T`     |         数组a转置         |
| `np.eye(n)`  | 创建包含n个分量的单位矩阵 |
| `np.diag(a)` | 以a中各元素，创建对角矩阵 |
| `np.triu(a)` |   取矩阵a中的上三角矩阵   |
| `np.tril(a)` |   取矩阵a中的下三角矩阵   |

##### 2.1.3  矩阵基本运算

包括矩阵乘法、向量内积、矩阵和向量的乘法等；

|                **解释/函数**                |              **描述**              |
| :-----------------------------------------: | :--------------------------------: |
|             `*`(向量、矩阵通用)             |             逐元素相乘             |
| `vdot`、`dot`、`inner`（也被称为点积/内积） |   **向量点积**，逐元素相乘后相加   |
|                   `vdot`                    | **矩阵点积**，等价于`(A*B).sum()`  |
|            `dot`、`matmul`、`@`             | **矩阵乘法**，代数学意义的矩阵相乘 |

##### 2.1.4  矩阵代数运算

包括矩阵的迹、矩阵的秩、逆矩阵的求解、伴随矩阵和广义逆矩阵等；

|          **函数**          |                           **描述**                           |
| :------------------------: | :----------------------------------------------------------: |
|       `np.trace(A)`        |               矩阵的**迹**，矩阵对角线元素之和               |
| `np.linalg.matrix_rank(A)` |          矩阵的**秩**，矩阵中行或列的极大线性无关数          |
|     `np.linalg.det(A)`     | 计算矩阵A的**行列式**，矩阵的一个基本性质或者属性<br> 要求矩阵<font color='blue'>必须是方阵</font> ，通过行列式的计算，能够知道矩阵是否可逆 |
|     `np.linalg.inv(A)`     | 矩阵**求逆**<br> 从<font color='blue'>方程组求解角度</font>来看，逆矩阵的存在就代表着方程组存在唯一解；<br> 从<font color='blue'>矩阵分解角度</font>来看，逆矩阵是一种最为基础的矩阵分解的形式。 |

#### 2.2  矩阵方程与向量求导

##### 2.2.1  矩阵方程求解

要求解$$A \cdot X = B$$：

-   通过`np.linalg.matrix_rank(A)`或`np.linalg.det(A)	`，来判断A是否满秩
-   对于满秩矩阵，我们可以求其逆矩阵`np.linalg.inv(A)`
-   在矩阵方程左右两端同时左乘其逆矩阵，即可解出X的取值：$$X=A^{-1}B$$  $\Rightarrow$  `np.matmul(np.linalg.inv(A), B)`或`np.linalg.inv(A).dot(B)`

更一般地，可使用`np.linalg.solve(A, B)`求解`X`。

##### 2.2.2  向量求导

>   向量求导的核心点在于，依据向量变元中的变量排列顺序，依次填写对应**变量的偏导函数计算结果**。

1.   **向量求导的梯度向量形式**

     设$f(x)$是一个关于$x$的函数，其中$x$是向量变元，并且$$x = [x_1, x_2,...,x_n]^T$$

     则$$\frac{\partial f}{\partial x} = [\frac{\partial f}{\partial x_1}, \frac{\partial f}{\partial x_2}, ...,\frac{\partial f}{\partial x_n}]^T$$

     <font color='blue'>**梯度**</font>：$$\nabla _xf(x) = \frac{\partial f}{\partial x} = [\frac{\partial f}{\partial x_1}, \frac{\partial f}{\partial x_2}, ...,\frac{\partial f}{\partial x_n}]^T$$

2.   **常见向量求导公式**

     |                             公式                             | 备注 |
     | :----------------------------------------------------------: | :--: |
     |             $\frac{\partial a}{\partial x} = 0$              |      |
     | $$\frac{\partial(x^T \cdot A)}{\partial x} = \frac{\partial(A^T \cdot x)}{\partial x} = A$$ |      |
     |      $$\frac{\partial (x^T \cdot x)}{\partial x} = 2x$$      |      |
     |        $$\frac{\partial (x^T A  x)}{x} = Ax + A^Tx$$         |      |

     公式推导：

     -   $$\frac{\partial a}{\partial x} = 0$$

         证明：

         $$\frac{\partial a}{\partial x} = [\frac{\partial a}{\partial x_1}, \frac{\partial a}{\partial x_2}, ...,\frac{\partial a}{\partial x_n}]^T = [0,0,...,0]^T$$

     -   $$\frac{\partial(x^T \cdot A)}{\partial x} = \frac{\partial(A^T \cdot x)}{\partial x} = A$$

         证明：

         $$\begin{aligned}\frac{\partial(x^T \cdot A)}{\partial x} & = \frac{\partial(A^T \cdot x)}{\partial x}\\& = \frac{\partial(a_1 \cdot x_1 + a_2 \cdot x_2 +...+ a_n \cdot x_n)}{\partial x}\\& = \left [\begin{array}{cccc}\frac{\partial(a_1 \cdot x_1 + a_2 \cdot x_2 +...+ a_n \cdot x_n)}{\partial x_1} \\\frac{\partial(a_1 \cdot x_1 + a_2 \cdot x_2 +...+ a_n \cdot x_n)}{\partial x_2} \\. \\. \\. \\\frac{\partial(a_1 \cdot x_1 + a_2 \cdot x_2 +...+ a_n \cdot x_n)}{\partial x_n} \\\end{array}\right] \\& =\left [\begin{array}{cccc}a_1 \\a_2 \\. \\. \\. \\a_n \\\end{array}\right] = A\end{aligned}$$

     -   $$\frac{\partial (x^T \cdot x)}{\partial x} = 2x$$

         证明：

         $$\begin{aligned}\frac{\partial(x^T \cdot x)}{\partial x} & = \frac{\partial(x_1^2+x_2^2+...+x_n^2)}{\partial x}\\& = \left [\begin{array}{cccc}\frac{\partial(x_1^2+x_2^2+...+x_n^2)}{\partial x_1} \\\frac{\partial(x_1^2+x_2^2+...+x_n^2)}{\partial x_2} \\. \\. \\. \\\frac{\partial(x_1^2+x_2^2+...+x_n^2)}{\partial x_n} \\\end{array}\right] \\& =\left [\begin{array}{cccc}2x_1 \\2x_2 \\. \\. \\. \\2x_n \\\end{array}\right] = 2x\end{aligned}$$

     -   $$\frac{\partial (x^T A  x)}{x} = Ax + A^Tx$$

         证明：

         $\begin{aligned}
         X^{T} A X &=\left[x_{1}, x_{2}, \ldots, x_{n}\right] \cdot\left[\begin{array}{cccc}
         a_{11} & a_{12} & \ldots & a_{1 n} \\
         a_{21} & a_{22} & \ldots & a_{2 n} \\
         \ldots & \ldots & \ldots & \ldots \\
         a_{n 1} & a_{n 2} & \ldots & a_{n n}
         \end{array}\right] \cdot\left[x_{1}, x_{2}, \ldots, x_{n}\right]^{T} \\
         &=\left[x_{1} a_{11}+x_{2} a_{21}+\ldots+x_{n} a_{n 1}, x_{1} a_{12}+x_{2} a_{22}+\ldots+x_{n} a_{n 2}, \ldots, x_{1} a_{1 n}+x_{2} a_{2 n}+\ldots+x_{n} a_{n n}\right] \cdot\left[\begin{array}{c}
         x_{1} \\
         x_{2} \\
         \cdot \\
         \cdot \\
         \vdots \\
         x_{n}
         \end{array}\right] \\
         &=x_{1}\left(x_{1} a_{11}+x_{2} a_{21}+\ldots+x_{n} a_{n 1}\right)+x_{2}\left(x_{1} a_{12}+x_{2} a_{22}+\ldots+x_{n} a_{n 2}\right)+\ldots+x_{n}\left(x_{1} a_{1 n}+x_{2} a_{2 n}+\ldots+x_{n} a_{n n}\right)
         \end{aligned}$

         令$k(x) = x_1(x_1a_{11}+x_2a_{21}+...+x_na_{n1})+x_2(x_1a_{12}+x_2a_{22}+...+x_na_{n2})+...+x_n(x_1a_{1n}+x_2a_{2n}+...+x_na_{nn})$

         则有$$\frac{\partial k(x)}{\partial x_1} = (x_1a_{11}+x_2a_{21}+...+x_na_{n1})+ (x_1a_{11} + x_2a_{12}+...+x_na_{1n})$$

         类似可得：

         $\begin{array}{l}
         \frac{\partial k(x)}{\partial x}=\left[\begin{array}{c}
         \frac{\partial k(x)}{\partial x_{1}} \\
         \frac{\partial k(x)}{\partial x_{2}} \\
         \cdot \\
         \cdot \\
         \frac{\partial k(x)}{\partial x_{n}}
         \end{array}\right]\\
         =\left[\begin{array}{c}
         \left(x_{1} a_{11}+x_{2} a_{21}+\ldots+x_{n} a_{n 1}\right)+\left(x_{1} a_{11}+x_{2} a_{12}+\ldots+x_{n} a_{1 n}\right) \\
         \left(x_{1} a_{12}+x_{2} a_{22}+\ldots+x_{n} a_{n 2}\right)+\left(x_{1} a_{21}+x_{2} a_{22}+\ldots+x_{n} a_{2 n}\right) \\
         . \\
         \cdot \\
         \cdot \\
         \left(x_{1} a_{1 n}+x_{2} a_{2 n}+\ldots+x_{n} a_{n n}\right)+\left(x_{1} a_{n 1}+x_{2} a_{n 2}+\ldots+x_{n} a_{n n}\right)
         \end{array}\right]\\
         =\left[\begin{array}{c}
         \left(x_{1} a_{11}+x_{2} a_{21}+\ldots+x_{n} a_{n 1}\right) \\
         \left(x_{1} a_{12}+x_{2} a_{22}+\ldots+x_{n} a_{n 2}\right) \\
         \cdot \\
         \cdot \\
         \cdot \\
         \left(x_{1} a_{1 n}+x_{2} a_{2 n}+\ldots+x_{n} a_{n n}\right)
         \end{array}\right]+\left[\begin{array}{c}
         \left(x_{1} a_{11}+x_{2} a_{12}+\ldots+x_{n} a_{1 n}\right) \\
         \left(x_{1} a_{21}+x_{2} a_{22}+\ldots+x_{n} a_{2 n}\right) \\
         \cdot \\
         \cdot \\
         \cdot \\
         \left(x_{1} a_{n 1}+x_{2} a_{n 2}+\ldots+x_{n} a_{n n}\right)
         \end{array}\right]\\
         =\left[\begin{array}{cccc}
         a_{11} & a_{21} & \ldots & a_{n 1} \\
         a_{12} & a_{22} & \ldots & a_{n 2} \\
         \ldots & \ldots & \ldots & \ldots \\
         a_{1 n} & a_{2 n} & \ldots & a_{n n}
         \end{array}\right]\left[\begin{array}{c}
         x_{1} \\
         x_{2} \\
         \cdot \\
         . \\
         \cdot \\
         x_{n}
         \end{array}\right]+\left[\begin{array}{cccc}
         a_{11} & a_{12} & \ldots & a_{1 n} \\
         a_{21} & a_{22} & \ldots & a_{2 n} \\
         \ldots & \ldots & \ldots & \ldots \\
         a_{n 1} & a_{n 2} & \ldots & a_{n n}
         \end{array}\right]\left[\begin{array}{c}
         x_{1} \\
         x_{2} \\
         \cdot \\
         \cdot \\
         \cdot \\
         x_{n}
         \end{array}\right]\\
         =A^{T} x+A x
         \end{array}$



#### 2.3  最小二乘法的推导过程

##### 2.3.1  方程组改写成矩阵形式

假设多元线性方程有如下形式：$ f(x) = w_1x_1+w_2x_2+...+w_dx_d+b $

令$w = [w_1,w_2,...w_d]^T$，$x = [x_1,x_2,...x_d]^T$，则上式可写为$ f(x) = w^Tx+b $

假设现在总共有$m$条$d$维的观测值，$x^{(i)} = [x_1^{(i)}, x_2^{(i)},...,x_d^{(i)}]$，则带入模型可构成m个方程：

$$\left[\begin{array}{c}
w_{1} x_{1}^{(1)}+w_{2} x_{2}^{(1)}+\ldots+w_{d} x_{d}^{(1)}+b \\
w_{1} x_{1}^{(2)}+w_{2} x_{2}^{(2)}+\ldots+w_{d} x_{d}^{(2)}+b \\
\cdot \\
\cdot \\
w_{1} x_{1}^{(m)}+w_{2} x_{2}^{(m)}+\ldots+w_{d} x_{d}^{(m)}+b
\end{array}\right]=\left[\begin{array}{c}
\hat{y}_{1} \\
\hat{y}_{2} \\
\cdot \\
\cdot \\
\cdot \\
\hat{y}_{m}
\end{array}\right]$$

令$$\hat w = [w_1,w_2,...,w_d,b]^T$$，$$\hat x = [x_1,x_2,...,x_d,1]^T$$

$\hat{X}=\left[\begin{array}{ccccc}
x_{1}^{(1)} & x_{2}^{(1)} & \ldots & x_{d}^{(1)} & 1 \\
x_{1}^{(2)} & x_{2}^{(2)} & \ldots & x_{d}^{(2)} & 1 \\
\ldots & \ldots & \ldots & \ldots & 1 \\
x_{1}^{(m)} & x_{2}^{(m)} & \ldots & x_{d}^{(m)} & 1
\end{array}\right]$

$y=\left[\begin{array}{c}
y_{1} \\
y_{2} \\
\cdot \\
\cdot \\
\cdot \\
y_{m}
\end{array}\right]$

$\hat{y}=\left[\begin{array}{c}
\hat{y}_{1} \\
\hat{y}_{2} \\
\cdot \\
\cdot \\
\cdot \\
\hat{y}_{m}
\end{array}\right]$

其中：

- $\hat w$：方程系数所组成的向量，并且我们将自变量系数和截距放到了一个向量；
- $\hat x$：方程自变量和1共同组成的向量；
- $\hat X$：样本数据特征构成的矩阵，并在最后一列添加一个全为1的列；
- $y$：样本数据标签所构成的列向量;
- $\hat y$：预测值的列向量。

因此，上述方程组可表示为$$\hat X \cdot \hat w = \hat y$$

线性模型也可以按照如下形式进行改写：$$f(\hat x) = \hat w^T \cdot \hat x$$

##### 2.3.2  构造损失函数

$$SSELoss(\hat w) = ||y - \hat X\hat w||_2^2 = (y - \hat X\hat w)^T(y - \hat X\hat w)$$

##### 2.3.3  最小二乘法求解损失函数

$\begin{aligned}
\frac{\partial\operatorname{SSELoss}(\hat{w})}{\partial \hat{\boldsymbol{w}}} &=\frac{\partial\|\boldsymbol{y}-\boldsymbol{X} \hat{\boldsymbol{w}}\|_{2}{ }^{2}}{\partial \hat{\boldsymbol{w}}} \\
&=\frac{\partial(\boldsymbol{y}-\boldsymbol{X} \hat{\boldsymbol{w}})^{T}(\boldsymbol{y}-\boldsymbol{X} \hat{\boldsymbol{w}})}{\partial \hat{\boldsymbol{w}}} \\
&=\frac{\partial\left(\boldsymbol{y}^{T}-\hat{\boldsymbol{w}}^{T} \boldsymbol{X}^{\boldsymbol{T}}\right)(\boldsymbol{y}-\boldsymbol{X} \hat{\boldsymbol{w}})}{\partial \hat{\boldsymbol{w}}} \\
&=\frac{\partial\left(\boldsymbol{y}^{T} \boldsymbol{y}-\hat{\boldsymbol{w}}^{\boldsymbol{T}} \boldsymbol{X}^{T} \boldsymbol{y}-\boldsymbol{y}^{T} \boldsymbol{X} \hat{\boldsymbol{w}}+\hat{\boldsymbol{w}}^{T} \boldsymbol{X}^{\boldsymbol{T}} \boldsymbol{X} \hat{\boldsymbol{w}}\right)}{\partial \hat{\boldsymbol{w}}} \\
&=0-\boldsymbol{X}^{\boldsymbol{T}} \boldsymbol{y}-\boldsymbol{X}^{T} \boldsymbol{y}+X^{T} X \hat{\boldsymbol{w}}+\left(X^{T} X\right)^{T} \hat{w} \\
&=0-\boldsymbol{X}^{T} \boldsymbol{y}-\boldsymbol{X}^{T} \boldsymbol{y}+2 \boldsymbol{X}^{T} \boldsymbol{X} \hat{\boldsymbol{w}} \\
&=2\left(\boldsymbol{X}^{T} \boldsymbol{X} \hat{\boldsymbol{w}}-\boldsymbol{X}^{T} \boldsymbol{y}\right)=0
\end{aligned}$

即$$X^TX\hat w = X^Ty$$

若$X^TX$可逆，$\hat w = (X^TX)^{-1}X^Ty$

若$X^TX$不可逆，则最小二乘法求解过程就不成立了。此时也代表着数据集存在着较为严重的多重共线性。

##### 2.3.4  $X^TX$不可逆的解决办法

-   其一，对数据进行**降维处理**： 

    首先，可考虑进一步对数据集进行SVD分解或PCA主成分分析，在SVD或PCA执行的过程中会对数据集进行正交变换，最终所得数据集各列将不存在任何相关性。当然此举会对数据集的结构进行改变，且各列特征变得不可解释。

-   其二，修改损失函数的**求解方法**：

    通过**求解广义逆矩阵**，也可以得到近似最优解；还可以通过使用其他最优化求解方法，如**梯度下降算法**等来进行求解

-   其三，**修改损失函数**：

    可以修改原损失函数，令其满足最小二乘法求解条件即可。如果$X^TX$不可逆，那么我们可以通过试图在损失函数中加入一个正则化项，从而令损失函数可解

    -    岭回归：$$Loss(\hat w) = ||y - X\hat w||_2^2 +\lambda ||\hat w||_2^2$$

         $$(X^TX+\lambda I) \hat w = X^Ty$$

         $$\hat w = (X^TX+\lambda I)^{-1}X^Ty$$

    -    Lasso回归：$$Loss(\hat w) = ||y - X\hat w||_2^2 +\lambda ||\hat w||_1$$

    -    Elastic-Net弹性网：$$Loss(\hat w) = \frac{1}{2n}||y - X\hat w||_2^2 + \lambda \alpha ||\hat w||_1 +\frac{\lambda(1-\alpha)}{2} ||\hat w||_2 ^ 2$$

##### 2.3.5  Numpy方法直接求解

`np.linalg.lstsq(X, y, rcond=-1)`

其中，返回的元组中第一个元素是最小二乘法**计算$w$的结果**，第二个元素是**SSE的计算结果**，第三个元素是**矩阵X的秩**，最后一个结果是**矩阵X的奇异值**。

<div style="page-break-after:always"></div>

------

### 第3章  线性回归

#### 3.1  变量相关性

>   在构建线性模型之前先探查数据本身的线性相关性，如果自变量和因变量存在很好的相关性，那就一定可以顺利的构建线性回归模型对数据进行拟合。而如果线性相关性不强，则说明当前数据并不适合构建线性回归模型，或者在构建模型之前我们需要对数据做特征工程，进行一些“不影响真实规律”的转化，令其表现出线性的分布趋势。

皮尔逊相关性系数计算公式：$$Correlation = \frac{Cov(X, Y)}{\sqrt {Var(X) * Var(Y)}}$$

其中，$X$和$Y$是两个随机变量（对应数据集也就代表两个字段），$Var(X)、Var(Y)$为$X、Y$的方差，$Cov(X,Y)$为$X$和$Y$这两个变量的协方差，具体计算公式为：

$$\begin{aligned} Cov(X, Y) &= E(X-E(X))E(Y-E(Y)) \\&=E(XY)-E(X)E(Y)\end{aligned}$$

协方差表示的是两个变量的总体的误差。如果两个变量的变化趋势一致，那么两者的协方差为正。如果$X$与$Y$是统计独立的，那么二者之间的协方差就是0。

#### 3.2  线性回归的决定系数

>   除了SSE以外，我们还可使用决定系数（R-square，也被称为拟合优度检验）作为其模型评估指标。决定系数介于**[**0,1**]**之间，并且越趋近于1，模型拟合效果越好。

-   （组间误差平方和）预测数据与标签均值之间差值的平方和：$$SSR =\sum^{n}_{i=1}(\bar{y_i}-\hat{y_i})^2$$
-   （离差平方和）实际值与标签均值之间的差值的平方和：$$SST =\sum^{n}_{i=1}(\bar{y_i}-y_i)^2$$

并且，$SST$可由$SSR+SSE$计算得出。而决定系数，则由$SSR$和$SST$共同决定：

$$Rsquare=\frac{SSR}{SST}=\frac{SST-SSE}{SST}=1-\frac{SSE}{SST}$$

#### 3.3  机器学习模型可信度理论基础

>   无论是机器学习还是传统的统计分析模型，核心使命就是探索数字规律，而有监督学习则是希望在探索数字规律的基础上进一步对未来进行预测。
>
>   但我们知道，基本上所有的模型，都只能在以往的、已经知道的数据集上进行训练。这里的核心矛盾在于，在以往的数据中提取出来的经验（也就是模型），怎么证明能够在接下来的数据中也具备一定的预测能力呢？或者说，要怎么训练模型，才能让模型在未知的数据集上也拥有良好的表现呢？

##### 3.3.1  统计分析

首先，在统计分析领域，我们会假设现在的数据和未来的数据其实都属于某个存在但不可获得的总体，也就是说，现在和未来的数据都是从某个总体中抽样而来的，都是这个总体的样本。而正式因为这些数据属于同一个总体，因此具备某些相同的规律，而现在挖掘到的数据规律也就在某些程度上可以应用到未来的数据当中去，不过呢，不同抽样的样本之间也会有个体之间的区别，另外模型本身也无法完全捕获规律，而这些就是误差的来源。

在有了假设基础之后，统计分析就会利用一系列的数学方法和数理统计工具去推导总体的基本规律，也就是变量的分布规律和一些统计量的取值，由于这个过程是通过已知的样本去推断未知的总体，因此会有大量的“估计”和“检验”，在确定了总体的基本分布规律之后，才能够进一步使用统计分析模型构建模型（这也就是为什么在数理统计分析领域，构建线性回归模型需要先进行一系列的检验和变换的原因），当然，这些模型都是在总体规律基础之上、根据样本具体的数值进行的建模，我们自然有理由相信这些模型对接下来仍然是从总体中抽样而来的样本还是会具备一定的预测能力，这也就是我们对统计分析模型“信心”的来源。简单来说，就是我们通过样本推断总体的规律，然后结合总体的规律和样本的数值构建模型，由于模型也描绘了总体规律，所以模型对接下来从总体当中抽样而来的数据也会有不错的预测效果。

<img src="https://cdn.jsdelivr.net/gh/louisyanglu/images/images/KIpJCDyq9VQoliN.jpg" alt="37" style="zoom:40%;" />

##### 3.3.2  机器学习

对于机器学习来说，并没有借助“样本-总体”的基本理论，而是简单的采用了一种后验的方法来判别模型有效性，前面说到，我们假设前后获取的数据拥有规律一致性，但数据彼此之间又略有不同，为了能够在捕捉规律的同时又能考虑到“略有不同”所带来的误差，机器学习会把当前能获取到的数据划分成训练集(`trainSet`)和测试集(`testSet`)，在训练集上构建模型，然后带入测试集的数据，观测在测试集上模型预测结果和真实结果之间的差异。这个过程其实就是在模拟获取到真实数据之后模型预测的情况，此前说到，模型能够在未知标签的数据集上进行预测，就是模型的核心价值，此时的测试集就是用于模拟未来的未知标签的数据集。如果模型能够在测试集上有不错的预测效果，我们就“简单粗暴”的认为模型可以在真实的未来获取的未知数据集上有不错的表现。

<img src="https://cdn.jsdelivr.net/gh/louisyanglu/images/images/fGzPxCQ1qoOZuFs.jpg" alt="38" style="zoom:40%;" />

##### 3.3.3  划分验证集

机器学习模型主要通过模型在测试集上的运行效果来判断模型好坏，测试集相当于是“高考”，而此前的模型训练都相当于是在练习。严格意义上的测试集是不能参与建模的，此处不能参与建模，不仅是指在训练模型时不能带入测试集进行训练，更是指当模型训练完成之后、观察模型在测试集上的运行结果后，也不能据此再进行模型修改（比如增加神经网络层数）。

此时我们就需要一类新的数据集——验证集。验证集在模型训练阶段不会带入模型进行训练，但当模型训练结束之后，我们会把模型带入验证集进行计算，通过观测验证集上模型运行结果，判断模型是否要进行调整，验证集间接参与模型训练。

总的来说，在模型训练和观测模型运行结果的过程总共涉及三类数据集，分别是训练集、验证集和测试集。我们也可以把验证集看成是应对高考的“模拟考试”，通过“模拟考试”的考试结果来调整复习策略，从而更好的应对“高考”（测试集）。

##### 3.3.4  交叉验证

>   在我们不严格区分测试集的情况下，我们可以将数据集整体按照某个比例切分，然后进行循环验证。

尽管通过训练集和测试集的划分，我们可以以不参与建模的测试集的结论来证明模型结果的可信度，但在很多实际场景中，数据集的随机切分本身也是影响模型泛化能力、影响测试集结果可信度的重要因素。此时，我们可以采用一种名为交叉验证的技术手段来进一步提升模型最终输出结果的可信度。

最基础也最常用的一种就是所谓的K-fold（K折）验证，也就是将数据集进行K份等比例划分，然后依次取出其中一份进行验证（测试）、剩下几份进行训练。

严谨的做法，是先划分训练集和测试集，然后再在训练集上划分验证集，并且“**训练集-测试集**”划分方法用于进行**模型参数训练**，而“**训练集-验证集**”的划分方法主要用于进行**模型超参数选取**。

-   参数：模型根据数据自动学习出的变量，如深度学习的权重；
-   超参数：用来确定模型的一些参数。超参数不同，模型也不同（都是CNN模型，如果层数不同，模型不一样），如深度学习中的学习率、迭代次数等。

<div style="page-break-after:always"></div>

------

### 第4章  逻辑回归

>   逻辑回归的基本原理，从整体上来划分可以分为两个部分，其一是关于**模型方程的构建**，也就是方程的基本形态，当然也包括模型的基本性质及其结果解读；其二则是**模型参数求解**，即在构建完模型之后如何利用数学工具求解最佳参数。
>
>   -   模型构建部分：
>       1.   可以从广义线性回归（Generalized liner model）+对数几率函数（logit function）角度理解
>       2.   也可以从随机变量的逻辑斯蒂分布（logistic distribution）角度出发进行理解；
>   -   参数求解部分：
>       1.   可以借助极大似然估计（Maximum Likelihood Estimate）方法求解
>       2.   也可以借助KL离散度基本理论构建二分类交叉熵损失函数求解。

#### 4.1  模型构建：广义线性模型+对数几率函数

##### 4.1.1  广义线性回归

为了解决**非线性相关**的问题，在线性回归基础上，在等号的左边或右边加上了一个函数，从而能够让模型更好的捕捉一般规律，此时该模型就被称为广义线性模型，该函数就被称为联系函数。

广义线性模型的一般形式可表示如下：$$g(y)=\hat w^T \cdot \hat x$$

等价于$$y = g^{-1}(\hat w^T \cdot \hat x)$$

其中$g(·)$为联系函数（link function），$g^{-1}(·)$为联系函数的反函数（如$y=e^x与ln(y)=x$）。

注：一般来说广义线性模型要求**联系函数**必须是**单调可微**函数。

##### 4.1.2  对数几率函数

假设某事件发生的概率为p，则该事件不发生的概率为1-p，该事件的几率为：$$odd(p)=\frac{p}{1-p}$$。

在几率的基础上取（自然底数的）对数，则构成该事件的对数几率（logit）：$$logit(p) = ln\frac{p}{1-p}$$。

如果我们将对数几率看成是一个函数，并将其作为联系函数，即$g(y)=ln\frac{y}{1-y}$，则该广义线性模型为：$$g(y)=ln\frac{y}{1-y}=\hat w^T \cdot \hat x$$。

此时模型就被称为对数几率回归（logistic regression），也被称为逻辑回归。

数理统计分析方法构建逻辑回归时，基本假设要求变量y必须服从伯努利分布（又名0-1分布，若试验成功则随机变量取值为1，否则取值为0）。

#### 4.2  模型构建：逻辑斯蒂分布

##### 4.2.1  Sigmoid函数

如果我们将上述对数几率函数$$g(y)=ln\frac{y}{1-y}=\hat w^T \cdot \hat x$$“反解”出来

$\begin{aligned} y &= 1-\frac{1}{e^{\hat w^T \cdot \hat x}+1}\\ &=\frac{e^{\hat w^T \cdot \hat x}}{e^{\hat w^T \cdot \hat x}+1} \\&=\frac{1}{1+e^{-(\hat w^T \cdot \hat x)}} = g^{-1}(\hat w^T \cdot \hat x)\end{aligned}$

即对数几率函数的反函数为：$$f(x) = \frac{1}{1+e^{-x}}$$

该函数的图像近似S形，这种类似S形的函数，也被称为Sigmoid函数。

<img src="https://cdn.jsdelivr.net/gh/louisyanglu/images/images/image-20221214161304505.png" alt="image-20221214161304505" style="zoom:50%;" />

##### 4.2.2  Sigmoid函数的导函数

对于Sigmoid函数来说，函数是单调递增函数，并且自变量在实数域上取值时，因变量取值范围在(0,1)之间。并且当自变量取值小于0时，因变量取值小于0.5，当自变量取值大于0时，因变量取值大于0.5。

令：$$Sigmoid(x) = \frac{1}{1+e^{-x}}$$

对其求导可得：

$$\begin{aligned} Sigmoid'(x) &= (\frac{1}{1+e^{-x}})' \\&=((1+e^{-x})^{-1})'  \\&=(-1)(1+e^{-x})^{-2} \cdot (e^{-x})' \\&=(1+e^{-x})^{-2}(e^{-x}) \\&=\frac{e^{-x}}{(1+e^{-x})^{2}} \\&=\frac{e^{-x}+1-1}{(1+e^{-x})^{2}} \\&=\frac{1}{1+e^{-x}} - \frac{1}{(1+e^{-x})^2} \\&=\frac{1}{1+e^{-x}}(1-\frac{1}{1+e^{-x}}) \\&=Sigmoid(x)(1-Sigmoid(x))\end{aligned}$$

Sigmoid导函数在实数域上取值大于0，并且函数图像先递增后递减，并在0点取得最大值。由于导函数始终大于0，因此Sigmoid函数始终递增，并且导函数在0点取得最大值，因此Sigmoid在0点变化率最快，而在远离零点的点，Sigmoid导函数取值较小，因此该区间Sigmoid函数变化缓慢。该区间也被称为Sigmoid的饱和区间。

<img src="https://cdn.jsdelivr.net/gh/louisyanglu/images/images/image-20221214161126949.png" alt="image-20221214161126949" style="zoom: 50%;" />

简单探索Sigmoid函数的二阶导函数，其实能够发现，x<0时二阶导函数取值大于0（一阶导函数递增），而x>0时二阶导函数小于0（一阶导函数递减）。因此0点其实也是sigmoid函数的拐点。

|   性质   |                         说明                         |
| :------: | :--------------------------------------------------: |
|  单调性  |                       单调递增                       |
|  变化率  |          0点变化率最大，越远离0点变化率越小          |
| 取值范围 |                       （0，1）                       |
|  凹凸性  | 0点为函数拐点，0点之前函数为凸函数，此后函数为凹函数 |

#### 4.3  参数求解：极大似然估计（4步）

逻辑回归的参数其实就是线性方程中的自变量系数和截距。不过由于加入了联系函数，逻辑回归的参数并不能像线性回归一样利用最小二乘法进行快速求解。

##### 4.3.1  一维特征

现有简单数据集如下：

| sepal_length | species |
| :----------: | :-----: |
|      1       |    0    |
|      3       |    1    |

由于只有一个特征，因此可以构建逻辑回归模型为：$$y=sigmoid(wx+b)=\frac{1}{1+e^{-(wx+b)}}$$

$$p(y=1|x=1)=\frac{1}{1+e^{-(w+b)}}$$

$$p(y=1|x=3)=\frac{1}{1+e^{-(3w+b)}}$$

$$p(y=0|x=1) = 1-p(y=1|x=1)=1-\frac{1}{1+e^{-(w+b)}}=\frac{e^{-(w+b)}}{1+e^{-(w+b)}}$$

| sepal_length | species |         1-predict         |              0-predict              |
| :----------: | :-----: | :-----------------------: | :---------------------------------: |
|      1       |    0    | $\frac{1}{1+e^{-(w+b)}}$  |  $\frac{e^{-(w+b)}}{1+e^{-(w+b)}}$  |
|      3       |    1    | $\frac{1}{1+e^{-(3w+b)}}$ | $\frac{e^{-(3w+b)}}{1+e^{-(3w+b)}}$ |

我们希望模型预测结果尽可能准确，就等价于希望$p(y=0|x=1)$和$p(y=1|x=3)$两个概率结果越大越好：$$max \ p(y=0|x=1)\cdot p(y=1|x=3)$$

考虑到损失函数一般都是求最小值，同时累乘也可以转化为对数相加结果，可等价于：

$$\begin{aligned}LogitLoss(w, b)&=-ln(p(y=1|x=3))-ln(p(y=0|x=1)) \\&=-ln(\frac{1}{1+e^{-(3w+b)}})- ln(\frac{e^{-(w+b)}}{1+e^{-(w+b)}}) \\&=ln(1+e^{-(3w+b)})+ln(1+\frac{1}{e^{-(w+b)}}) \\&=ln(1+e^{-(3w+b)}+e^{(w+b)}+e^{-2w})\end{aligned}$$

通过对$LogitLoss(w,b)$求偏导然后令偏导函数等于0、再联立方程组的方式来对参数进行求解。

$\frac{\partial LogitLoss(w,b)}{\partial w}=0$

$\frac{\partial LogitLoss(w,b)}{\partial b}=0$

**问题：**

1.   **为何不能采用SSE**来构建损失函数，即：$$||y-\hat y||_2^2=||y-\frac{1}{1+e^{-(\hat w^T \cdot \hat x)}}||_2^2$$ 

     在数学层面上我们可以证明，对于逻辑回归，当y属于0-1分类变量时，$||y-\hat y||_2^2$损失函数**并不是凸函数**，而非凸的损失函数将对后续参数最优解求解造成很大麻烦。而相比之下，概率连乘所构建的损失函数是凸函数，可以快速求解出全域最小值。

2.   在构建损失函数的过程中，我们需要将概率**连乘改为对数累加**

     在实际建模运算过程中，尤其是面对大量数据进行损失函数构建过程中，由于有多少条数据就要进行多少次累乘，而累乘的因子又是介于(0,1)之间的数，因此极有可能**累乘得到一个非常小的数**，而通用的计算框架计算精度有限，即有可能在累乘的过程中损失大量精度，而转化为对数累加之后能够很好的避免该问题的发生。

##### 4.3.2  多维特征

逻辑回归模型：$$y = \frac{1}{1+e^{-(\hat w^T \cdot \hat x)}}$$

其中：$$\hat w = [w_1,w_2,...w_d, b]^T, \hat x = [x_1,x_2,...x_d, 1]^T$$

求解过程分4步：

1.   确定**似然项** $$p_1(\hat x;\hat w)^{y_i} \cdot p_0(\hat x;\hat w)^{(1-y_i)}$$

     累乘过程中的每个项，可称为似然项。似然项和数据是一一对应的，带入多少条数据进行建模，似然函数中就有多少个似然项。

     对于逻辑回归来说，当$\hat w$和$\hat x$确定之后，输出一个概率预测结果，即：$$p(y=1|\hat x;\hat w) = \frac{1}{1+e^{-(\hat w^T \cdot \hat x)}}$$

     而对应$y$取0的概率为：$$1-p(y=1|\hat x;\hat w) =1- \frac{1}{1+e^{-(\hat w^T \cdot \hat x)}}=\frac{e^{-(\hat w^T \cdot \hat x)}}{1+e^{-(\hat w^T \cdot \hat x)}}$$

     我们可以令，$$p_1(\hat x;\hat w)=p(y=1|\hat x;\hat w)$$，$$p_0(\hat x;\hat w)=1-p(y=1|\hat x;\hat w)$$

     因此，第$i$个数据所对应的似然项可以写成：$$p_1(\hat x;\hat w)^{y_i} \cdot p_0(\hat x;\hat w)^{(1-y_i)}$$

     其中，$y_i$表示第$i$条数据对应的类别标签。不难发现，当$y_i=0$时，代表的是$i$第条数据标签为0，此时需要带入似然函数的似然项是$p_0(\hat x;\hat w)$（因为希望$p_0$的概率更大）。反之，当$y_i=1$时，代表的是$i$第条数据标签为1，此时需要带入似然函数的似然项是$p_1(\hat x;\hat w)$。上述似然项可以同时满足这两种不同的情况。

2.   构建**似然函数** $$\prod^N_{i=1}[p_1(\hat x;\hat w)^{y_i} \cdot p_0(\hat x;\hat w)^{(1-y_i)}]$$

     通过似然项的累乘构建极大似然函数：$$\prod^N_{i=1}[p_1(\hat x;\hat w)^{y_i} \cdot p_0(\hat x;\hat w)^{(1-y_i)}]$$

3.   进行**对数转换**

     在似然函数基础上对其进行（以e为底的）对数转换，为了方便后续利用优化方法求解最小值，同样我们考虑构建负数对数似然函数：

     $$\begin{aligned}L(\hat w) &= -ln(\prod^N_{i=1}[p_1(\hat x;\hat w)^{y_i} \cdot p_0(\hat x;\hat w)^{(1-y_i)}]) \\&= \sum^N_{i=1}[-y_i \cdot ln(p_1(\hat x;\hat w))-(1-y_i) \cdot ln(p_0(\hat x;\hat w))] \\&= \sum^N_{i=1}[-y_i \cdot ln(p_1(\hat x;\hat w))-(1-y_i) \cdot ln(1-p_1(\hat x;\hat w))] \end{aligned}$$

4.   **求解**对数似然函数

     通过一系列数学过程可以证明，通过**极大似然估计构建的损失函数是凸函数**，此时我们**可以采用导数为0**联立方程组的方式进行求解，这也是极大似然估计对参数求解的一般方法。

     但这种方法会涉及大量的导数运算、方程组求解等，**并不适用于大规模数值运算**，因此，在机器学习领域，我们通常会采用一些更加通用的优化方法对逻辑回归的损失函数进行求解，通常来说是牛顿法或者梯度下降算法，其中，**梯度下降算法**是机器学习中最为通用的求解损失函数的优化算法。

#### 4.4  参数求解：交叉熵损失函数

##### 4.4.1  熵

通常我们用熵（entropy）来表示随机变量不确定性的度量，或者说系统混乱程度、信息混乱程度。熵的计算公式如下：$$H(X) = -\sum^n_{i=1}p(x_i)log(p(x_i))$$

其中，$p(x_i)$表示多分类问题中第$i$个类别出现的概率，$n$表示类别总数，通常来说信息熵的计算都取底数为2，并且规定$log0=0$

```python
def entropy(p):
    if p == 0 or p == 1:
        ent = 0
    else:
        ent = -p * np.log2(p) - (1-p) * np.log2(1-p)
    return ent
```

熵的计算结果在[0,1]之间，并且**熵值越大，系统越混乱**

假设p为二分类数据集中1样本所占比例，则数据集信息熵随着p变化为变化趋势如下：

<img src="https://cdn.jsdelivr.net/gh/louisyanglu/images/images/image-20221214170336371.png" alt="image-20221214170336371" style="zoom:50%;" />

##### 4.4.2  相对熵

相对熵也被称为Kullback-Leibler散度（KL散度）或者信息散度（information divergence）。通常用来衡量两个随机变量分布的差异性。假设对同一个随机变量X，有两个单独的概率分布P(x)和Q(x)，当X是离散变量时，我们可以通过如下相对熵计算公式来衡量二者差异：$$D_{KL}(P||Q)=\sum ^n_{i=1}P(x_i)log(\frac{P(x_i)}{Q(x_i)})$$。

和信息熵类似，相对熵越小，代表Q(x)和P(x)越接近。

从交叉熵的计算公式不难看出，这其实是一种非对称性度量，也就是$D_{KL}(P||Q)≠D_{KL}(Q||P)$。从本质上来说，**相对熵**刻画的是**用概率分布Q来刻画概率分布P**的**困难程度**，而在机器学习领域，我们一般令**Q为模型输出结果**，而**P为数据集标签真实结果**，以此来判断**模型输出结果是否足够接近真实情况**。Q为拟合分布P为真实分布，也被称为前向KL散度（forward KL divergence）

$$\begin{aligned}D_{KL}(P||Q)&=\sum ^n_{i=1}P(x_i)log(\frac{P(x_i)}{Q(x_i)}) \\&=\sum ^n_{i=1}P(x_i)log(P(x_i))-\sum ^n_{i=1}P(x_i)log(Q(x_i)) \\&=-H(P(x))+[-\sum ^n_{i=1}P(x_i)log(Q(x_i))] \\&=交叉熵-信息熵 \end{aligned}$$

对于给定数据集，信息熵$H(P(X))$是确定的，因此相对熵的大小完全由$-\sum ^n_{i=1}P(x_i)log(Q(x_i))$决定。而该式计算结果也被称为交叉熵（cross entropy）计算。

$$cross\_entropy(P,Q) = -\sum ^n_{i=1}P(x_i)log(Q(x_i))$$

因此，如果我们希望P、Q二者分布尽可能接近，我们就需要尽可能减少相对熵，但由于相对熵=交叉熵-信息熵，因此我们只能力求减少交叉熵。

小结：

-   我们用相对熵$D_{KL}(P||Q)$来表示模型拟合分布Q和数据真实分布P之间的差距，相对熵越小拟合效果越好；
-   根据计算公式，$D_{KL}(P||Q)=-H(P(x))+[-\sum ^n_{i=1}P(x_i)log(Q(x_i))]$，相对熵=交叉熵-信息熵；
-   对于给定数据集，信息熵是确定的，因此我们只能通过尽可能减小交叉熵来降低相对熵。

根据吉布斯不等式，相对熵的取值恒大于等于零，当预测分布和真实分布完全一致时相对熵取值为0，此时交叉熵等于数据信息熵，此外只要二者分布不一致，交叉熵的取值都将大于信息熵。

据此，我们可以给出多样本交叉熵计算公式如下：$$cross\_entropy = -\frac{1}{m}\sum ^m_j \sum^n_ip(p_{ij})log(q_{ij})$$，其中m为数据量，n为类别数量。

对比极大似然估计：$$L(\hat w)= \sum^N_{i=1}[-y_i \cdot ln(p_1(\hat x;\hat w))-(1-y_i) \cdot ln(1-p_1(\hat x;\hat w))] $$，带入数据可得：$$-ln(0.8)-ln(0.7)-ln(0.6)-ln(0.7)$$。尽管具体数值计算结果有所差异，但基本流程都是类似的——取类别1的概率的对数运算结果进行累加再取负数。

据此，我们也可最终推导**二分类交叉熵损失函数**计算公式，结合极大似然估计的计算公式和交叉熵的基本计算流程，二分类交叉熵损失函数为：$$binaryCE(\hat w)= -\frac{1}{n}\sum^N_{i=1}[y_i \cdot log(p_1(\hat x;\hat w))+(1-y_i) \cdot log(1-p_1(\hat x;\hat w))] $$

```py
def BCE(y, yhat):
    """
    二分类交叉熵损失函数
    """
    return(-(1 / len(y)) * np.sum(y * np.log2(yhat) + (1 - y) * np.log2(1 - yhat)))
```

##### 4.4.3  PSI

**KL散度是单向描述信息熵差异**

$$\begin{aligned}D_{KL}(P||Q)&=\sum ^n_{i=1}P(x_i)log(\frac{P(x_i)}{Q(x_i)})\end{aligned}$$

$\begin{aligned}
p s i &=\sum_{i=1}^{n}\left(A_{i}-E_{i}\right) * \ln \left(A_{i} / E_{i}\right) \\
p s i &=\sum_{i=1}^{n} A_{i} * \ln \left(A_{i} / E_{i}\right)+\sum_{i=1}^{n} E_{i} * \ln \left(E_{i} / A_{i}\right)  \\ &=KL(A||E)+KL(E||A)
\end{aligned}$

**PSI本质上是实际分布（A）与预期分布（E）的KL散度的一个对称化操作**

##### 4.4.4  CSI

CSI = SUM( (每个分箱内实际占比 - 每个分箱内预期占比）* 分箱分值），分箱分值用基准Odds、基准分数、PDO和woe值计算得出

-   CSI为正，表示当前样本相对于开发样本往高分段偏移
-   绝对值越大，稳定性越差

每个人的基准Odds、基准分数、PDO不一样，CSI不能对齐，没有**经验阈值**

不同特征变量比较也没有意义

机器学习模型不能计算CSI

##### 4.4.5  KS

$KS=\max (|cum\_bad\_rate-cum\_good\_rate|)\max (|TPR-FPR|)$

$TPR=\frac{TP}{TP+FN},有多少真实正被预测出来，抓对坏人$

$FPR=\frac{FP}{FP+TN},有多少真实负被预测成正，错抓好人$

KS检验：根据样本来推断总体是否服从某种分布的方法

-   **原假设H0** ：好人、坏人的分数分布**服从**同一总体分布
-   **备择假设H1**：好人、坏人的分数分布**不服从**同一总体分布

p越小越拒绝，越不服从同一分布

##### 4.4.6  WOE

$W O E_{i}=\ln \left(\frac{\text { Bad }_{i}}{B a d_{T}} / \frac{\text { Good }_{i}}{\operatorname{Good}_{T}}\right)=\ln \left(\frac{\text { Bad }_{i}}{B a d_{T}}\right)-\ln \left(\frac{\text { Good }_{i}}{\text { Good }_{T}}\right)，i表示第i个分箱$

$\left\{\begin{array}{r}
p(Y=B a d \mid X)=\frac{p(X \mid Y=B a d) p(Y=B a d)}{P(X)} \\
p(Y=G o o d \mid X)=\frac{p(X \mid Y=G o o d) p(Y=\text { Good })}{P(X)}
\end{array}\right.$

$\begin{array}{l}
\Rightarrow \frac{p(Y=\operatorname{Bad} \mid X)}{p(Y=\operatorname{Good} \mid X)}=\frac{p(X \mid Y=\operatorname{Bad}) p(Y=\text { Bad })}{p(X \mid Y=\text { Good }) p(Y=\text { Good })} \\
\Rightarrow \ln \left(\frac{p(Y=B a d \mid X)}{p(Y=\operatorname{Good} \mid X)}\right)=\ln \left(\frac{p(X \mid Y=B a d)}{p(X \mid Y=\text { Good })}\right)+\ln \left(\frac{p(Y=\text { Bad })}{p(Y=\text { Good })}\right) \\ \Rightarrow  ln(\frac{Bad_i}{Good_i}) = WOE +ln(\frac{Bad_T}{Good_T}) \\(主观的先验认知：\frac{Bad_T}{Good_T}，观测数据WOE=ln(\frac{p(X|Y=Bad)}{p(X|Y=Good)})，通过先验数据修正后的知识，即后验认知：\frac{Bad_i}{Good_i})
\end{array}$

**WOE用以衡量对先验认识修正的增量，**这就是WOE被取名为“**证据权重**”的原因

##### 4.4.7  IV

$\begin{array}{l}
I V=\sum_{i=1}^{n}\left(\frac{\text { Bad }_{i}}{\text { Bad }_{T}}-\frac{\text { Good }_{i}}{\text { Good }_{T}}\right) * \ln \left(\frac{\text { Bad }_{i}}{\text { Bad }_{T}} / \frac{\text { Good }_{i}}{\text { Good }_{T}}\right) \\
P S I=\sum_{i=1}^{n}\left(\frac{\text { Actual }_{i}}{\text { Actual }_{T}}-\frac{\text { Expect }_{i}}{\text { Expect }_{T}}\right) * \ln \left(\frac{\text { Actual }_{i}}{\text { Actual }_{T}} / \frac{\text { Expect }_{i}}{\text { Expect }_{T}}\right)
\end{array}$

IV指标是在**从信息熵上比较好人分布和坏人分布之间的差异性**

#### 4.5  逻辑回归模型输出结果是否是概率

>   决定输出结果 $\hat{y}$ 是否是概率的核心因素，不是模型本身，而是建模流程。

逻辑斯蒂本身也有对应的概率分布，因此输入的自变量其实是可以视作随机变量的，但前提是需要满足一定的分布要求。如果逻辑回归的建模流程遵照数理统计方法的一般建模流程，即自变量的分布（或者转化之后的分布）满足一定要求（通过检验），则最终模型输出结果就是严格意义上的概率取值。

而如果是遵照机器学习建模流程进行建模，在为对自变量进行假设检验下进行模型构建，则由于自变量分布不一定满足条件，因此输出结果不一定为严格意义上的概率。

如果我们将逻辑回归模型输出结果视作样本属于1类的概率，则可将逻辑回归模型改写成如下形式：

$$p(y=1|\hat x;\hat w) =\frac{1}{1+e^{-(\hat w^T \cdot \hat x)}}$$

$$p(y=0|\hat x;\hat w) =\frac{e^{-(\hat w^T \cdot \hat x)}}{1+e^{-(\hat w^T \cdot \hat x)}}$$

#### 4.6  多分类逻辑回归

如果要使用逻辑回归解决多分类问题，一般来说有两种方法，其一是将逻辑回归模型改为**多分类模型形式**，其二则是采用通用的**多分类学习方法**对建模流程进行改造。

其中将逻辑回归模型改写成多分类模型形式并不常用并且求解过程非常复杂，包括Scikit-Learn在内，主流的实现多分类逻辑回归的方法都是采用多分类学习方法。所谓多分类学习方法，则指的是将一些二分类学习器（binary classifier）推广到多分类的场景中，该方法属于包括逻辑回归在内所有二分类器都能使用的通用方法。

用二分类学习器解决多分类问题，基本思想是**先拆分后集成**，也就是先将数据集进行拆分，然后多个数据集可训练多个模型，然后再对多个模型进行集成。这里所谓集成，指的是使用这多个模型对后续新进来数据的预测方法。

| 策略 | 拆分                                  | 子数据集组合                                   | 结果集成                                 | 训练的子模型数 |
| :--: | ------------------------------------- | ---------------------------------------------- | ---------------------------------------- | :------------: |
| OvO  | 将每个类别对应的子数据集单独拆分      | 两两组合                                       | 投票法                                   |    $C_N^2$     |
| OvR  | 将某一类的样例作为正例1，其余作为0    | $/$                                            | 预测为正的分类器中，准确率更高的作为结果 |      $N$       |
| MvM  | 任选其中1类/2类…作为正例1，其余作为-1 | 采用“纠错输入码”（ECOC），挑选部分子数据集建模 | 计算编码距离，挑选最近的样本对应的标签   |      $/$       |

##### 4.6.1  OvO策略

-   拆分

    将每个类别对应数据集单独拆分成一个子数据集，然后令其两两组合，再来进行模型训练

    N分类问题，则需要训练$C^2_N=\frac{N(N-1)}{2}$个模型

    <img src="https://cdn.jsdelivr.net/gh/louisyanglu/images/images/NT8MEoSJcdFaVL9.jpg" alt="81" style="zoom:33%;" />

-   集成

    使用投票法从$C^2_N$个分类器的判别结果中挑选最终判别结果。

##### 4.6.2  OvR策略

-   拆分

    每次将一类的样例作为正例、其他所有数据作为反例来进行数据集拆分

    N分类问题，则需要训练N个模型

    <img src="https://cdn.jsdelivr.net/gh/louisyanglu/images/images/t9fKCdqOnwgJmEM.jpg" alt="83" style="zoom:33%;" />

-   集成

    对于OvR方法来说，对于新数据的预测，如果仅有一个分类器将其预测为正例，则新数据集属于该类。若有多个分类器将其预测为正例，则根据分类器本身准确率来进行判断，选取准确率更高的那个分类器的判别结果作为新数据的预测结果。

**OVO vs. OvR**

尽管OvO需要训练更多的基础分类器，但由于OvO中的每个切分出来的数据集都更小，因此基础分类器训练时间也将更短。因此，综合来看在训练时间开销上，OvO往往要小于OvR。而在性能方面，大多数情况下二者性能类似。

##### 4.6.3  MvM策略

-   拆分

    可以任选其中一类作为正类、其余作为负类，也可以任选其中两类作为正类、其余作为负数。

    同时将若干类化为正类、其他类化为负类，并且要求多次划分，再进行集成。一般来说，通常会采用一种名为“纠错输入码”（Error Correcting Output Codes，简称ECOC）的技术来实现MvM过程。

    <img src="https://cdn.jsdelivr.net/gh/louisyanglu/images/images/rCJLkghq5ROj1p6.jpg" alt="85" style="zoom:33%;" />

    根据上述划分方式，总共将划分$C_4^1+C_4^2=10$个数据集，对应构建，对应的我们可以构建10个分类器。不过一般来说对于ECOC来说我们不会如此详尽的对数据集进行划分，而是再上述划分结果中挑选部分数据集进行建模，例如就挑选上面显式表示的4个数据集来进行建模，即可构建4个分类器。

-   集成

    <img src="https://cdn.jsdelivr.net/gh/louisyanglu/images/images/hydDjczHIvS8EsV.jpg" alt="87" style="zoom:33%;" />

    使用训练好的四个基础分类器对新数据进行预测，也将产生四个结果，而这四个结果也可构成一个四位的新数据的编码。接下来，我们可以计算新数据的编码和上述不同类别编码之间的距离，从而判断新生成数据应该属于哪一类。

    **距离衡量公式**

    -   **欧式距离**：$$d(x, y) = \sqrt{\sum_{i = 1}^{n}(x_i-y_i)^2}$$
    -   **街道距离**：$$d(x, y) =\sum_{i = 1}^{n}(|x_i-y_i|)$$
    -   **闵可夫斯基距离**：$$d(x, y) = \sqrt[n]{\sum_{i = 1}^{n}(|x_i-y_i|)^n}$$

    对于ECOC方法来说，编码越长预测结果越准确，不过编码越长也代表着需要耗费更多的计算资源，并且由于模型本身类别有限，因此数据集划分数量有限，编码长度也会有限。不过一般来说，相比OvR，**MvM方法效果会更好**。OvR是MvM的一种特例。

<div style="page-break-after:always"></div>

------

### 第5章  梯度下降法

>   梯度下降算法的目标仍然是求最小值，但和最小二乘法这种一步到位、通过解方程组直接求得最小值的方式不同，梯度下降是通过一种“迭代求解”的方式来进行最小值的求解，其整体求解过程可以粗略描述为，**先随机选取一组参数初始值，然后沿着某个方向，一步一步移动到最小值点**。

#### 5.1  梯度下降基本原理

##### 5.1.1  梯度

设$f(x)$是一个关于$x$的函数，其中$x$是向量变元，并且$$x = [x_1, x_2,...,x_n]^T$$​，则$$\frac{\partial f}{\partial x} = [\frac{\partial f}{\partial x_1}, \frac{\partial f}{\partial x_2}, ...,\frac{\partial f}{\partial x_n}]^T$$

而该表达式也被称为向量求导的梯度向量形式：$$\nabla _xf(x) = \frac{\partial f}{\partial x} = [\frac{\partial f}{\partial x_1}, \frac{\partial f}{\partial x_2}, ...,\frac{\partial f}{\partial x_n}]^T$$

进一步的，如果假设$f(x)$是关于参数$x$的损失函数，则$\nabla _xf(x)$就是损失函数的梯度向量，或者梯度表达式。而当损失函数的参数$x$选定一组取值之后，我们就能计算梯度表达式的取值，该值也被称为损失函数在某组参数取值下的梯度。

##### 5.1.2  梯度下降基本流程

在确定了梯度之后，接下来参数的移动方向也随之确定，在梯度下降算法中，**参数的移动方向是梯度的负方向**。

-   Step 1.随机选取初始参数值
-   Step 2.基于$w_0$，计算梯度，确定参数移动方向（梯度反方向）
-   Step 3.确定移动步长并进行移动（`lr * 梯度`）

##### 5.1.3  梯度下降基本特性

梯度下降的计算过程中，刚开始$w$变化非常快，而随着逐渐接近最小值点$w$的变化幅度逐渐减少，也就是说，梯度下降其实并不是一个等步长的移动过程。当然，根据梯度下降的计算公式，$w_{(n-1)}$和$w_{n}$的差值是：$$|w_n - w_{(n-1)}| =  |lr \cdot \nabla _wf(w_{(n-1)})|$$。而lr又是一个恒定的数值，那么也就是说，每个点的梯度值是不一样的（哪怕梯度方向一样），并且**越靠近最小值点梯度值越小，步长越小。**

1.   **不同损失函数选取方式或者数值处理方法对梯度下降过程中移动距离有影响**

     >   **影响迭代收敛结果的是每一步移动的真实距离**，而移动的真实距离又和**学习率**和**梯度**二者相关。

     有的时候我们可以**通过一些数值处理手段等比例缩小梯度，此时学习率就可以稍微设置大些**。例如此处如果我们采用MSE计算公式作为损失函数，则梯度计算公式就由原先的$28(w-2)$变为了$\frac{28(w-2)}{3}$（总共三条样本，$MSE=\frac{SSE}{3}$）。而此时就相当于梯度减少至原先的1/3，在学习率不变的情况下，每次移动的距离也将减少至原先的1/3。

     而在另外一种情况下，也就是例如**数据归一化**，即对带入的数据进行数值调整的一种方法（后续会介绍）。如果带入损失函数计算的数值大幅减少，则最终的梯度也会受其影响，数值也会有所减少，此时同样在学习率不变的情况下每次移动的距离也会减少。

2.   **移动距离衰减**

     参数点越远离最小值点，参数点的梯度就相对较大，此时每次迭代移动的距离就相对较大，而如果参数点比较靠近最小值点，此时梯度取值较小，每次移动的距离就比较小。而当已经非常接近最小值点时，每次移动的距离就会变得非常小，因此我们其实无论增加多少轮迭代，只要参数不会发散，最终参数值点都不可能“跨过”最小值点。

#### 5.2  梯度下降算法的优缺点

##### 5.2.1  优点

主要体现在两个方面，其一是相比大规模数值矩阵运算，梯度下降所遵循的迭代求解效率更高（尽管大规模矩阵运算也可以通过分块矩阵的划分来减少每一次计算的数据量），其二则是对于某些最小二乘法无法计算全域唯一最优解的情况，梯度下降仍然能够有效进行最小值点（或者解空间）的寻找。

##### 5.2.2  缺点

当损失函数不是凸函数时，也就是有可能存在局部最小值或者鞍点时，梯度下降并不一定能够准确找到全域最小值。

-   **Local Minimum**

    局部最小值，指的是该点左右两端取值都大于该点，但是该点不是全域最小值点。

    <img src="https://cdn.jsdelivr.net/gh/louisyanglu/images/images/local minimum.png" alt="87" style="zoom:0%;" />

-   **Saddle Point**

    鞍点是那些不是极值点但梯度为0的点。所谓极值，指的是那些连续函数上导数为0、并且所有两边单调性相反的点，极值包括局部最小值、最小值点、局部最大值和最大值点四类。而鞍点和极值点的区别在于**导数为0但左右两边单调性相同**。

    <img src="https://cdn.jsdelivr.net/gh/louisyanglu/images/images/saddle point.png" alt="87" style="zoom:0%;" />

##### 5.2.3  改进

>   在实际情况中，鞍点出现的频率高于局部最小值点。

梯度下降的本质作用其实是让参数点移动到梯度为0的点，当损失函数是严格意义的凸函数时，梯度为0的点就是全域最小值点，但如果损失函数不是凸函数，那么梯度为0的点就有可能是局部最小值点或者鞍点。此时受到局部最小值点或者鞍点梯度为0的影响，梯度下降无法从该点移出。

尽管大多数线性模型的损失函数都是凸函数，但很多复杂机器学习模型所构建的损失函数都不一定是严格凸函数，**要避免局部最小值点或者鞍点陷阱**，我们就必须在梯度下降算法基础上进行改进。

其中最为简单有效的方式是**调整每次带入训练的样本数量**，通过局部规律的不一致性来规避“非全域最小值但梯度为0”的陷阱，从而让参数有机会跳出陷阱，这就是所谓的**随机梯度下降**和**小批量梯度下降**。

#### 5.3  随机梯度下降

##### 5.3.1  损失函数理论基础

数据集1:

| Index |  x   |  y   |
| :---: | :--: | :--: |
|   1   |  1   |  2   |
|   2   |  3   |  5   |
|   3   |  6   |  4   |
|   4   |  8   |  3   |

数据集2:

| Index |  x   |  y   |
| :---: | :--: | :--: |
|   1   |  1   |  2   |
|   2   |  2   |  4   |

模型：$$y=wx$$，损失函数计算公式：$$MSELoss(w)=\frac{\sum_{i=1}^n||y_i-\hat y_i||_2^2}{n}$$

>   带入训练的数据不同，损失函数会有所不同，进而训练出来的模型参数会有所不同，最终得到不同的模型结果。

当我们带入全部四条数据进行计算时，损失函数为：$$\begin{aligned}Loss_4(w) &= \frac{(2-w)^2+(5-3w)^2+(4-6w)^2+(3-8w)^2}{4} \\&=\frac{110w^2-100w+54}{4}\end{aligned}$$。令损失函数导函数为0，最终解得模型$y = \frac{5}{11}x$。

而如果我们带入其中第一条数据进行计算，则损失函数计算公式为：$$Loss_1(w)=(2-w)^2 = w^2-4w+4$$。此时解出最优参数结果为$w=2$，即训练得出模型为$y=2x$。

很明显，**带入训练数据不同、损失函数不同、训练所得模型也不同。**

1.   **损失函数其实是数据集规律的一种体现**

     模型其实是数据集规律的体现，而损失函数又是求解模型参数的基本函数，因此我们可以认定损失函数其实是一批数据所表现出规律的一种体现，并且不同数据的损失函数不同，我们就认定这几批数据对应的基本规律有所不同。

     如数据集1中，两个损失函数形态不同，其实也就代表着其背后的数据基本规律各不相同。

     $Loss(w)_4$和$Loss(w)_1$，二者之所以会表现出差异，是因为$Loss(w)_4$背后的四条数据所表现出的整体规律和$MSELoss(w)_1$后背的一条数据所表现出的**规律不一致**。

2.   **规律一致、损失函数也一致**

     同时需要知道的是，有时数据看似不同，但实际上背后规律一致，此时损失函数其实也是一致的。

     从原理上讲，损失函数是指导求解全域最小值的方程，而如果多条（部分）数据规律一致，则构建出来的损失函数也将基本一致，至少是全域最小值点将保持一致。

     例如数据集2中，两条数据**规律一致**，都满足$y=2x$这一基本规律。

     $$MSELoss(w)_1 = (2-w)^2$$

     $$MSELoss(w)_2 = (4-2w)^2 = 4(2-w)^2$$

     而这两个损失函数，尽管看起来系数差距成一定比例，但这种差异其实并不影响实际梯度下降的计算过程，上述$MSELoss_1$和$MSELoss_2$的比例差距完全可以通过在迭代过程中调整学习率来确保最终参数迭代过程完全一致

3.   **局部规律与整体规律不一定一致**

     我们将训练数据集所表现出来的规律称为训练数据的整体规律，而单独某条或者某几条数据所表现出来的规律称为局部规律。

     对于数据集1来说，第一条数据所表现出的局部规律和整个数据集所表现出来的规律并不一致，而对于数据集2来说，第一条数据、第二条数据和整个数据集表现出来的规律都一致

4.   **局部规律和整体规律的相对统一**

     尽管局部规律和整体规律并不一致，但局部规律和整体规律却是相对统一的。例如，我们还是以数据集1为例，并且以前两条数据构造第一个损失函数$Loss_2$、后两条数据构造另一个损失函数$Loss_3$、所有数据构造损失函数$Loss_4$

     $$ \begin{aligned} Loss_2& = \frac{(2-1w)^2 + (5-3w)^2}{2} \\& = \frac{w^2-4w+4+9w^2-30w+25}{2} \\& = \frac{10w^2-34w+29}{2}  \end{aligned} $$

     $$ \begin{aligned} Loss_3& = \frac{(4-6w)^2 + (3-8w)^2}{2} \\& = \frac{36w^2-48w+16+64w^2-48w+9}{2} \\& = \frac{100w^2-96w+25}{2}  \end{aligned} $$

     $$Loss_4(w) =\frac{110w^2-100w+54}{4}=\frac{Loss_2 + Loss_3}{2}$$

     整体损失函数其实就是上述二者的平均值。即代表**局部规律的损失函数其实也能够部分表示整体损失函数**。一种更加严谨的表述是，局部规律的损失函数平均来说是整体损失函数的一个良好的估计。

**小结**：

1.   数据规律可以用损失函数表示，损失函数形态不同代表其背后构造损失函数的数据规律不同；
2.   一般来说，对于一个数据集来说，局部规律之间和局部规律与整体规律之间就存在一定的差异，但也存在一定的统一性；
3.   利用局部规律之间的“对立统一”的特性，我们就能够在参数移动过程中改变参数移动方向，从而避免局部最小值或者鞍点陷阱。

##### 5.3.2  SGD逃脱LoaclMinimum和SaddlePoint

>   SGD的计算本质是借助局部规律（而不是整体规律）来更新参数，而局部规律不一致性能够让参数在移动过程中保持灵活的移动方向，并因此能够逃离局部最小值点或鞍点陷阱，但方向不一致的代价是最终无法收敛到一个稳定的点。

BGD梯度下降过程中每一次参数移动都是基于整体规律（全部数据集对应的损失函数）来进行每一次参数迭代，而无论是随机梯度下降SGD（Stochastic Gradient Descent）还是小批量梯度下降（Mini-batch Gradient Descent），其实都是在利用局部规律（部分数据的损失函数）来进行每一次参数迭代，其中随机梯度下降每次参数迭代都挑选一条数据来构建损失函数，而小批量梯度下降则每次选择一个小批数据（训练数据集的子集）来进行迭代。

但如何通过这种方法来优化梯度下降过程，并使得其能够**跳出局部最小值点**呢？在这个过程中**局部规律的不一致性**又是如何发挥作用的？

数据集：

| Index |  x   |  y   |
| :---: | :--: | :--: |
|   1   |  1   |  2   |
|   2   |  3   |  5   |

第一条数据：$$Loss_1(w) = (2-w)^2$$

第二条数据：$Loss_2(w)=(5-3w)^2$

随机梯度下降尽管有效，但其实无法像批量梯度下降一样收敛至全域最优解，随机梯度下降只能收敛到全域最小值点附近。

1.   迭代结果**震荡**特性

     尽管从执行流程上来看，SGD只是将梯度下降的“每次带入全部数据进行计算”改成了“每次带入一条数据进行计算”，但实际上，这么做会极大程度影响参数每一次移动的方向，从而使得参数最终无法收敛至全域最优解，但同时这么一来却也使得参数迭代过程能够跨越局部最小值点。

     第一次迭代，朝向$w=2$这个点前进的。第二次迭代时，朝着$\frac{5}{3}=1.667$前进，且全域最小值点就位于1.667和2之间。

     因此，在实际迭代过程中，当参数点小于1.667或大于2时，无论是遵照哪一条数据的损失函数进行梯度下降，都能朝向全域最小值点前进。但当参数点迭代至1.667和2之间时，这时参数的迭代就会陷入“进退两难”的境地，当带入第一条数据进行梯度下降时，算法执行过程会要求参数点往前走，走到2这个点；而如果带入第二条数据进行梯度下降时，算法执行过程会要求参数点往后退，退到1.667这个点。

2.   **震荡能逃离局部最小值点**

     合理推测，就将有可能出现一种情况，那就是整体损失函数存在局部最小值，但某条数据在该点的梯度不为0。那么，当参数迭代至全域局部最小值点时正好带入该条数据进行梯度下降，由于该条数据在该点梯度不为0，因此参数就将顺利跨过局部最小值点。

     例如，现在全部训练数据的损失函数为$y=x\cdot cos(\pi x)$，而某条数据的损失函数为$y=(x-0.7)^2$，则当参数在0.35附近时，带入该条数据进行梯度下降时就能顺利跨过0.35局部最小值点。

3.   **震荡导致损失函数波动**

     这种参数迭代方向的不确定性的另一方面影响，就是容易会造成整体损失函数在收敛过程不断波动。只要参数的行进方向不是和全部数据的损失函数的梯度递减方向保持一致，只要参数在中途发生方向的调整，就会导致由全部数据构造的损失函数计算结果的震荡。

#### 5.4  小批量梯度下降

>   希望借助局部规律的不确定性来规避局部最⼩值陷阱的同时，也希望⼀定程度减少随机性所带来的麻烦。

随机梯度下降的计算过程还是“过于”随机了，在很多复杂模型中，这种随机性所造成的迭代收敛上的麻烦几乎和这种随机性所带来的益处不相上下，比如迭代需要更多次数、最终收敛结果不稳定等等，要对其进行改善，我们能够想到的一个最为基础的办法就是在确保一定程度随机性的基础上增加一些算法的稳定性。即尝试适度修正每次迭代所带入的样本量，也就是合理设置每次迭代参数所带入的数据量，一方面我们还是希望**借助局部规律的不确定性来规避局部最小值陷阱**，同时我们**也希望一定程度控制住迭代过程随机性**，来减少随机性所带来的麻烦。而这种每次迭代过程带入若干条样本的梯度下降算法，就被称为小批量梯度下降。

所谓小批量梯度下降，其实就是对随机梯度下降过程稍作修改：每次不在是带入一条数据进行计算，而是带入batch_size条数据进行计算，当然batch_size是一个人工设置的超参数。

尽管小批量梯度下降每次带入了更多的数据进行参数训练，但其算法特性和随机梯度下降还是比较类似的，在训练阶段，每次训练实际上是利用某批数据的综合规律（综合损失函数）来进行参数训练，同时，小批量梯度下降也是借助不同批次数据的规律不一致性帮助参数跳出局部最小值陷阱，并且，由于规律不一致性，小批量梯度下降最终收敛结果也会呈现小幅震荡，只不过在所有的“随机不确定性”的方面，小批量梯度下降都比随机梯度下降显得更加稳健。

#### 5.5  梯度下降收敛过程优化

>   要真正帮助随机梯度下降和小批量梯度下降解决随机性所造成的“麻烦”，就必须采用一些围绕迭代过程的优化方法，而所有的围绕迭代过程的优化方法中，最基础也是最通用的两种方法，分别是**数据归一化**方法和**学习率调度**。

在引入了一定的样本随机性之后，能够帮助参数点跨越局部最小值点。但在引入随机性提升算法性能的时候也将面临随机性本身所造成的麻烦。如随机梯度下降会伴随着收敛过程不稳定、收敛结果持续震荡等问题。很明显通过增加每次迭代的样本数量来减少随机性进而缓解上述问题并不是长久之计。

##### 5.5.1  数据归一化

数据归一化方法的本质是一种对数据进行**线性转换**的方法，通过构建一种样本空间之间的线性映射关系来进行数据数值的转化，这种转化并**不会影响数据分布**，即不会影响数据的内在规律，只是对数据的数值进行调整。

一般来说，归一化和标准化都是指对数据进行数值转化，根据维基百科的解释，都是Feature scaling(特征缩放)的方法，并且都可以称为normalization。但某些场景下也会有不同的称呼，例如将0-1标准化称为normalization，也就是归一化，而把Z-Score标准化称为Standardization，即标准化。

1.   **0-1归一化**：$${x}_{normalization}=\frac{x-Min}{Max-Min}$$

2.   **Z-Score标准化**：$${x}_{normalization}=\frac{x-\mu }{\sigma }$$。

     如果原数据服从正态分布，处理之后的数据服从标准正态分布。Z-Score的使用场景要远高于0-1标准化使用场景。

     -   生成Zero-Centered Data

         Z-Score标准化并不会将数据放缩在0-1之间，⽽是均匀地分布在0的两侧。类似这种数据也被称为Zero-Centered Data。

     -   标准正态分布。

         如果原始数据满足正态分布，则经过Z-Score转化之后就能转化为标准正态分布，进而可以利用标准正态分布诸多统计性质。

     -   保留极端值分布

         相比0-1标准化，Z-Score标准化能够保留极端值的分布。由于极端值的存在，MinMax会将其他数值压缩在一个非常小的范围内。

3.   **非线性标准化**：利用Sigmoid函数对数据集的每一列进行处理，由于Sigmoid函数特性，处理之后的数据也将被压缩到0-1之间。`1 / (1 + np.exp(-x))`

##### 5.5.2  归一化的评价

1.   首先，并非所有模型都受到数据各列的绝对数值大小影响。

     在通用的模型中，**线性模型和距离类模型**是两类典型的会受到各列绝对数值大小影响的模型，例如线性回归、KNN、K-Means（一种无监督的聚类模型）等，并且逻辑回归在使用ECOC编码进行类别判别时也是利用距离来判别样本最终归属，此时，由于各列的绝对数值会影响模型学习的偏重，模型会更加侧重于学习那些数值比较大的列，而无法“均匀”的从各列中提取有效信息，因此有时会出现较差的模型结果。但有些模型却不受此影响，典型的如树模型。

2.   一旦对数据进行归一化处理，数据就失去了量纲，也就是将**失去可解释性**。

3.   归一化方法属于仿射变换的一种特殊形式，而所有的仿射变换其实都不会影响数据集原始分布，也就是并**不影响数据集真实规律**，只会影响某些算法挖掘规律的难度（也就是受到特征绝对数值影响的算法）。

     >   仿射变换指的是样本空间平移（加减某个数）和放缩（乘除某个数）的变换。
     >
     >   0-1标准化过程中，平移就是减去每⼀列最⼩值，放缩就是除以某⼀列的极差。

4.   对于梯度下降算法来说，归一化**能够提高收敛速度**。

     从理论角度出发，其实梯度下降过程每一步参数点移动的方向是能够让梯度最快速下降的方向，也就是图片上垂直于等高线的方向。但这种所谓的最快速的方向只在开始移动的一瞬间满足，由于梯度是连续变化的函数，因此当移动了一小步之后“最优方向”其实就可能发生了变化，但参数只能在下次移动时再改变方向，因此中间其实很长一段距离参数并不不一定是沿着最优方向在进行移动。这里需要注意，如果下一次移动的方向和上一次移动方向一致或者类似，那就说明这次移动过程中参数并没有偏离方向太多，反之则这次移动走了很多弯路。而当损失函数的等高线是均匀分布时，外圈的垂直线也就是内圈的垂直线，此时参数两次移动过程大概率最优方向一致，也就是说相同的移动能够更大程度降低损失函数值

     从等高线图上来看是**等高线变得更加均匀**，但实际上是整个损失函数在不同区域对应梯度都更加均匀，从而在靠近最小值点附近的梯度也比归一化之前的损失函数梯度要大，也就是说，虽然学习率相同，但由于**归一化之后最小值点附近梯度要更大**，因此同样的迭代次，在归一化之后的损失函数上参数点将移动至更加靠近最小值地附近的点。学习率相同，迭代次数相同，但经过归一化的损失函数更加陡峭，靠近最小值点附近梯度更大，因此最终收敛到一个更加靠近最小值点附近的点。

##### 5.5.3  学习率调度

梯度下降优化的核心目标就是希望“更快更好”的找到最小值点，归一化是通过修改损失函数来达成这个目标，而所谓学习率调度，则是通过**调整学习率**来达到这个目标。

此时找到一个确定的最优学习率并不是目标，“更快更好”找到最小值点才是目标，因此我们完全可以考虑在迭代过程动态调整学习率。而所谓学习率调度，也并不是一个寻找最佳学习率的方法，而是一种伴随迭代进行、**不断调整学习率**的策略。

一种最为通用的学习率调度方法是学习率衰减法，指的是在迭代**开始时设置较大**学习率，而伴随着迭代进行**不断减小**学习率。通过这样的学习率设置，能够让梯度下降收敛速度更快、效果更好。

1.   在很多海量数据处理场景下，学习率调度的重大价值在于能够提供对学习率超参数设置更大的容错空间。在很多情况下，搜索出一个最佳学习率取值进而设置恒定学习率进行梯度下降，难度会远高于设置一组学习率衰减的参数。并且有的时候，刚开始学习率设置过大其实也可以通过多轮迭代进行调整，其所消耗的算力也远低于反复训练模型寻找最佳恒定学习率。
2.   更为一般的情况是**学习率调度和小批量梯度下降或者随机梯度下降来配合使用**。

#### 5.6  交叉熵损失函数的梯度表达式

假设数据集是m行n列的一个数据集，则二分类交叉熵损失函数如下：$$binaryCE(\hat w)= -\frac{1}{m}\sum^m_{i=1}[y^{(i)} \cdot log(p_1(\hat x^{(i)};\hat w))+(1-y^{(i)}) \cdot log(1-p_1(\hat x^{(i)};\hat w))]$$

其中n为样本数量，$\hat x^{(i)}$为第i条样本（添加了最后全是1的列），$\hat w$为带截距项的线性方程系数向量，$p_1$为某条样本在当前参数下逻辑回归输出结果，即预测该样本为1的概率，$y^{(i)}$为第$i$条样本的真实类别。对于上述BCE损失函数，梯度表达式为：$$\nabla _{\hat w} BCE(\hat w) = \frac{\partial BCE(\hat w)}{\partial \hat w}$$

其中$\hat w=[w_1, w_2, w_3, ..., w_n, b]$​，因此上式可进一步展开：$$\nabla _{\hat w} BCE(\hat w) = \frac{\partial BCE(\hat w)}{\partial \hat w}= [\frac{\partial BCE(\hat w)}{\partial w_1}, \frac{\partial BCE(\hat w)}{\partial w_2}, ...,\frac{\partial BCE(\hat w)}{\partial w_n}, \frac{\partial BCE(\hat w)}{\partial b}]^T$$

对带入某条数据后的$w_i$进行求导：$$log(p_1(\hat x^{(i)}; \hat w))' = log(Sigmoid(\hat x^{(i)} \cdot \hat w))'=\frac{1}{Sigmoid(\hat x^{(i)} \cdot \hat w)} \cdot Sigmoid'(\hat x^{(i)} \cdot \hat w)$$

对于Sigmoid函数来说，有$Sigmoid'(x) = Sigmoid(x)(1-Sigmoid(x))$​，因此$$log(p_1(\hat x^{(i)}; \hat w))' = (1-Sigmoid(\hat x^{(i)} \cdot \hat w)) \cdot (\hat x^{(i)} \cdot \hat w)'$$

其中$\hat x^{(i)} \cdot \hat w=w_1x_1^{(i)}+w_2x_2^{(i)}+...+w_nx_n^{(i)}+b$，对$w_i$求导可得：$$(\hat x^{(i)} \cdot \hat w)' = x_i^{(i)}$$，对截距$b$​求导可得：$$(\hat x^{(i)} \cdot \hat w)' = 1$$

因此，在$log(p_1(\hat x^{(i)}; \hat w))$中，对$w_i$求导可得:$$log(p_1(\hat x^{(i)}; \hat w))' = (1-Sigmoid(\hat x^{(i)} \cdot \hat w)) \cdot x_i^{(i)}$$，对$b$求导可得:$$log(p_1(\hat x^{(i)}; \hat w))' = (1-Sigmoid(\hat x^{(i)} \cdot \hat w)) \cdot 1$$

类似的，在$(1-y^{(i)}) \cdot log(1-p_1(\hat x^{(i)};\hat w))$中，对$w_i$​求导可得：$$\begin{aligned}(1-y^{(i)}) \cdot log'(1-p_1(\hat x^{(i)};\hat w)) & = (1-y^{(i)}) \cdot log'(1-Sigmoid(\hat x^{(i)} \cdot \hat w)) \\&=(1-y^{(i)}) \cdot \frac{1}{(1-Sigmoid(\hat x^{(i)} \cdot \hat w))} \cdot (-Sigmoid'(\hat x^{(i)} \cdot \hat w))\\& = (1-y^{(i)}) \cdot (-Sigmoid(\hat x^{(i)} \cdot \hat w)) \cdot (\hat x^{(i)} \cdot \hat w)' \\&=(1-y^{(i)}) \cdot (-Sigmoid(\hat x^{(i)} \cdot \hat w)) \cdot x_i^{(i)}\end{aligned}$$

对$b$求导可得:$$(1-y^{(i)}) \cdot log'(1-p_1(\hat x^{(i)};\hat w))= (1-y^{(i)}) \cdot (-Sigmoid(\hat x^{(i)} \cdot \hat w)) \cdot 1$$

将上述结果带入$\frac{\partial BCE(\hat w)}{\partial w_i}$，当对$w_i$​进行求导时：$$\begin{aligned}\frac{\partial BCE(\hat w)}{\partial w_i} &= (-\frac{1}{m}\sum^m_{i=1}[y^{(i)} \cdot log(p_1(\hat x^{(i)};\hat w))+(1-y^{(i)}) \cdot log(1-p_1(\hat x^{(i)};\hat w))])' \\&=-\frac{1}{m}\sum^m_{i=1}[y^{(i)} \cdot log'(p_1(\hat x^{(i)};\hat w))+(1-y^{(i)}) \cdot log'(1-p_1(\hat x^{(i)};\hat w))] \\&=-\frac{1}{m}\sum^m_{i=1}[y^{(i)} \cdot (1-Sigmoid(\hat x^{(i)} \cdot \hat w)) \cdot x_i^{(i)} + (1-y^{(i)}) \cdot (-Sigmoid(\hat x^{(i)} \cdot \hat w)) \cdot x_i^{(i)})] \\&=-\frac{1}{m}\sum^m_{i=1}[x_i^{(i)}y^{(i)}-x_i^{(i)}y^{(i)}Sigmoid(\hat x^{(i)} \cdot \hat w) - x_i^{(i)}Sigmoid(\hat x^{(i)} \cdot \hat w)+x_i^{(i)}y^{(i)}Sigmoid(\hat x^{(i)} \cdot \hat w)] \\&=\frac{1}{m}\sum^m_{i=1}(x_i^{(i)}(Sigmoid(\hat x^{(i)} \cdot \hat w)-y^{(i)})) \\&=\frac{1}{m}\sum^m_{i=1}(x_i^{(i)}(\hat y^{(i)}-y^{(i)}))\end{aligned}$$

对截距项b进行求导时：$$\frac{\partial BCE(\hat w)}{\partial b} = \frac{1}{m}\sum^m_{i=1}1 \cdot (\hat y^{(i)}-y^{(i)})$$

根据定义，$x^{(i)}=[x_1^{(i)}, x_2^{(i)}, ..., x_n^{(i)}, 1]$，$x^{(i)}_{n+1}=1$，1就是$x^{(i)}$的第$n+1$个分量

$$\begin{aligned}\nabla _{\hat w} BCE(\hat w) &= \frac{\partial BCE(\hat w)}{\partial \hat w}\\& =\left [\begin{array}{cccc}\frac{\partial BCE(\hat w)}{\partial w_1} \\\frac{\partial BCE(\hat w)}{\partial w_2} \\. \\. \\. \\\frac{\partial BCE(\hat w)}{\partial w_n} \\\frac{\partial BCE(\hat w)}{\partial b} \\\end{array}\right] \\& =\left [\begin{array}{cccc}\frac{1}{m}\sum^m_{i=1}(x_1^{(i)}(Sigmoid(\hat x^{(i)} \cdot \hat w)-y^{(i)})) \\\frac{1}{m}\sum^m_{i=1}(x_2^{(i)}(Sigmoid(\hat x^{(i)} \cdot \hat w)-y^{(i)})) \\. \\. \\. \\\frac{1}{m}\sum^m_{i=1}(x_n^{(i)}(Sigmoid(\hat x^{(i)} \cdot \hat w)-y^{(i)})) \\\frac{1}{m}\sum^m_{i=1}(1 \cdot (Sigmoid(\hat x^{(i)} \cdot \hat w)-y^{(i)})) \\\end{array}\right] \\&= \frac{1}{m} \left [\begin{array}{cccc}\sum^m_{i=1}x_1^{(i)}Sigmoid(\hat x^{(i)} \cdot \hat w)-\sum^m_{i=1}x_1^{(i)}y^{(i)} \\\sum^m_{i=1}x_2^{(i)}Sigmoid(\hat x^{(i)} \cdot \hat w)-\sum^m_{i=1}x_2^{(i)}y^{(i)} \\. \\. \\. \\\sum^m_{i=1}x_n^{(i)}Sigmoid(\hat x^{(i)} \cdot \hat w)-\sum^m_{i=1}x_n^{(i)}y^{(i)} \\\sum^m_{i=1}Sigmoid(\hat x^{(i)} \cdot \hat w)-\sum^m_{i=1}y^{(i)} \\\end{array}\right]\\\end{aligned}$$

我们令$X$为添加最后一列全是1的特征矩阵，$y$是标签数组：

$$\begin{aligned}\hat X &= [x^{(1)}, x^{(2)}, ..., x^{(m)}]^T\\& =\left [\begin{array}{cccc}x^{(1)}_1, x^{(1)}_2, ... ,x^{(1)}_n, 1 \\x^{(2)}_1, x^{(2)}_2, ... ,x^{(2)}_n, 1 \\. \\. \\. \\x^{(m)}_1, x^{(m)}_2, ... ,x^{(m)}_n, 1 \\\end{array}\right] \\\end{aligned}$$

$$y = [y^{(1)}, y^{(2)}, ..., y^{(m)}]^T$$

则上式前半部分可简化为：$$\begin{aligned}\left [\begin{array}{cccc}\sum^m_{i=1}x_1^{(i)}Sigmoid(\hat x^{(i)} \cdot \hat w) \\\sum^m_{i=1}x_2^{(i)}Sigmoid(\hat x^{(i)} \cdot \hat w) \\. \\. \\. \\\sum^m_{i=1}x_n^{(i)}Sigmoid(\hat x^{(i)} \cdot \hat w) \\\sum^m_{i=1}Sigmoid(\hat x^{(i)} \cdot \hat w) \\\end{array}\right] &=\left [\begin{array}{cccc}x^{(1)}_1, x^{(2)}_1, ... ,x^{(m)}_1 \\x^{(1)}_2, x^{(2)}_2, ... ,x^{(m)}_2 \\. \\. \\. \\x^{(1)}_m, x^{(2)}_m, ... ,x^{(m)}_m \\1, 1, ... ,1, 1 \\\end{array}\right] \cdot\left [\begin{array}{cccc}Sigmoid(\hat x^{(1)} \cdot \hat w) \\Sigmoid(\hat x^{(2)} \cdot \hat w) \\. \\. \\. \\Sigmoid(\hat x^{(m)} \cdot \hat w) \\\end{array}\right] \\&=\left [\begin{array}{cccc}x^{(1)}_1, x^{(1)}_2, ... ,x^{(1)}_n, 1 \\x^{(2)}_1, x^{(2)}_2, ... ,x^{(2)}_n, 1 \\. \\. \\. \\x^{(m)}_1, x^{(m)}_2, ... ,x^{(m)}_n, 1 \\\end{array}\right]^T \cdot Sigmoid(\left [\begin{array}{cccc}x^{(1)}_1, x^{(1)}_2, ... ,x^{(1)}_n, 1 \\x^{(2)}_1, x^{(2)}_2, ... ,x^{(2)}_n, 1 \\. \\. \\. \\x^{(m)}_1, x^{(m)}_2, ... ,x^{(m)}_n, 1 \\\end{array}\right] \cdot \left [\begin{array}{cccc}w_1 \\w_2 \\. \\. \\. \\w_n \\b \\\end{array}\right]) \\&= \hat X^T Sigmoid(\hat X \cdot \hat w)\end{aligned}$$

后半部分可简化为：$$\begin{aligned}\left [\begin{array}{cccc}\sum^m_{i=1}x_1^{(i)}y^{(i)} \\\sum^m_{i=1}x_2^{(i)}y^{(i)} \\. \\. \\. \\\sum^m_{i=1}x_n^{(i)}y^{(i)} \\\sum^m_{i=1}y^{(i)} \\\end{array}\right] = \left [\begin{array}{cccc}x^{(1)}_1, x^{(1)}_2, ... ,x^{(1)}_n, 1 \\x^{(2)}_1, x^{(2)}_2, ... ,x^{(2)}_n, 1 \\. \\. \\. \\x^{(m)}_1, x^{(m)}_2, ... ,x^{(m)}_n, 1 \\\end{array}\right]^T \cdot \left [\begin{array}{cccc}y^{(1)} \\y^{(2)} \\. \\. \\. \\y^{(m)} \\\end{array}\right]=\hat X^T \cdot y\end{aligned}$$

因此，逻辑回归损失函数的梯度计算公式为：$$\nabla _{\hat w} BCE(\hat w)=\frac{1}{m}\hat X^T(Sigmoid(\hat X \cdot \hat w) - y)$$

```python
def logit_gd(X, w, y):
    """
    逻辑回归梯度计算公式
    """
    m = X.shape[0]
    grad = X.T.dot(sigmoid(X.dot(w)) - y) / m
    return grad
```

<div style="page-break-after:always"></div>

------

### 第6章  模型评估指标

#### 6.1  准确率

>   最为通用、同时也是较好理解的评估指标。

|index|labels|A-predicts|B-predicts|predicts_results|      
|:--:|:--:|:--:|:--:|:--:|   
|1|1|0.8|0.6|1|      
|2|0|0.6|0.9|1|
|3|0|0.2|0.4|0|
|4|1|0.9|0.7|1|
|5|1|0.9|0.6|1|

1.   对于某些样本**极端不平衡的分类数据集**来说准确率**很难很好的衡量模型表现**。在计算过程中，所有样本其实是“均匀投票”的，也就是说对每个样本的判别结果，对于最终准确率的影响其实是相同的。例如假设总共有100条数据进行分类，其中任意一条样本被误判都会且仅会影响1%的准确率。假设总共有100样本，其中0类有99条，1类有1条，则此时就算模型判别此100条样本全都为0类，准确率也将达到99%，但很多时候可能我们希望的是模型能够将这些1识别出来，例如癌症病患数据中癌症患者、金融风控中欺诈用户等。

2.   对于哪怕是均衡的分类样本数据集，准确率有时也**无法很好的衡量分类模型的分类性能**，尤其是模型本身的泛化能力，这也是为什么我们不以准确率而以交叉熵作为损失函数的另一个原因。

     从准确率指标来看，两个模型在阈值为0.5的情况下，判别准确率都是80%（仅判错第二条样本），二者并无高下之分。但如果我们更加仔细的观察模型对各样本输出的概率欧安别结果，其实我们会发现模型A其实会更加“优秀”：首先，对于判断正确的1类数据，模型A输出的概率预测分别为0.8、0.9和0.9，表示模型非常肯定这些样本应该属于1类，而模型B的概率预测结果为0.6、0.7、0.6，表示模型并不是特别肯定这样样本属于1类，类似的情况也出现在两个模型正确识别0类的判别过程中。此外，对于误判的样本，虽然两个模型都将原本属于0类的2号样本误判为1，但模型B给出的概率结果是0.9，代表其非常肯定该样本应该属于1类，而模型A输出的概率结果为0.6，表示其并不是非常肯定该样本属于1类。在实际建模过程中，类似A模型的模型，即对判断正确的样本有较高的肯定、对判断错误的样本不太肯定，这类模型其实是更加准确的捕捉到了数据规律，在后续对于新数据集预测时，也将拥有更强的泛化能力。但遗憾的是，准确率评估指标并无法很好的将A类模型和B类模型的模型判别能力进行准确区分。

#### 6.2  交叉熵

>   既然能够通过交叉熵观察模型判别能力，那为何我们不选取交叉熵作为模型评估指标？

此时我们可以通过交叉熵来比较两个模型的好坏优劣。我们知道，交叉熵计算结果越小、模型本身判别能力越强。$$BCE_A = \frac{-log_2(0.8)-log_2(0.4)-log_2(-0.8)-log_2(0.9)-log_2(0.9)}{5}$$，$$BCE_B = \frac{-log_2(0.6)-log_2(0.1)-log_2(-0.6)-log_2(0.7)-log_2(0.6)}{5}$$。

交叉熵的主要功能还是作为指导模型进行参数求解的损失函数。

1.   交叉熵的**取值并不在一个固定的区间范围内，很难进行横向对比**。交叉熵=相对熵+信息熵，由于相对熵大于等于0的特性，所以交叉熵实际上是在\[信息熵, +∞)内取值，而不在一个固定区间内取值就导致交叉熵数值很难进行不同模型、数据之间的横向对比。
2.   尽管在建模的时候我们是通过梯度下降求解交叉熵损失函数的最小值，此时我们希望交叉熵的值越小越好，但其实有的时候，**一味追求交叉熵更小的值也有可能导致模型过拟合**，因此实际上交叉熵的值也不是越小越好，此时甚至会需要结合准确率来综合调参，寻找一个准确率较高、但交叉熵不是特别小的模型，来削弱过拟合倾向。

#### 6.3  混淆矩阵

-   Actual condition positive（P）：样本中阳性样本总数，一般也就是真实标签为1的样本总数；

-   Actual condition negative（N）：样本中阴性样本总数，一般也就是真实标签为0的样本总数；

-   Predicted condition positive（PP）：预测中阳性样本总数，一般也就是预测标签为1的样本总数；

-   Predicted condition negative（PN）：预测中阳性样本总数，一般也就是预测标签为0的样本总数；

-   True positive（TP）：样本属于阳性（类别1）、并且被正确识别为阳性（类别1）的样本总数；TP发生时也被称为正确命中(hit)

-   True negative（TN）：样本属于阴性（类别0）、并且被正确识别为阴性（类别0）的样本总数；TN发生时也被称为正确拒绝（correct rejection）；

-   False positive（FP）：样本属于阴性（类别0），但被错误判别为阳性（类别1）的样本总数；FP发生时也被称为发生I类了错误（Type I error），或者假警报（False alarm）、低估（underestimation）等；

-   False negative（FN）：样本属于阳性（类别1），但被错误判别为阴性（类别0）的样本总数；FN发生时也被称为发生了II类错误（Type II error），或者称为错过目标（miss）、高估（overestimation）等；

<img src="https://cdn.jsdelivr.net/gh/louisyanglu/images/images/tqu1naCcVKNW5Mv.jpg" alt="87" style="zoom:0%;" />

#### 6.4  围绕识别类别1所构建的评估指标

>   1.   只需要考虑1类别的识别率：Recall；
>   2.   只需考虑对1样本判别结果中的准确率：Precision；
>   3.   重点识别1类但也要兼顾0类的准确率：F1-Score；

1.   **准确率**：$ACC=\frac{TP+TN}{TP+TN+FP+FN}$

2.   **召回率**：$$Recall = \frac{TP}{TP+FN}$$

     sensitivity（敏感度）、hit rate（命中率）、true positive rate (**TPR**)以及**查全率**（有多少真实正样本被预测出来）

     以召回率作为模型评估指标，则会使得模型非常重视是否把1全部识别了出来，甚至是牺牲掉一些0类样本判别的准确率来提升召回率，即哪怕是错判一些0样本为1类样本，也要将1类样本识别出来，这是一种“宁可错杀一千不可放过一个”的判别思路。在偏态数据中，相比准确率，召回率对于1类样本能否被正确识别的敏感度要远高于准确率，但对于是否牺牲了0类别的准确率却无法直接体现。

3.   **精确度**：$$Precision = \frac{TP}{TP+FP}$$

     **查准率**（预测为正有多少真实正）

     更加关注每一次出手（对1类样本的识别）能否成功（准确识别出1）的概率

     这种对正样本力求**每次出手都尽可能成功**的策略，使得当我们在以精确度作为模型判别指标时，模型整体对1的判别会**趋于保守**，**只对那些大概率确定为1的样本进行1类的判别**，从而会一定程度牺牲1类样本的准确率

4.   **F1-Score**：$$F1-Score = \frac{2}{\frac{1}{Recall}+\frac{1}{Precision}}=\frac{2 \cdot Recall \cdot Precision}{Recall+Precision}$$

     在围绕1类样本的识别过程中，召回率力求尽可能更多的将1识别出来，而精确度则力求每次对1样本的判别都能获得一个正确的结果

     我们既不希望模型太过于激进、也不希望模型太过于保守，并且对于偏态样本，既可以较好的衡量1类样本是否被识别，同时也能够兼顾考虑到0类样本的准确率牺牲程度，此时，我们可以考虑使用二者的调和平均数（harmonic mean）作为模型评估指标，即F1-Score。相比平均数(balanced accuracy，简称BA)，$$BA = \frac{Recall+Precision}{2}$$，调和平均数其实会更大程度上受到短板数据的影响。即只要参与计算的Recall和Precision其中一个指标较小，F1-Score指标就会整体偏小，而当F1-Score结果较大时，则说明模型整体分类性能较强，并且哪怕是极端不平衡数据，只要F1-Score计算结果较大，就说明模型对少数类别样本也具有很好的分类性能，从这个角度来说，F1-Score是个比ACC更全面的评估指标

     F1-Score并不是类别对称的，也就是说，如果我们将0类和1类数据标签互换，最终算得的F1-Socre结果会有所不同。因此其实F1-Score虽然是一个更加均衡的评估指标，但其实也只是均衡了在识别1类样本时“激进”或者“保守”的倾向性，但本质上还是一个**围绕模型对1类样本识别能力**所构建的评估指标。

5.   $F_\beta$：一种更为一般的、可以自主调整召回率和精确度在参与调和平均数计算过程中的权重的评估指标。

     $$F_\beta=(1+\beta ^2)\frac{precision \cdot recall}{(\beta ^2 \cdot precision)+recall}$$

#### 6.5  围绕识别类别0所构建的评估指标

1.   **阴性预测值**（negative predictive value）：$$NPV = \frac{TN}{TN+FN}$$

     一个相对保守评估指标，类似于Precision（**预测为0的样本中有多少是真实0**）；

2.   **特异度**：$$Specificity = \frac{TN}{TN+FP}$$

     衡量0类被正确识别比例的特异度，该指标类似召回率，都是较为激进的评估指标，只考虑关注的类（0类或者1类）被识别出来的比例，而不考虑在识别过程中是否牺牲了另外一类的准确率。

3.   **伪阳率**（false positive rate）：$$FPR = 1-specificity=\frac{FP}{FP+TN}$$

     **在所有真实为0的样本中，被预测为1的样本所占比例**。

#### 6.6  ROC、AUC

>   如果数据集的**各类别并没有明确的差异**，在算力允许的情况下，应当**优先考虑roc-auc**；而如果希望**重点提升模型对类别1（或者某类别）的识别能力**，则可以**优先考虑f1-score**作为模型评估指标。

1.   由于FPR和TPR都是在[0,1]区间范围内取值，因此ROC曲线上的点分布在横纵坐标都在[0,1]范围内的二维平面区间内。

2.   ROC曲线越靠近左上方、ROC曲线下方面积越大，则模型分类性能越好。

     根据点的移动轨迹构成ROC曲线角度来理解，刚开始移动时，是朝向X还是Y轴正向移动，其实是由模型输出概率最高的几个样本决定的，如果这几个样本被判别错了（即实际样本类别为0），则刚开始从原点移动就将朝着X轴正方向移动，此时曲线下方面积会相对更小（相比刚开始朝着Y轴正方向移动的情况）。此时由于模型对于“非常肯定”的样本都判错了，证明模型本身判别性能欠佳；而反之，如果输出概率最高的头部几条样本都判断正确，样本真实类别确实属于1，则点开始移动时将朝向Y轴正方向移动，此时曲线下方面积就将相对更大，模型判别性能也将相对较好

3.   ROC**概率敏感**。如果数据是偏态数据，由于ROC是对概率敏感的判别曲线（根据概率结果而非类别判别结果进行识别），因此ROC能够对模型对于偏态数据中少量样本的识别能力进行评估。

4.   ROC-AUC对于模型在偏态样本上分类能力的评判，其实也会**受到偏态样本“偏态”程度的影响**。例如A、B两个模型对唯一的一个1类样本判别概率为0.8、0.6的差异情况下，模型AUC值的差异其实会受到剩余0类样本数量的影响，剩余0类样本数量越多、两个模型AUC值的差异越大。正是这种AUC值的差异会被0类样本“稀释”的性质，导致如果我们在利用偏态数据建模时，可以通过减少0类样本的样本量（如欠采样、数据聚类等）来提升1类样本在AUC计算结果时的权重。

5.   ROC**排序敏感**。ROC-AUC其实是对根据模型预测的概率结果降序排序后的数据真实标签的各元素位置敏感，例如，对于下述A、B两个模型，尽管在部分样本的预测概率不同，但由于最终的按照预测概率降序排序的真实标签排序相同，因此两个模型最终绘制的ROC曲线相同。

     <img src="https://cdn.jsdelivr.net/gh/louisyanglu/images/images/5adhxjiLYAJcs1z.jpg" alt="87" style="zoom: 67%;" />

6.   ROC**类别对称性**。F1-Score并不是类别对称的，而是更加侧重于评估模型在识别1类样本时的整体性能，但ROC却是类别对称的，即如果我们将数据中的0和1类互换，而模型原先预测1的类概率就变成了现在预测0类的概率，此时ROC曲线会参照$x+y=1$的直线进行对称变换，但AUC面积不变，即模型性能评估数值仍然不会发生变化。

     <img src="https://cdn.jsdelivr.net/gh/louisyanglu/images/images/k6C9Ryr3pKuxXzT.jpg" alt="87" style="zoom: 60%;" /><img src="https://cdn.jsdelivr.net/gh/louisyanglu/images/images/auc对称性.png" alt="87"  />

     二者的AUC计算结果都是$1-0.5*(1-0.66)=0.83$，而这也正是由于两个ROC曲线围绕$x+y=1$对称所导致的。

#### 6.7  多分类混淆矩阵

<img src="https://cdn.jsdelivr.net/gh/louisyanglu/images/images/pVEc5CvLzq2dFy8.jpg" alt="87" style="zoom:50%;" />

采用OVR策略进行“划分”、然后采用均值策略进行“集成”：

-   $$Recall_A = \frac{6}{6+2+2} = 0.6$$
-   $$Recall_B = \frac{3}{3+1+3} = \frac{3}{7} = 0.42$$
-   $$Recall_C = \frac{2}{2+2+6} = 0.2$$

$$Recall = \frac{0.6+0.42+0.2}{3} = 0.4$$

类似，可以算得$Precision_A = \frac{6}{13} = 0.46$，$Precision_B = \frac{3}{7} = 0.42$，$Precision_C = \frac{2}{7} = 0.28$，随后利用三者均值求出模型整体$Precision=0.38$。

#### 6.8  多分类评估指标

`from sklearn.metrics import precision_score, recall_score, f1_score`

|     Name      |                   Description                    |
| :-----------: | :----------------------------------------------: |
|    y_true     |                  数据集真实标签                  |
|    y_pred     |                   标签预测结果                   |
|    labels     | 允许以列表形式输入其他形态的标签，一般不进行修改 |
|   pos_label   |                 positive类别标签                 |
|    average    |               多分类时指标计算方法               |
| sample_weight |                不同类别的样本权重                |
| zero_division |               当分母为0时返回结果                |

-   `average='macro'`：先计算每个类别的recall，然后求均值
-   `average='weighted'`：根据每个类别的数量进行加权求和
-   `average='micro'`：计算整体的TP和FN，然后根据整体TP和FN计算recall

#### 6.9  多分类ROC、AUC

>   对于roc-auc进行多分类问题评估时，建议选择的参数组合是ovr+macro。

|    Name     |                 Description                  |
| :---------: | :------------------------------------------: |
|   max_fpr   |       fpr最大值，fpr是roc曲线的横坐标        |
| multi_class | 分类器在进行多分类时进行的多分类问题处理策略 |

sklearn中的`multi_class`参数都是二分类器中用于解决多元分类问题时的参数（如逻辑回归），而由于roc-auc需要分类结果中的概率来完成最终计算，因此需要知道概率结果对应分类标签——即到底是以ovo还是ovr模式在进行多分类，因此如果是进行多分类roc-auc计算时，需要对其进行明确说明。

不过对于多分类逻辑回归来说，无论是ovr还是mvm策略，最终分类结果其实都可以看成是ovr分类结果，因此如果是多分类逻辑回归计算roc-auc，需要设置multi_class参数为ovr。同时由于根据roc-auc的函数参数说明可知，在multi_class参数取为ovr时，average参数取值为macro时能够保持一个较高的偏态样本敏感性，因此对于roc-auc来说，大多数时候**average参数建议取值为macro**。

#### 6.10  模型评估

##### 6.10.1  make_scorer

`sorted(sklearn.metrics.SCORERS.keys())`

```python
from sklearn.metrics import make_scorer

make_scorer(score_func, greater_is_better=True)  # score_func(y, y_pred)
```

`score_func`：可调用对象，**评估指标函数**，只需要输入标签的预测值和真实值即可进行计算。

`make_scorer`：将评估指标函数转化为**评估器结果评估函数**，需要同时输入评估器、特征矩阵以及对应的真实标签。其执行过程是先将特征矩阵输入评估器、然后计算预测结果，最后将输出结果和真实标签进行对比。

在网格搜索或者交叉验证评估器中，只支持输入经过`make_scorer`转化后的评估指标函数。

##### 6.10.2  多组评估指标

有的时候我们可能需要同时看不同参数下多项评估指标的结果，此时我们就可以在scoring中输入列表、元组或者字典

`scoring = {'AUC': 'roc_auc', 'Accuracy': make_scorer(accuracy_score)}`

不过，需要注意的是，尽管此时网格搜索评估器将同时计算一组参数下的多个评估指标结果并输出，但我们只能选取其中一个评估指标作为挑选超参数的依据，而其他指标尽管仍然会计算，但结果只作参考。而`refit`参数中输入的评估指标，就是最终选择参数的评估指标。

<div style="page-break-after:always"></div>

------

### 第7章  Scikit-Learn使用

#### 7.1  标准化与归一化

Z-Score标准化和0-1标准化，都属于Standardization的范畴，而在sklearn中，Normalization则特指针对单个样本（一行数据）利用其范数进行放缩的过程。

1.   Z-Score标准化

     -   快速处理：`preprocessing.scale`

     -   评估器实现：`preprocessing.StandardScaler()`

         ```python
         scaler.scale_  # 查看训练数据各列的标准差
         scaler.mean_  # 查看训练数据各列的均值
         scaler.var_  # 查看训练数据各列的方差
         scaler.n_samples_seen_  # 总共有效的训练数据条数
         ```

2.   MinMax标准化

     -   快速处理：`preprocessing.minmax_scale`

     -   评估器实现：`preprocessing.MinMaxScaler()`

         ```python
         scaler.scale_  # (max - min) / (X.max(axis=0) - X.min(axis=0))
         scaler.data_min_  # 最小
         scaler.data_max_  # 最大
         scaler.data_range_  # (data_max_ - data_min_)
         ```

3.   稀疏矩阵标准化`MaxAbsScaler`

4.   存在异常值点特征矩阵的标准化`RobustScaler`

5.   非线性变化的标准化

6.   归一化

     -   快速处理：`preprocessing.normalize`

         假设向量$x = [x_1, x_2, ..., x_n]^T$，则向量x的1-范数的基本计算公式为：$$||x||_1 = |x_1|+|x_2|+...+|x_n|$$

         而向量x的2-范数计算公式为：$$||x||_2=\sqrt{(|x_1|^2+|x_2|^2+...+|x_n|^2)}$$

         sklearn中的Normalization过程，实际上就是将每一行数据视作一个向量，然后用每一行数据去除以该行数据的1-范数或者2-范数。

     -   评估器实现：`preprocessing.Normalizer`

#### 7.2  正则化

##### 7.2.1  什么是正则化

正则化（regularization）的外在形式非常简单，就是在模型的损失函数中加上一个正则化项（regularizer），有时也被称为惩罚项（penalty term），如下方程所示，其中L为损失函数，J为正则化项。通常来说，正则化项往往是关于模型参数的1-范数或者2-范数，当然也有可能是这两者的某种结合，例如sklearn的逻辑回归中的弹性网正则化项。

##### 7.2.2  为何需要正则化

正则化核心的作用是缓解模型过拟合倾向，此外，由于加入正则化项后损失函数的形体发生了变化，因此也会影响损失函数的求解过程，在某些时候，加入了正则化项之后会让损失函数的求解变得更加高效。如此前介绍的岭回归，其实就是在线性回归的损失函数基础上加入了w的2-范数，损失函数变成严格的凸函数。

##### 7.2.3  什么是过拟合

当训练数据和新数据具有规律的一致性时，才能够进行建模，而只有挖掘出贯穿始终的规律（同时影响训练数据和新数据的规律），模型才能够进行有效预测。不过，既然有些贯穿始终的全局规律，那就肯定存在一些只影响了一部分数据的局部规律。一般来说，由于全局规律影响数据较多，因此更容易被挖掘，而局部规律只影响部分数据，因此更难被挖掘，因此从较为宽泛的角度来看，但伴随着模型性能提升，也是能够捕获很多局部规律的。但是需要知道的是，局部规律对于新数据的预测并不能起到正面的作用，反而会影响预测结果，此时就出现模型过拟合现象。

##### 7.2.4  正则化如何缓解过拟合倾向

构建损失函数求最小值的过程，其实就是依据以往经验（也就是训练数据）追求风险最小（以往数据误差最小）的过程，而在给定一组参数后计算得出的损失函数的损失值，其实就是经验风险。而所谓结构风险，我们可以将其等价为模型复杂程度，模型越复杂，模型结构风险就越大。而正则化后的损失函数在进行最小值求解的过程中，其实是希望损失函数本身和正则化项都取得较小的值，即模型的经验风险和结构风险能够同时得到控制。

模型的经验风险需要被控制不难理解，因为我们希望模型能够尽可能的捕捉原始数据中的规律，但为何模型的结构风险也需要被控制？核心原因在于，尽管在一定范围内模型复杂度增加能够有效提升模型性能，但模型过于复杂可能会导致另一个非常常见的问题——模型过拟合，一旦模型过拟合了，尽管模型经验风险在降低、但模型的泛化能力会下降。因此，为了控制模型过拟合倾向，我们可以把模型结构风险纳入损失函数中一并考虑，当模型结构风险的增速高于损失值降低的收益时，我们就需要停止参数训练（迭代）。

<img src="https://cdn.jsdelivr.net/gh/louisyanglu/images/images/008i3skNly1gs3wqah1w2j30pu0iaadu.jpg" alt="87" style="zoom:50%;" />

等价于希望训练得到一个较小的模型同时具有较好的解释数据的能力（规律捕捉能力）。

#### 7.3  逻辑回归

`from sklearn.linear_model import LinearRegression`

|       参数        |                             解释                             |
| :---------------: | :----------------------------------------------------------: |
|      penalty      |                           正则化项                           |
|       dual        | <font color='blue'>是否求解对偶问题\*</font><br>对偶问题是约束条件相反、求解方向也相反的问题，<br>当数据集过小而特征较多时，求解对偶问题能一定程度降低运算复杂度 |
|        tol        |     迭代停止条件：两轮迭代损失值差值小于tol时，停止迭代      |
|         C         |             经验风险和结构风险在损失函数中的权重             |
|   fit_intercept   |                   线性方程中是否包含截距项                   |
| intercept_scaling | 相当于此前讨论的特征最后一列全为1的列，当使用liblinear求解参数时用于捕获截距 |
|   class_weight    | <font color='blue'>各类样本权重\*</font><br>例如输入{0:1, 1:3}，则代表1类样本的每一条数据在进行损失函数值的计算时都会在原始数值上*3 |
|   random_state    |                          随机数种子                          |
|      solver       |         <font color='blue'>损失函数求解方法\*</font>         |
|     max_iter      | 求解参数时最大迭代次数，迭代过程满足max_iter或tol其一即停止迭代 |
|    multi_class    |       <font color='blue'>多分类问题时求解方法\*</font>       |
|      verbose      |                       是否输出任务进程                       |
|    warm_start     |           是否使用上次训练结果作为本次运行初始参数           |
|     l1_ratio      | 当采用弹性网正则化时，$l1$正则项权重，就是损失函数中的$\rho$ |

<img src="https://cdn.jsdelivr.net/gh/louisyanglu/images/images/008i3skNly1gs5dfa4trbj31580ew47m.jpg" alt="87" style="zoom:50%;" />

##### 7.3.1  逻辑回归优化方法

>   -   Penalize the intercept (bad)，如果要对截距项也进行惩罚，那只能选取liblinear；    
>   -   Faster for large datasets，如果需要对海量数据进行快速处理，则可以选取sag和saga；
>   -   Robust to unscaled datasets，如果未对数据集进行标准化，但希望维持数据集的鲁棒性（迭代平稳高效），则可以考虑使用liblinear、lbfgs和newton-cg三种求解方法。 

1.   `liblinear`，这是一种**坐标轴下降法**，并且该软件包中大多数算法都有C++编写，运行速度很快，支持OVR+L1或OVR+L2；    
2.   `lbfgs`，全称是L-BFGS，牛顿法的一种改进算法（一种**拟牛顿法**），适用于**小型数据集**，并且支持MVM+L2、OVR+L2以及不带惩罚项的情况；    
3.   `newton-cg`，同样也是一种**拟牛顿法**，和lbfgs适用情况相同；    
4.   `sag`，随机平均梯度下降，随机梯度下降的改进版，类似**动量法**，会在下一轮随机梯度下降开始之前保留一些上一轮的梯度，从而为整个迭代过程增加惯性，除了**不支持L1正则化**的损失函数求解以外（包括弹性网正则化）其他所有损失函数的求解；    
5.   `saga`，sag的改进版，修改了梯度惯性的计算方法，使得其支持所有情况下逻辑回归的损失函数求解；

#### 7.4  网格搜索

`from sklearn.model_selection import GridSearchCV`

参数

|        Name        |                         Description                          |
| :----------------: | :----------------------------------------------------------: |
|     estimator      |                      调参对象，某评估器                      |
|     param_grid     | 参数空间，可以是字典或者字典构成的列表，稍后介绍参数空间的创建方法 |
|      scoring       |                评估指标，支持同时输出多个参数                |
|       n_jobs       |                 设置工作时参与计算的CPU核数                  |
|        iid         | 交叉验证时各折数据是否独立，该参数已在0.22版中停用，将在0.24版中弃用，此处不做介绍 |
|       refit        |        挑选评估指标和最佳参数，在完整数据集上进行训练        |
|         cv         |                        交叉验证的折数                        |
|      verbose       |                       输出工作日志形式                       |
|    pre_dispatch    |                   多任务并行时任务划分数量                   |
|    error_score     | 当网格搜索报错时返回结果，选择'raise'时将直接报错并中断训练过程，其他情况会显示警告信息后继续训练 |
| return_train_score |             在交叉验证中是否显示训练集中参数得分             |

##### 7.4.1  核心参数

`estimator`、`param_grid`

如果某个维度的参数取值对应一组新的参数，应该如何处理？例如，对于逻辑回归来说，如果penalty参数中选择弹性网参数，则会衍生出一个新的参数l1_ratio，如果我们还想考虑penalty参数选取elasticnet参数，并且同时评估l1_ratio取不同值时模型效果，则无法将上述参数封装在一个参数空间内，因为当penalty取其他值时l1_ratio并不存在。为了解决这个问题，我们可以创造多个参数空间（字典），然后将其封装在一个列表中，而该列表则表示多个参数空间的集成。

```python
param_grid_ra = [
    {'penalty': ['l1', 'l2'], 'C': [1, 0.5, 0.1, 0.05, 0.01]}, 
    {'penalty': ['elasticnet'], 'C': [1, 0.5, 0.1, 0.05, 0.01], 'l1_ratio': [0.3, 0.6, 0.9]}
]
```

##### 7.4.2  评估参数

`scoring`、`refit`和`cv`

##### 7.4.3  性能参数

`n_jobs`和`pre_dispatch`，规定调用的核心数和一个任务按照何种方式进行并行运算

##### 7.4.4  评估器结果

|      Name       |                       Description                        |
| :-------------: | :------------------------------------------------------: |
|   cv_results_   |                 交叉验证过程中的重要结果                 |
| best_estimator_ |                     最终挑选出的最优                     |
|   best_score_   |       在最优参数情况下，训练集的交叉验证的平均得分       |
|  best_params_   |                       最优参数组合                       |
|   best_index_   | CV过程会对所有参数组合标号，该参数表示最优参数组合的标号 |
|     scorer      |             在最优参数下，计算模型得分的方法             |
|    n_splits_    |                      交叉验证的折数                      |

<div style="page-break-after:always"></div>

------

### 第8章  聚类

#### 8.1  Kmeans

##### 8.1.1  迭代步骤

1.   确定中心点，第一轮是随机生成的，其他情况都是通过质心计算得到；
2.   根据中心点，计算每个点到中心点的距离；
3.   根据距离计算结果，对数据集进行划分。

##### 8.1.2  迭代停止条件

1.   相邻两次迭代过程中质心位置不发生变化；
2.   相邻两次迭代过程中各点所属类别不发生变化。

##### 8.1.3  数学表示

在给定K（簇的个数）的情况下，找到一种最优的划分情况，使得组内误差平方和尽可能的小。这里所谓的组内误差平方和，指的是每个点到当前簇的中心点的距离的平方和。

| Name  |    Description    |
| :---: | :---------------: |
|  $x$  |     单独样本      |
| $C_i$ |      第i个簇      |
| $c_i$ |   簇$C_i$的质心   |
|  $c$  |   所有点的质心    |
| $m_i$ | 第i个簇中数据个数 |
|  $m$  |   数据集总个数    |
|  $K$  |     簇的个数      |

1.   **组内误差**为：$$\sum^K_{i=1}\sum_{x\in C_i}(c_i-x)^2$$

2.   **原型与SSE**

     中心点、质心其实还有另一个叫法：原型。即当前簇中所有点的原型。我们希望通过原型来“代表”一个簇中的点，也就是说，我们希望通过原型来预测这个簇中数据的表现。在线性回归中，预测值和真实值之间的距离，被称为SSE，因此对于K-Means快速聚类来说，其组内误差平方和也就是SSE

3.   可以借助数学证明，选取质心作为中心点，实际上是有利于让SSE下降速度最快的迭代方法。

     由于原型概念的引入，使得我们可以将K-Means视作预测模型，而上述SSE就是其损失函数，并且该损失函数中变量为$c_k$​，也就是质心，对其求导可得：

     $$\begin{aligned}\frac{\partial}{\partial c_k}SSE &= \sum^K_{i=1}\sum_{x\in C_i}\frac{\partial}{\partial c_i}(c_i-x)^2 \\&=\sum^K_{i=1}\sum_{x\in C_i}2(c_i-x) = 0\end{aligned}$$

     $$\sum_{x\in C_i}(c_i-x) = 0$$

     $$\sum_{x \in C_i}x = m_ic_i$$

     即$$c_i = \frac{1}{m_i}\sum_{x \in C_i}x$$

即中心是由质心计算得出。换而言之，中心点采用每个点各维度均值的计算方式，能够让SSE下降速度最快。如果采用**曼哈顿距离**进行距离计算，则需要采用**中位数**作为质心的计算方法。

##### 8.1.4  参数

|         Name         |      Description       |
| :------------------: | :--------------------: |
|      n_clusters      |      聚类类别总数      |
|         init         |   初始中心点创建方法   |
|        n_init        |    初始化几次中心点    |
|       max_iter       |      最大迭代次数      |
|         tol          |        收敛条件        |
| precompute_distances |   是否提前预计算距离   |
|      algorithm       | 优化距离计算的方法选取 |

当面对复杂数据集时，K-Measn很有可能陷入“局部最小值陷进”或者“震荡收敛”。所谓落入局部最小值陷进，指的是尽管可能有更好的划分数据集的方法（SSE取值更小），但根据K-Means的收敛条件却无法达到，算法会在另外一种划分情况时停止迭代；而所谓“震荡收敛”，指的是算法会在两种不同的划分方法中来回震荡（尽管SSE取值可能有差别）。前种情况非常类似于参数进行梯度下降求解过程中，如果采用BGD，并且参数在一个局部最小值点附近，则最终参数会收敛到局部最小值点类似，而后面一种情况则非常类似于学习率过大导致无法收敛、一直处于震荡状态。

出现这种问题的根本原因，其实在于初始中心点的随机选取。因此sklearn中其实集成了两种技术手段来避免上述两种问题的出现。

1.   采用k-means++算法来计算初始中心点，经过这种算法生成的中心点，能够大概率在后续的迭代过程中让模型保持平稳；
2.   多次初始化中心点、多次训练模型、然后找到最优数据集划分的方法。

```python
km.cluster_centers_  # 查看中心点
km.labels_  # 查看每条数据属于哪一类
km.inertia_  # 收敛时SSE
km.n_iter_  # 迭代次数
```

##### 8.1.5  轮廓系数

尽管我们可以通过SSE来表示当前K-Means聚类模型效果好坏（甚至作为损失函数），但SSE却不能作为模型超参数（K）的选取依据。其实我们不难发现，伴随K增加，模型整体SSE将会逐渐下降。

轮廓系数的计算过程：

1.   对于第i条数据（以下简称i），计算该对象到所属簇的平均距离，记为$a_i$；
2.   如果还存在其他簇，计算该对象到这些簇的所有点的平均距离，并在这些距离中找到最小值记为$b_i$；
3.   则对于i，轮廓系数计算结果为：$s_i=\frac{b_i-a_i}{max(a_i, b_i)}$；
4.   对于聚类中的所有N条数据，最终轮廓系数为单个$s_i$的均值，即$s=mean(s_i)$

轮廓系数可以在[-1, 1]区间内取值，但我们并不希望轮廓系数出现负值，此时代表组内的平均距离要大于组外平均距离的最小值，此时说明聚类算法无效。我们希望$b_i>a_i$，并且希望$a_i$尽可能的小，此时$s_i$也就趋近于1，而当轮廓系数趋于0时，则说明各簇重叠现象明显。

```python
from sklearn.metrics import silhouette_score

silhouette_score(X, km.labels_)  # 越高越好
```

#### 8.2  Mini Batch KMeans

所谓Mini Batch K-Means算法，就是在K-Means基础上增加了一个Mini Batch的抽样过程，并且每轮迭代中心点时，不再带入全部数据、而是带入抽样的Mini Batch进行计算。

1.   从数据集中随机抽取一些数据形成小批量，把他们分配给最近的质心
2.   根据小批量数据划分情况，更新质心

梯度下降过程中，我们带入全部数据构造损失函数，相当于带入全部数据进行参数的更新，就类似于K-Means带入每个簇的全部数据进行中心点位置计算，而在小批量梯度下降过程中，实际上我们是借助小批数据构造损失函数并对参数进行更新，就类似于Mini Batch K-Means中利用小批数据更新中心点。

##### 8.2.1  参数

`from sklearn.cluster import MiniBatchKMeans`

|        Name        |                         Description                          |
| :----------------: | :----------------------------------------------------------: |
|     batch_size     |                      小批量抽样的数据量                      |
|   compute_labels   |           在聚类完成后，是否对所有样本进行类别计算           |
| max_no_improvement |           当SSE不发生变化时，质心最多再迭代多少次            |
|     init_size      |                 用于生成初始中心点的样本数量                 |
| reassignment_ratio | 某比例，数值越大、样本数越少的簇被重新计算中心点的概率就越大 |

1.   在迭代收敛条件上，通过查看说明文档我们不难发现，MiniBatchKMeans主要通过max_no_improvement和max_iter两个参数来控制收敛，在默认情况下不采用tol参数。其根本原因在于小批量聚类往往需要迭代很多轮，因而出实际未收敛、但现两次相邻的迭代结果中SSE变化值小于tol的情况的概率会显著增加，因此此时我们不能以tol条件作为收敛条件；
2.   在控制结果精度上，尽管小批量聚类是用精度换速度，但仍然提供了可以提升聚类精度的参数，也就是reassignment_ratio，当发现聚类结果不尽如人意时，可以适当提升该参数的取值。

如果希望更进一步提高迭代速度，可以适度减少`batch_size`、减少`reassignment_ratio`、`max_no_improvement`这三个参数，不过代价就是聚类的精度可能会进一步降低，而如果希望提高精度，则可以提升reassignment_ratio参数，不过相应的，运行时间将会有所提升。

#### 8.3  DBScan

从最终聚类效果上来看，MiniBatchKMeans和K-Means聚类算法仍然属于同一类聚类——**假设簇的边界是凸形的聚类**。换而言之，就是这种聚类能够较好的捕捉圆形/球形边界（直线边界可以看成是大直径的圆形边界），而对于非规则类边界，则无法进行较好的聚类，当然这也是和K-Means聚类的核心目的：让更相近同一个中心点的数据属于一个簇，息息相关。但有些时候，更接近同一个中心点的数据却不一定应该属于一个簇。

如果我们希望捕获上述**非凸的边界**，则需要使用一种**基于密度**的聚类方法，也就是我们将要介绍的DBSCAN密度聚类。

##### 8.3.1  密度的定义

通过两个概念和密度密切相关：分别是半径（eps）与半径范围内点的个数（num_samples）。对于数据集中任意一个点，只要给定一个eps，就能算出对应的num_samples，例如对于下述A点，在一个eps范围内，num_samples为7（包括自己）。

<img src="https://cdn.jsdelivr.net/gh/louisyanglu/images/images/008i3skNly1gsczpozxc0j30m80gsjw5.jpg" alt="87" style="zoom: 33%;" />

eps越小、num_samples越大，则说明该点所在区域密度较高。

我们可以据此设置一组参数，即半径（eps）和半径范围内至少包含多少点（min_samples）作为评估指标，来对数据集中不同的点进行密度层面的分类：例如我们令eps=Eps（某个数），min_samples=6，并且如果某点在一个Eps范围内包含的点的个数大于min_samples，则称该点为**核心点**（core point），如下图中的A点；而如果某个点不是核心点，但是在某个核心点的一个eps领域内，则称该点为**边界点**，例如下图B点；而如果某点既不是核心点也不是边界点，则成该点为**噪声点**，如下图的C点。

<img src="https://cdn.jsdelivr.net/gh/louisyanglu/images/images/008i3skNly1gsd01ibvqbj611q0jigxp02.jpg" alt="87" style="zoom: 33%;" />

当我们对数据集中的所有点完成上述三类的划分之后，接下来，我们一个eps范围内的核心点化为一个簇，并且将边界点划归到一个临近的核心点所属簇中，并且抛弃噪声点，最终完成数据集整体的划分。即将高密度区域划分成一个簇，将低密度区域视作不同簇的分界线。

##### 8.3.2  参数

`from sklearn.cluster import DBSCAN`

核心参数就是上面介绍的eps和min_samples

`DB.labels_`：噪声点，标签为-1

eps变小、min_samples变大：同一个簇对簇内的密度要求更高，噪声点更多，此时更容易划分出多个簇。

<div style="page-break-after:always"></div>

------

### 第9章  决策树

#### 9.1  ID3：离散变量+分类问题

>   确定分类规则判别指标、寻找能够最快速降低信息熵的⽅式进⾏数据集划分（分类规则提取），不断迭代直⾄收敛。

1.   只能围绕离散型变量处理分类问题；

2.   按照列来展开

     >   CART树是在所有特征中寻找切分点、然后再从中挑选出能够最⼤程度降低数据集不纯度的节分⽅式，换⽽⾔之就是CART树是按照某切分点来展开；
     >
     >   ⽽ID3则是按照列来展开，即根据某列的不同取值来对数据集进⾏划分。更倾向于挑选取值较多的分类变量来作为划分点，可划分两个以上的⼦集。

     <img src="https://cdn.jsdelivr.net/gh/louisyanglu/images/images/008i3skNly1gst02jw4o4j31w10u0gr8.jpg" alt="87" style="zoom: 33%;" />

3.   采⽤信息熵作为不纯度的评估指标

     >   信息熵⽤于衡量标签的纯度，在[0,1]之间取值，信息熵越⼩则说明数据集纯度越⾼。

     $$Entropy(t) = -\sum_{i=1}^c p(i|t)log_2p(i|t)$$

     对于某列变量来说，其整体信息熵就是按某列划分后的所有⼦节点的信息熵加权求和。其中$加权的权重=每个叶子节点样本数/父节点样本数$。

#### 9.2  C4.5：连续/离散变量+分类问题

>   使得现在的树模型能够处理**连续变量**（此前的ID3只能处理分类变量），同时也能够⼀定程度提⾼树模型的⽣⻓速度。

1.   在衡量不纯度降低的数值计算过程中引⼊信息值（information value，也被称为划分信息度、分⽀度等）概念来修正信息熵的计算结果，以抑制ID3更倾向于寻找分类⽔平较多的列来展开的情况，从⽽间接抑制模型过拟合倾向。

     $$Information\ Value = -\sum^K_{i=1}P(v_i)log_2P(v_i)$$

     $$Gain\ Ratio = \frac{Information\ Gain}{Information\ Value}$$

     其中，$K$表示某次划分是总共分⽀个数， $v_i$表示划分后的某样本， $P(v_i)$表示该样本数量占⽗节点数据量的⽐例。

2.   新增了连续变量的处理⽅法，也就是CART树中寻找相邻取值的中间值作为切分点的⽅法；

     C4.5的离散变量和连续变量提取规则⽅式不同，离散变量是⼀次消耗⼀列来进⾏展开（有可能多分叉），⽽连续变量则⼀次消耗⼀个切分点，因此和CART树⼀样、同⼀个连续变量可以多次指导数据集进⾏划分。

3.   加⼊了决策树的剪枝流程，使得模型泛化能⼒能够得到进⼀步提升。

#### 9.3  CART：连续/离散变量+分类/回归问题

>   CART树和C4.5决策树的构造过程⾮常类似，但拓展了**回归类问题**的计算流程（此前C4.5只能解决分类问题），并且允许采⽤更丰富的评估指标来指导建模流程。

1.   能处理分类/回归问题；

2.   在所有特征中寻找中间值作为切分点；

     ⽆法直接处理分类变量，需要将其映射为数值型。

3.   只能进⾏⼆叉树的⽣⻓；

4.   分类树使⽤信息熵/基尼系数作为评估指标；

     $Gini(t)=1-\sum_{i=1}^cp(i|t)^2$

     基尼系数在[0, 0.5]范围内取值，值越⼩表示数据集纯度越⾼。

5.   回归树可使⽤mse、mae、friedman_mse

     **CART回归树的criterion不仅是划分⽅式挑选时的评估标准，同时也是划分⼦数据集后选取预测值的决定因素。**

     -   `mse`：**预测值=⼦节点样本的标签y的均值**（每个⼦集MSE最⼩ 组内误差平⽅和SSE最⼩ 质⼼）

         每个节点整体的mse=左右两个⼦节点的平⽅误差加权求和，权重为⼦节点样本数/⽗节点样本数。

         mse易受极端值影响。

     -   `mae`：**预测值=⼦节点样本的标签y的中位数**

         mae对异常值不敏感。

     -   `friedman_mse`：常⽤于GBDT梯度提升树中。

#### 9.4  评估器参数

|Name|Description|      
|:--:|:--:| 
|criterion|规则评估指标或损失函数，默认基尼系数，可选信息熵| 
|splitter|树模型生长方式，默认以损失函数取值减少最快方式生长，可选随机根据某条件进行划分|
|max_depth|树的最大生长深度，类似max_iter，即总共迭代几次| 
|min_samples_split|内部节点再划分所需最小样本数| 
|min_samples_leaf|叶节点包含最少样本数| 
|min_weight_fraction_leaf|叶节点所需最小权重和| 
|max_features|在进行切分时候最多带入多少个特征进行划分规则挑选|
|random_state|随机数种子| 
|max_leaf_nodes|叶节点最大个数| 
|min_impurity_decrease|数据集再划分至少需要降低的损失值| 
|min_impurity_split|数据集再划分所需最低不纯度，将在0.25版本中移除| 
|class_weight|各类样本权重| 
|presort|已在0.24版本中移除| 
|ccp_alpha|在执行CART树原生原理中的剪枝流程时结构复杂度惩罚因子的系数，默认情况下不使用该方法进行剪枝| 

1.   `criterion` ：**不纯度衡量指标**

     -   相⽐信息熵，基尼系数复杂度更低、计算速度更快，⼀般情况下推荐使⽤基尼系数；
     -   在有些情况下，基尼不纯度更倾向于在数据集中分割出多数类，⽽信息熵则更倾向于⽣成出更加平衡的树。

2.   `ccp_alpha` ：**结构⻛险权重**

     ccp是复杂度剪枝（Cost-Complexity Pruning）的简称。在sklearn中并不⼀定要通过该⽅法进⾏剪枝，因此该参数其实也并不是⼀个必选参数。

     其原理是在决策树的损失函数上加上⼀个结构⻛险项，类似于正则化项在线性⽅程的损失函数中作⽤相同。

     设$T$为某决策树，$R(T)$为决策树在训练集上整体不纯度，即代表模型的经验风险，令$\alpha \times|\widetilde{T}|$表示模型结构风险，其中$\alpha$为参数，$|\widetilde{T}|$为树的叶节点数量，则我们可以修改模型损失函数如下：$R_\alpha(T) = R(T) + \alpha \times |\widetilde{T}|$。

     $\alpha$取值越⼤、对模型的结构⻛险惩罚⼒度就越⼤、模型结构就越简单、过拟合就能够被更好的抑制。

3.   **控制树结构**的参数类

     -   限制模型**整体结构**

         -   `max_depth`
         -   `max_leaf_nodes`
         -   `min_samples_split`

     -   限制**树⽣⻓**的参数

         -   `min_samples_leaf`

         -   `min_impurity_split`

         -   `min_impurity_decrease`

             sklearn在计算⽗节点和⼦节点的信息熵/基尼系数的差值时，会在计算结果上乘以⼀个系数（⽗节点样本数占根节点样本数的⽐例，这样样本数少的节点，哪怕再划分时⼦节点纯度下降很多，但最终的impurity_decrease也不⾼，这样也可以防⽌过拟合。

     -   控制**迭代随机过程**的参数

         -   `splitter`
         -   `max_features`

<div style="page-break-after:always"></div>

------

### 第10章  随机森林

#### 10.1  Bagging基本思想

>   -   当集成算法目标是回归任务时，集成算法的输出结果是弱评估器输出的结果的平均值；
>   -   当集成算法的目标是分类任务时，集成算法的输出结果是弱评估器输出的结果少数服从多数。

Bagging又称为“装袋法”，它是所有集成学习方法当中最为著名、最为简单、也最为有效的操作之一。

在Bagging集成当中，我们并行建立多个弱评估器（通常是决策树，也可以是其他非线性算法），并综合多个弱评估器的结果进行输出。

#### 10.2  随机森林

随机森林是机器学习领域最常用的算法之一，其算法构筑过程非常简单：**从提供的数据中随机抽样出不同的子集，用于建立多棵不同的决策树，并按照Bagging的规则对单棵决策树的结果进行集成（回归则平均，分类则少数服从多数）。**

**任意集成算法在发源时都是回归类算法，因此我们的重点将会放在回归类算法上**。

##### 10.2.1  参数

|类型|参数|
|---|---|
|**弱分类器数量**|**<font color="green">n_estimators</font>**|
|**弱分类器的训练数据**|**<font color="green">bootstrap, <br/>oob_score, <br/>max_samples</font>**, <br/>max_features, <br/>random_state|
|**弱分类器结构**|criterion, <br/>max_depth, <br/>min_samples_split, <br>min_samples_leaf, <br/>min_weight_fraction_leaf, <br/>max_leaf_nodes,<br>min_impurity_decrease|
|**其他**|n_jobs, <br/>verbose, <br/>ccp_alpha|

##### 10.2.2  弱分类器结构

>   **在集成算法当中，控制单个弱评估器的结构是一个重要的课题，因为单个弱评估器的复杂度/结果都会影响全局**，其中单棵决策树的结构越复杂，集成算法的整体复杂度会更高，计算会更加缓慢、模型也会更加容易过拟合，因此集成算法中的弱评估器也需要被剪枝。

|类型|参数|
|----|----|
|**弱分类器结构**|criterion：弱评估器分枝时的不纯度衡量指标<br>max_depth：弱评估器被允许的最大深度，默认None<br>min_samples_split：弱评估器分枝时，父节点上最少要拥有的样本个数<br>min_samples_leaf：弱评估器的叶子节点上最少要拥有的样本个数<br>min_weight_fraction_leaf：当样本权重被调整时，叶子节点上最少要拥有的样本权重<br>max_leaf_nodes：弱评估器上最多可以有的叶子节点数量<br>min_impurity_decrease：弱评估器分枝时允许的最小不纯度下降量|

-   `criterion`

    >   1.   平方误差比绝对误差更敏感，在计算上平方误差比绝对误差快很多；
    >   2.   泊松偏差则是适用于一个特殊场景的：当需要预测的标签全部为正整数时，标签的分布可以被认为是类似于泊松分布。如预测点击量、预测客户/离职人数、预测销售量等。
    >   3.   选择不同的criterion之后，决策树的feature_importances_也会随之变化，因为在sklearn当中，feature_importances_是特征对criterion下降量的总贡献量，因此不同的criterion可能得到不同的特征重要性。

    -   'squared_error'：平方误差，$\sum{(y_i - \hat{y_i})^2}$
    -   'absolute_error'：绝对误差，$\sum{|y_i - \hat{y_i}|}$
    -   'poisson'：泊松偏差，$$2\sum{(y_ilog(\frac{y_i}{\hat{y_i}})-(y_i - \hat{y_i}))}$$

-   `max_depth`

    最粗犷的剪枝方式，从树结构层面来看，对随机森林抗过拟合能力影响最大的参数。

-   `max_leaf_nodes`与`min_sample_split`

    比max_depth更精细的减枝方式，限制叶子数量和分枝，既可以实现微调，也可以实现大刀阔斧的剪枝。

-   `min_impurity_decrease`

    最精细的减枝方式，可以根据不纯度下降的程度减掉相应的叶子。默认值为0，是个相当有空间的参数。

##### 10.2.3  弱分类器数量

-   `n_estimators`

    >   n_estimators对随机森林模型的精确程度、复杂度、学习能力、过拟合情况、需要的计算量和计算时间都有很大的影响，因此n_estimators往往是我们在调整随机森林时第一个需要确认的参数。

    当n_estimators越大时：

    - 模型的复杂程度上升，泛化能先增强再减弱（或不变）
    - 模型的学习能力越来越强，在训练集上的分数可能越来越高，过拟合风险越来越高
    - 模型需要的算力和内存越来越多
    - 模型训练的时间会越来越长

##### 10.2.4  弱分类器的训练数据

>   对于决策树而言，只要给出数据一致、并且不进行减枝的话，决策树的结构一定是完全相同的。对集成算法来说，平均多棵相同的决策树的结果并没有意义，因此集成算法中每棵树必然是不同的树，Bagging算法是依赖于随机抽样数据来实现这一点的。

|类型|参数|
|---|---|
|**弱分类器的训练数据**|<font color="green">**bootstrap**</font>：是否对样本进行随机抽样<br><font color="green">**oob_score**</font>：如果使用随机抽样，是否使用袋外数据作为验证集<br><font color="green">**max_samples**</font>：如果使用随机抽样，每次随机抽样的样本量<br>max_features：随机抽取特征的数目<br>random_state：控制一切随机模式|

1.   样本的随机抽样

     -   `bootstrap`：**有放回随机抽样，默认True，控制是否在每次建立决策树之前对数据进行随机抽样**。

         当抽样次数足够多、且原始数据集足够大时，自助集大约会包含全数据的63%。其余37%被称为袋外数据(out of bag data，简写为oob)。在实际使用随机森林时，袋外数据常常被我们当做验证集使用，所以我们或许可以不做交叉验证、不分割数据集，而只依赖于袋外数据来测试我们的模型即可。

     -   `oob_score`：是否使用袋外数据进行验证，默认为False（前提是使用bootstrap）；

         可使用`.oob_score_`来查看我们的在袋外数据上测试的结果，遗憾的是我们无法调整输出的评估指标，它默认是R2。

     -   `max_samples`：控制自助集的大小（前提是使用bootstrap）。

2.   特征的随机抽样

     >   无论对数据进行怎样的抽样，我们能够控制的都只是建立单棵树时的数据而已。在总数据量有限的情况下，单棵树使用的数据量越大，每一棵树使用的数据就会越相似，每棵树的结构也就会越相似，bagging的效果难以发挥、模型也很容易变得过拟合。因此，当数据量足够时，我们往往会消减单棵树使用的数据量。
     >
     >   一般而言，取[log2(m) * 0.5, sqrt(m) * 1.5]。

     -   `max_features`

         > 1.   输入整数，表示每次分枝时随机抽取max_features个特征
         > 2.   输入浮点数，表示每次分枝时抽取round(max_features * n_features)个特征
         > 3.   输入"auto"或者None，表示每次分枝时使用全部特征n_features
         > 4.   输入"sqrt"，表示每次分枝时使用sqrt(n_features)
         > 5.   输入"log2"，表示每次分枝时使用log2(n_features)

3.   随机种子

     -   当数据样本量足够大的时候（数万），变换随机数种子几乎不会对模型的泛化能力有影响，因此在数据量巨大的情况下，我们可以随意设置任意的数值。
     -   当数据量较小的时候，我们可以把随机数种子当做参数进行调整，但前提是必须依赖于交叉验证的结果。选择交叉验证结果中均值最高、方差最低的随机数种子，以找到泛化能力最强大的随机模式。

##### 10.2.5  其他参数

|类型|参数|
|---|---|
|**其他**|n_jobs：允许调用的线程数<br>verbose：打印建树过程<br>ccp_alpha：结构风险$\|\widetilde{T}\|$上的系数，可用于控制过拟合<br>warm_start：支持增量学习|

>   **增量学习允许算法不断接入新数据来拓展当前的模型，即允许巨量数据被分成若干个子集，分别输入模型进行训练**

##### 10.2.6  调参顺序

|影响力|参数|
|:-:|:-:|
|⭐⭐⭐⭐⭐<br>几乎总是具有巨大影响力|n_estimators（整体学习能力）<br>max_depth（粗剪枝）<br>max_features（随机性）|
|⭐⭐⭐⭐<br>大部分时候具有影响力|max_samples（随机性）<br>class_weight（样本均衡）|
|⭐⭐<br>可能有大影响力<br>大部分时候影响力不明显|min_samples_split（精剪枝）<br>min_impurity_decrease（精剪枝）<br>max_leaf_nodes（精剪枝）<br>criterion（分枝敏感度）|
|⭐<br>当数据量足够大时，几乎无影响|random_state<br>ccp_alpha（结构风险）|

##### 10.2.7  tree属性

>   `from sklearn.tree._tree import Tree`

|参数|参数含义|对应属性|属性含义|
|:-:|:-:|:-:|:-:|
|n_estimators|树的数量|reg.estimators_|森林中所有树对象|
|max_depth|允许的最大深度|.tree_.max_depth|0号树实际的深度|
|max_leaf_nodes|允许的最大<br>叶子节点量|.tree_.node_count|0号树实际的总节点量|
|min_sample_split|分枝所需最小<br>样本量|.tree_.n_node_samples|0号树每片叶子上实际的样本量|
|min_weight_fraction_leaf|分枝所需最小<br>样本权重|tree_.weighted_n_node_samples|0号树每片叶子上实际的样本权重|
|min_impurity_decrease|分枝所需最小<br>不纯度下降量|.tree_.impurity<br>.tree_.threshold|0号树每片叶子上的实际不纯度<br>0号树每个节点分枝后不纯度下降量|

```python
# 所有树上的总叶子量
for t in reg_f.estimators_:
    print(t.tree_.node_count)

# 每个节点上的不纯度下降量，为-2则表示该节点是叶子节点
reg_f.estimators_[0].tree_.threshold.tolist()
# 你怎么知道min_impurity_decrease的范围设置多少会剪掉多少叶子？
np.cumsum(pd.Series(reg_f.estimators_[0].tree_.threshold).value_counts().sort_index()[1:])  # 剔除-2叶节点

# min_sample_split的范围要如何设置才会剪掉很多叶子？
np.bincount(reg_f.estimators_[0].tree_.n_node_samples.tolist())[:10]
```

#### 10.3  面试问题

##### 10.3.1  为什么Bagging算法的效果比单个评估器更好？

>   考察Bagging方法降低模型泛化误差的基本原理。

当算法是回归算法、且模型衡量指标是MSE时，模型的泛化误差可以有如下定义：$$\begin{aligned} 泛化误差 &= 偏差^2 + 方差 + 噪音^2 \\&= bias^2 + variance + noise^2 \end{aligned}$$

-   偏差是预测值与真实值之间的差异，衡量模型的精度
-   方差是模型在不同数据集上输出的结果的方差，衡量模型稳定性
-   噪音是数据收集过程当中不可避免的、与数据真实分布无关的信息

**Bagging的基本思想是借助弱评估器之间的“独立性”来降低方差**，从而降低整体的泛化误差。**“降低方差”指的是bagging算法输出结果的方差一定小于弱评估器输出结果的方差**。

##### 10.3.2  为什么Bagging可以降低方差？

随机森林中含有$n$个弱评估器（$n$棵树），任意弱评估器上的输出结果是$X_i$，则所有弱评估器输出结果的方差可以被表示为Var($X_i$)

1.   **回归任务**

     森林的输出结果等于森林中所有树输出结果的平均值$\bar{X} = \frac{\sum{X_i}}{n}$，因此随机森林输出结果的方差可以被表示为Var($\bar{X}$)，也可以写作Var($\frac{\sum{X_i}}{n}$)。**当森林中的树互相独立时，Var($\boldsymbol{\bar{X}}$)永远小于Var($\boldsymbol{X_i}$)**。

     假设任意树输出的方差Var($X_i$) = $\sigma^2$，则有：

     $$\begin{aligned}Var(\bar{X}) &= Var\left(\frac{1}{n}\sum_{i=1}^{n}X_i\right)\\&= \frac{1}{n^2}Var\left(\sum_{i=1}^{n}X_i\right)\\&= \frac{1}{n^2} \left( Var(X_1) + Var(X_2) + ... + Var(X_n) \right)\\&= \frac{1}{n^2}n\sigma^2\\&= \frac{\sigma^2}{n}\end{aligned}$$

     当$n$为正整数、且弱评估器之间相互独立时，必然有Var($\bar{X}$) 永远小于Var($X_i$)

2.   **分类任务**

     每棵树上的输出结果进行少数服从多数的计算，并将“多数”指向的类别作为随机森林分类器的结果。这个过程可以使用函数来替代，只要我们对所有树的结果的均值套上sigmoid函数，再以0.5为阈值就可以：$sigmoid(r.mean())$。

     因此，随机森林分类器的方差可以写作Var($f(\bar{X})$)，其中$f(z)$就是sigmoid函数，$\bar{X}$是所有弱评估器的分类结果的均值。**当森林中的树互相独立，且$f(x)$为sigmoid函数时，Var($\boldsymbol{f(\bar{X})}$)永远小于Var($\boldsymbol{X_i}$)**。

     当$f(x)$为二阶可导函数时，根据泰勒展开有：

     $$\begin{aligned}Var(f(\bar{X})) &\approx f'(E[\bar{X}])^2 * Var[\bar{X}]\\&= f'(E[\bar{X}])^2 * \frac{\sigma^2}{n}\end{aligned}$$，其中A为任意随机变量，f'为函数$f(x)$的一阶导数。

     式子的第一部分是sigmoid函数一阶导数的平方，sigmoid函数的一阶导数的取值范围为[0,0.25]，因此无论$E[\bar{X}]$是怎样的一个值，该式子的前半部分一定是一个位于范围[0,0.0625]的数。

##### 10.3.3  Bagging有效的基本条件有哪些？Bagging的效果总是强于弱评估器吗？

Bagging当然不总是有效的，Bagging能够提升模型效果的条件有以下三个：

-   弱评估器的**偏差较低**，特别地来说，弱分类器的准确率至少要达到50%以上；

    在使用随机森林之前，一定要检查，用来组成随机森林的分类树们是否都有至少50%的预测正确率。

-   弱评估器之间相关性弱，最好**相互独立；**

    假设任意弱评估器之间的相关系数为$ρ$，则$$Var(\boldsymbol{\bar{X}}) = \frac{\sigma^2}{n} + \frac{n-1}{n}\rho\sigma^2$$。

    **随机森林输出结果的方差与森林中弱评估器之间的相关性是负相关的**。

    弱评估器之间的相关性越强，随机森林输出的结果的方差就越大，Bagging方法通过降低方差而获得的泛化能力就越小。

-   弱评估器是方差较高、不稳定的评估器

##### 10.3.4  Bagging方法可以集成决策树之外的算法吗？

强大又复杂的算法如决策树、支持向量机等，往往学习能力较强，倾向于表现为偏差低、方差高，这些算法就比较适合于Bagging。而线性回归、逻辑回归、KNN等复杂度较低的算法，学习能力较弱但表现稳定，因此倾向于表现为偏差高，方差低，就不太适合被用于Bagging。

##### 10.3.5  怎样增强Bagging中弱评估器的独立性？

在实际使用数据进行训练时，我们很难让Bagging中的弱评估器完全相互独立，主要是因为：

-   训练的数据一致
-   弱评估器构建的规则一致

最终建立的弱评估器都大同小异，Bagging的效力无法完整发挥出来

-   多个模型：为了弱评估器构建规则一致的问题，我们有了Averaging和Voting这样的模型融合方法
-   数据：使用“随机性”来削弱弱分类器之间的联系、增强独立性、提升随机森林的效果

##### 10.3.6  除了随机森林，你还知道其他Bagging算法吗？

在sklearn当中，除了随机森林之外还提供另一个bagging算法：极端随机树。极端随机树是一种比随机森林更随机、对方差降低更多的算法。

与随机森林一样，极端随机树在建树时会随机挑选特征，但不同的是，随机森林会将随机挑选出的特征上**每个节点**都进行完整、精致的不纯度计算，然后挑选出最优节点，而极端随机树则会**随机选择数个节点**进行不纯度计算，然后选出这些节点中不纯度下降最多的节点。这样生长出的树比随机森林中的树更不容易过拟合，同时独立性更强，因此极端随机树可以更大程度地降低方差。

当然了，这种手段往往也会带来偏差的急剧下降，因此极端随机树是只适用于方差过大、非常不稳定的数据的。除非特殊情况，我们不会考虑使用极端随机树。

<div style="page-break-after:always"></div>

------

### 第11章  超参数优化

#### 11.1  网格搜索GridSearchCV

>   **当参数空间穷尽了所有可能的取值时，网格搜索一定能够找到损失函数的最小值所对应的最优参数组合**。

只有1个参数n_estimators，备选范围是[50,100,150,200,250,300]，需要建模**6**次；

增加参数max_depth，且备选范围是[2,3,4,5,6]，需要建模**30**次；

增加参数min_sample_split，且备选范围为[2,3,4,5]，需要建模**120**次；

假设交叉验证次数为5，则三个参数就需要建模600次。在面对超参数众多、且超参数取值可能无限的人工神经网络、融合模型、集成模型时，伴随着数据和模型的复杂度提升，网格搜索所需要的时间会急剧增加，完成一次枚举网格搜索可能需要耗费几天几夜。考虑到后续实践过程中，算法和数据都将更加复杂，而建模过程中超参数调优是模型训练的必备环节，因此，我们急需寻找到一种更加高效的超参数搜索方法。

当所使用的算法确定时，决定枚举网格搜索运算速度的因子一共有两个：

1.   **参数空间**的大小：参数空间越大，需要建模的次数越多；
2.   **数据量**的大小：数据量越大，每次建模时需要的算力和时间越多。

网格搜索优化方法主要包括两类，其一是**调整搜索空间**，其二是调整**每次训练的数据**。

#### 11.2  随机网格搜索RandomizedSearchCV

-   当设置相同的全域空间时，随机搜索的**运算速度**比枚举网格搜索**快**很多；

-   当设置相同的训练次数时，随机搜索可以**覆盖的空间**比枚举网格搜索**大**很多；

-   随机网格搜索得出的**最小损失**与枚举网格搜索得出的最小损失**很接近**。

    **随机网格搜索在实际运行时，并不是先抽样出子空间，再对子空间进行搜索**。而是仿佛“循环迭代”一般，在这一次迭代中随机抽取1组参数进行建模，下一次迭代再随机抽取1组参数进行建模，由于这种随机抽样是不放回的，因此不会出现两次抽中同一组参数的问题。

    “从某个全数据集/全域中进行抽样”的操作，能够有效的根本原因在于：

    >   1、抽样出的子空间可以一定程度上反馈出全域空间的分布，且子空间相对越大（含有的参数组合数越多），子空间的分布越接近全域空间的分布；
    >
    >   2、当全域空间本身足够密集时，很小的子空间也能获得与全域空间相似的分布；
    >
    >   3、如果全域空间包括了理论上的损失函数最小值，那一个与全域空间分布高度相似的子空间很可能也包括损失函数的最小值，或包括非常接近最小值的一系列次小值。

-   更大/更密集的全域空间

    由于随机网格搜索计算更快，所以在相同计算资源的前提下，我们可以对随机网格搜索使用**更大的全域空间**，因此随机搜索可能得到比网格搜索**更好的效果**。

-   连续的参数空间

    -   对于网格搜索来说，参数空间中的点是分布均匀、间隔一致的，因为网格搜索无法从某种“分布”中提取数据，只能使用组合好的参数组合点；
    -   随机搜索却可以接受“分布”作为输入。由于是一段分布上随机选择参数点，因此在同样的参数空间中，取到更好的值的可能性更大；
    -   如浮点数的超参，使用均匀分布`scipy.stats.uniform(loc=1,scale=100)`作为参数备选值。

|        Name         |                         Description                          |
| :-----------------: | :----------------------------------------------------------: |
|      estimator      |                      调参对象，某评估器                      |
| param_distributions |          全域参数空间，可以是字典或者字典构成的列表          |
|     **n_iter**      |         迭代次数，迭代次数越多，抽取的子参数空间越大         |
|       scoring       |                评估指标，支持同时输出多个参数                |
|       n_jobs        |                  设置工作时参与计算的线程数                  |
|        refit        |        挑选评估指标和最佳参数，在完整数据集上进行训练        |
|         cv          |                        交叉验证的折数                        |
|       verbose       |                       输出工作日志形式                       |
|    pre_dispatch     |                   多任务并行时任务划分数量                   |
|  **random_state**   |                          随机数种子                          |
|     error_score     | 当网格搜索报错时返回结果，选择'raise'时将直接报错并中断训练过程，其他情况会显示警告信息后继续完成训练 |
| return_train_score  |             在交叉验证中是否显示训练集中参数得分             |

#### 11.3  对半网格搜索HalvingSearchCV

调整**搜索空间**的方法就是随机网格搜索，而调整每次**训练数据**的方法就是对半网格搜索。

假设现在存在数据集$D$，我们从数据集$D$中随机抽样出一个子集$d$。如果一组参数在整个数据集$D$上表现较差，那大概率这组参数在数据集的子集$d$上表现也不会太好。反之，如果一组参数在子集$d$上表现不好，我们也不会信任这组参数在全数据集$D$上的表现。**参数在子集与全数据集上反馈出的表现一致**。

这一假设要成立的条件：**任意子集的分布都与全数据集D的分布类似**。当子集的分布越接近全数据集的分布，同一组参数在子集与全数据集上的表现越有可能一致。我们知道子集越大、其分布越接近全数据集的分布，但是大子集又会导致更长的训练时间，需要权衡。

具体的流程：

1.   首先从全数据集中无放回随机抽样出一个很小的子集$d_0$，并在$d_0$上验证全部参数组合的性能。根据$d_0$上的验证结果，淘汰评分排在后1/2的那一半参数组合；

2.   然后，从全数据集中再**无放回抽样**出一个比$d_0$大一倍的子集$d_1$，并在$d_1$上验证剩下的那一半参数组合的性能。根据$d_1$上的验证结果，淘汰评分排在后1/2的参数组合；

3.   再从全数据集中无放回抽样出一个比$d_1$大一倍的子集$d_2$，并在$d_2$上验证剩下1/4的参数组合的性能。根据$d_2$上的验证结果，淘汰评分排在后1/2的参数组合。

     持续循环。如果使用S代表首次迭代时子集的样本量，C代表全部参数组合数，则在迭代过程中，用于验证参数的数据子集是越来越大的，而需要被验证的参数组合数量是越来越少的：

     | 迭代次数 | 子集样本量 |   参数组合数   |
     | :------: | :--------: | :------------: |
     |    1     |     S      |       C        |
     |    2     |     2S     | $\frac{1}{2}C$ |
     |    3     |     4S     | $\frac{1}{4}C$ |
     |    4     |     8S     | $\frac{1}{8}C$ |

     停止条件：**备选参数组合只剩下一组，或剩余可用的数据不足**，**当$\frac{1}{n}$C <= 1或者nS > 总体样本量，搜索就会停止**。

只有在不同的子集上不断获得优秀结果的参数组合能够被留存到迭代的后期，最终选择出的参数组合一定是在所有子集上都表现优秀的参数组合。这样一个参数组合在全数据上表现优异的可能性是非常大的，同时也可能展现出比网格/随机搜索得出的参数更大的泛化能力。

局限性：

1.   对半搜索算法在开头的时候，就用最小的子集筛掉了最多的参数组合。如果最初的子集与全数据集的分布差异巨大的化，在对半搜索开头的前几次迭代中，就可能筛掉许多对全数据集D有效的参数，因此对半网格搜索最初的子集一定不能太小；
2.   在初始子集不能太小、且对半搜索的抽样是不放回抽样的大前提下，**整体数据的样本量必须要很大**。

```python
from sklearn.experimental import enable_halving_search_cv
from sklearn.model_selection import KFold, HalvingGridSearchCV
```

|            Name            |                         Description                          |
| :------------------------: | :----------------------------------------------------------: |
|         estimator          |                      调参对象，某评估器                      |
|         param_grid         |            参数空间，可以是字典或者字典构成的列表            |
|         **factor**         | 每轮迭代中新增的样本量的比例，同时也是每轮迭代后留下的参数组合的比例 |
|        **resource**        |              设置每轮迭代中增加的验证资源的类型              |
|     **max_resources**      |     在一次迭代中，允许被用来验证任意参数组合的最大样本量     |
|     **min_resources**      |            首次迭代时，用于验证参数组合的样本量r0            |
| **aggressive_elimination** | 是否以全部数被使用完成作为停止搜索的指标，如果不是，则采取措施 |
|             cv             |                        交叉验证的折数                        |
|          scoring           |                评估指标，支持同时输出多个参数                |
|           refit            |        挑选评估指标和最佳参数，在完整数据集上进行训练        |
|        error_score         | 当网格搜索报错时返回结果，选择'raise'时将直接报错并中断训练过程<br>其他情况会显示警告信息后继续完成训练 |
|     return_train_score     |             在交叉验证中是否显示训练集中参数得分             |
|      **random_state**      |                  控制随机抽样数据集的随机性                  |
|           n_jobs           |                  设置工作时参与计算的线程数                  |
|          verbose           |                       输出工作日志形式                       |

-   `factor`：每轮迭代中新增的样本量的比例，同时也是每轮迭代后留下的参数组合的比例。例如，当`factor=2`时，下一轮迭代的样本量会是上一轮的2倍，每次迭代后有1/2的参数组合被留下。如果`factor=3`时，下一轮迭代的样本量会是上一轮的3倍，每次迭代后有1/3的参数组合被留下。该参数通常取3时效果比较好
-   `resource`：设置每轮迭代中增加的验证资源的类型，默认是`n_samples`样本量。也可以是任意集成算法当中输入正整数的弱分类器，例如"n_estimators"或者"n_iteration"。
-   `min_resource`：首次迭代时，用于验证参数组合的样本量r0。
    -   输入正整数`n`，表示首次迭代时使用n个样本
    -   输入"`smallest`"，则根据规则计算r0:
        -   当资源类型是样本量时，对回归类算法，r0 = 交叉验证折数 * 2
        -   当资源类型是样本量时，对分类算法，r0 = 类别数量n_classes_ * 交叉验证折数n_splits * 2
        -   当资源类型不是样本量时，等于1
    -   输入"`exhaust`"，则根据迭代最后一轮的最大可用资源倒推r0
        -   例如，factor=2, 样本量为1000，假如一共迭代3次，则最后一轮迭代的最大可用资源为1000，倒数第二轮为500，倒数第三轮（第一轮）为250。此时r0 = 250。"exhaust"模式下最有可能得到好的结果，不过计算量会略大，计算时间会略长。
-   `aggressive_elimination`：默认为False，以全部样本被用完作为搜索结束的指标。设置为True时，会重复使用首次迭代时的样本量，直到剩下的数据足以支撑样本量的增加直到只剩下最后一组备选参数。当数据总样本量较小时，打开该参数。

>   1、min_resources的值不能太小，且在全部迭代过程结束之前，我们希望使用尽量多的数据；
>
>   2、迭代完毕之后，剩余的验证参数组合不能太多，10以下最佳，如果无法实现，则30以下也可以接受；
>
>   3、迭代次数不能太多，否则时间可能会太长。

```python
factor = 1.5
n_samples = X.shape[0]
min_resources = 500
space = 1536
for i in range(100):
    if (min_resources*factor**i > n_samples) or (space/factor**i < 1):
        break
    print(i+1,"本轮迭代样本:{}".format(min_resources * factor ** i)
          ,"本轮验证参数组合:{}".format(space // factor ** i + 1))
```

#### 11.4  AutoML

> 已实现的自动化框架：
>
> - 自动化数据预处理框架：[MLBoX](https://github.com/AxeldeRomblay/MLBox)
> - 自动化模型选择框架：[H20 AutoML](http://docs.h2o.ai/h2o/latest-stable/h2o-docs/automl.html)
> - 自动化超参数优化框架：[Bayesian Optimization](https://github.com/fmfn/BayesianOptimization)，[Hyperopt](https://github.com/hyperopt/hyperopt)，[DEAP](https://github.com/DEAP/deap)，[Optuna](https://github.com/optuna/optuna)
> - 自动化stacking融合：[AutoGluon](https://auto.gluon.ai/stable/index.html)
> - 自动化管道结构优化（基于遗传算法）：[TPOT](http://epistasislab.github.io/tpot/)
> - 自动化神经网络架构构建：[Auto-PyTorch](https://github.com/automl/Auto-PyTorch)，[AutoKeras](https://autokeras.com/)
> - 综合性自动化建模：[AutoWEKA](http://www.cs.ubc.ca/labs/beta/Projects/autoweka/)，[Auto-sklearn](https://automl.github.io/auto-sklearn/master/)，[hpsklearn](https://hyperopt.github.io/hyperopt-sklearn/)

-   **AutoWEKA只支持Java**

    AutoWEKA底层是基于WEKA所构建，而WEKA只有Java才能调用，因此AutoWEKA拓展性较差，不适用Java以外语言

-   **Auto-sklearn不支持windows**

    Auto-sklearn底层是基于linux中的resorce模块运行，因此不支持Windows系统，也不能完全支持Mac系统

-   **hpsklearn缺乏维护，年久失修**

    hpsklearn底层是基于sklearn，代码简单但缺乏维护，年久失修，时至今日一些基本的代码（如fit）运行还会报错

#### 11.5  贝叶斯优化

>   网格搜索、随机网格搜索与Halving网格搜索，无论具体每种网格搜索的思想如何变化，网格优化都是在一个大参数空间中、尽量对所有点进行验证后再返回最优损失函数值的方法，这一类方法在计算量与计算时间上有着不可避免的缺陷，因此才会有随机、Halving等试图缩短训练时间、让整体网格搜索更加适合于大型数据和大型空间的手段。然而，尽管sklearn在提高网格搜索效率方面做出了种种优化，但上述方法仍然无法在效率和精度上做到双赢，若希望更快速的进行参数搜索、并且搜索出一组泛化能力尽可能强的参数，目前的常见做法还是选用一些带有**先验过程**的调参工具，即一些基于贝叶斯过程调参工具。

##### 11.5.1  常用求函数最小值的方法

1.   对$f(x)$求导、令其一阶导数为0来求解其最小值

     **函数$f(x)$可微，且微分方程可以直接被求解**

2.   通过梯度下降等优化方法迭代出$f(x)$的最小值

     **函数$f(x)$可微，且函数本身为凸函数**

3.   将全域的$x$带入$f(x)$计算出所有可能的结果，再找出最小值

     **函数$f(x)$相对不复杂、自变量维度相对低、计算量可以承受**

##### 11.5.2  异常复杂的函数求最小值

**假设现在函数$f(x)$是一个平滑均匀的函数，但它异常复杂、且不可微，我们无法使用上述三种方法中的任意一种方法求解**。

>   可以从中随机抽样部分观测点来观察整个函数可能存在的趋势。

1.   选择在$x$的定义域上随机选择了4个点，并将4个点带入$f(x)$进行计算，得到了如下结果：

     <img src="https://cdn.jsdelivr.net/gh/louisyanglu/images/images/01.png" style="zoom: 67%;" />

2.   现在有了这4个观测值，大部分人会倾向于认为，最小值点可能非常接近于已观测出4个$f(x)$值中最小的那个值，但也有许多人不这么认为。当我们有了4个观测值，并且知道我们的函数是相对均匀、平滑的函数，那我们可能对函数的整体分布有如下猜测：当我们对函数整体分布有一个猜测时，这个分布上一定会存在该函数的最小值：

     <img src="https://cdn.jsdelivr.net/gh/louisyanglu/images/images/02.png" style="zoom: 67%;" />

     不同的人可能对函数的整体分布有不同的猜测，不同猜测下对应的最小值也是不同的：

     <img src="https://cdn.jsdelivr.net/gh/louisyanglu/images/images/03.png" style="zoom: 67%;" />

     假设我们邀请了数万个人对该问题做出猜测，每个人所猜测的曲线如下图所示。不难发现，在观测点的附近，每个人猜测的函数值差距不大，但是在远离观测点的地方，每个人猜测的函数值就高度不一致了：

     <img src="https://cdn.jsdelivr.net/gh/louisyanglu/images/images/05.png" style="zoom: 67%;" />

3.   我们将所有猜测求均值，得到一条黑色的实线。并将实线周围的潜在函数值所在的区域用色块表示。色块所覆盖的范围其实就是大家猜测的函数值的上界和下界。上下界差异越大，表示人们对函数上该位置的猜测值的越不确定，**色块范围越大，置信度越低**：

     <img  src="https://cdn.jsdelivr.net/gh/louisyanglu/images/images/06.png?versionId=CAEQIBiBgMC_i.png"  style="zoom:  67%;"  />

4.   在观测点周围，置信度总是很高的，远离观测点的地方，置信度总是很低，所以如果我们能够在置信度很低的地方补充一个实际的观测点，围绕该区间的“猜测”会立刻变得集中，该区间内的置信度会大幅升高:

     <img  src="https://cdn.jsdelivr.net/gh/louisyanglu/images/images/08.png"  style="zoom:  67%;"  />

5.   当整个函数上的置信度都非常高时，我们可以说我们得出了一条与真实的$f(x)$曲线高度相似的曲线$f^*$。

     如何才能够让$f^*$更接近$f(x)$呢？根据我们刚才提升置信度的过程，很明显——观测点越多，我们估计出的曲线会越接近真实的$f(x)$。然而，由于计算量有限，我们每次进行观测时都要非常谨慎地选择观测点。那现在，**如何选择观测点才能够最大程度地帮助我们估计出$f(x)$的最小值呢？**

     最简单的手段是使用**最小值出现的频数**进行判断。不同的人对函数的整体分布有不同的猜测，不同猜测下对应的最小值也是不同的，我们在$X$轴上将定义域区间均匀划分为100个小区间，如果有某个猜测的最小值落在其中一个区间中，我们就对该区间进行计数。频数越高，说明猜测最小值在该区间内的人越多，反之则说明该猜测最小值在该区间内的人越少。**频数一定程度上反馈出最小值出现的概率，频数越高的区间，函数真正的最小值出现的概率越高**。

     当我们将$X$轴上的区间划分得足够细后，绘制出的频数图可以变成概率密度曲线：**曲线的最大值所对应的点是$f(x)$的最小值的概率最高**，**因此，我们应该将曲线最大值所对应的点确认为下一个观测点。**

     <img  src="https://cdn.jsdelivr.net/gh/louisyanglu/images/images/09.png"  style="zoom:  67%;"  />

     <img  src="https://cdn.jsdelivr.net/gh/louisyanglu/images/images/07.png"  style="zoom:  67%;"  />

     根据图像，我们知道最小值最有可能在的区间就在x=0.7左右的位置。当我们不取新的观测点时，现在$f(x)$上可以获得的可靠的最小值就是x=0.6时的点，但我们如果在x=0.7处取新的观测值，我们就很有可能找到比当前x=0.6的点还要小的$f_{min}$。因此，我们可以在x=0.7处进行下一次观测。

6.   当我们在x=0.7处取出观测值之后，我们就有了5个已知的观测点。现在，我们再让数万人根据5个已知的观测点对整体函数分布进行猜测，猜测完毕之后再计算当前最小值频数最高的区间，然后再取新的观测点对$f(x)$进行计算。当允许的计算次数被用完之后（比如，500次），整个估计也就停止了。

     在这个过程当中，我们其实在不断地优化我们对目标函数$f(x)$的估计，虽然没有对$f(x)$进行全部定义域上的计算，也没有找到最终确定一定是$f(x)$分布的曲线，但是随着我们观测的点越来越多，我们对函数的估计是越来越准确的，因此也有越来越大的可能性可以估计出$f(x)$真正的最小值。**这个优化的过程，就是贝叶斯优化**。

##### 11.5.3  序贯模型优化（SMBO）

1.   定义需要估计的$f(x)$以及$x$的定义域

     -   在HPO过程当中，需要定义的$f(x)$一般是交叉验证的结果/损失函数的结果，而我们往往非常清楚损失函数的表达式，只是我们不了解损失函数内部的具体规律，因此HPO中的$f(x)$不能算是严格意义上的黑盒函数（black box function，也译作黑箱函数，即只知道$x$与$f(x)$的对应关系，却丝毫不知道函数内部规律、同时也不能写出具体表达式的一类函数）

     -   在HPO中，自变量$x$就是超参数空间

2.   取出有限的n个$x$上的值，求解出这些$x$对应的$f(x)$（求解观测值）

     -   最初的观测值数量n、以及最终可以取到的最大观测数量m都是贝叶斯优化的超参数，最大观测数量m也决定了整个贝叶斯优化的迭代次数

3.   根据有限的观测值，对函数进行估计（该假设被称为贝叶斯优化中的先验知识），得出该估计$f^*$上的目标值（最大值或最小值）

     -   根据有限的观测值、对函数分布进行估计的工具被称为**概率代理模型**（Probability Surrogate model）。**这些概率代理模型自带某些假设，他们可以根据廖廖数个观测点估计出目标函数的分布$f^*$**（包括$f^*$上每个点的取值以及该点对应的置信度）。概率代理模型往往是一些强大的算法，最常见的比如高斯过程、高斯混合模型等等。传统数学推导中往往使用高斯过程，但现在最普及的优化库中基本都默认使用基于**高斯混合模型的TPE过程**。

4.   定义某种规则，以确定下一个需要计算的观测点

     -   用来确定下一个观测点的规则被称为**采集函数**（Aquisition Function），采集函数衡量观测点对拟合$f^*$所产生的影响，并选取影响最大的点执行下一步观测，因此我们往往关注**采集函数值最大的点**。

     -   常见的采集函数主要是概率增量PI（Probability of improvement，比如我们计算的频数）、期望增量EI（Expectation Improvement）、置信度上界UCB（Upper Confidence Bound）、信息熵（Entropy）等等。默认期望增量EI。

         <img  src="https://cdn.jsdelivr.net/gh/louisyanglu/images/images/11.png"  style="zoom:  67%;"  />

##### 11.5.4  bayes_opt

`pip install bayesian-optimization`

>   当且仅当我们必须要实现**基于高斯过程**的贝叶斯优化，且算法的参数空间中带有**大量连续型参数**时，我们才会优先考虑Bayes_opt（https://github.com/fmfn/BayesianOptimization）。

效率不足：

-   没有提前停止机制
-   只能够在参数空间提取浮点数。如即便在10次不同的迭代中`n_estimators`分别取到了[88.89, 88.23, 88.16, 88.59……]等值，在取整之后也只能够获得一个备选值88，但bayes_opt无法辨别这种区别。

**实现过程**：

1.   定义目标函数
     -   **目标函数的输入必须是具体的超参数，而不能是整个超参数空间，也不能是X、y具体的数据**
     -   **超参数的输入值只能是浮点数，不支持整数与字符串**
     -   **只支持寻找$f(x)$的最大值，不支持寻找最小值**
2.   定义参数空间
     -   超参数组合会被输入我们定义好的目标函数$f(x)$中，一组一组进行训练
     -   使用字典方式来定义参数空间，参数的取值范围为**双向闭区间**，因此bayes_opt会直接取出闭区间中任意浮点数作为备选参数
     -   只支持填写参数空间的**上界与下界**，不支持填写步长等参数，且bayes_opt会将所有参数都当作**连续型超参**进行处理
3.   定义优化目标函数的具体流程
     -   在任意贝叶斯优化算法的实践过程中，一定都有涉及到随机性的过程——例如，随机抽取点作为观测点，随机抽样部分观测点进行采集函数的计算等等。**在大部分优化库当中，这种随机性是无法控制的**。我们可以尝试填写随机数种子，但需要记住优化算法每次运行时一定都会不一样
     -   优化算法无法被复现，但是优化算法得出的最佳超参数的结果却是可以被复现的
4.   定义验证函数（非必须）
     -   对优化算法给出的最优参数进行再验证
     -   **因此原则上来说，只要在目标函数中设置了随机数种子，贝叶斯优化给出的最佳分数一定与我们验证后的分数相同**
5.   执行实际优化流程

```python
from bayes_opt import BayesianOptimization

# 1.定义评估器
def bayesopt_objective(n_estimators, max_depth, max_features, min_impurity_decrease):
    # 需要调整的超参数等于目标函数的输入，不需要调整的超参数则直接等于固定值
    # 默认参数输入一定是浮点数，因此需要套上int函数处理成整数
    reg = RFR(n_estimators = int(n_estimators)
              ,max_depth = int(max_depth)
              ,max_features = int(max_features)
              ,min_impurity_decrease = min_impurity_decrease
              ,random_state=1412
              ,verbose=False  # 可自行决定是否开启森林建树的verbose
              ,n_jobs=-1)
    # 定义损失的输出，5折交叉验证下的结果，输出负根均方误差（-RMSE）
    # 注意，交叉验证需要使用数据，但我们不能让数据X,y成为目标函数的输入
    cv = KFold(n_splits=5,shuffle=True,random_state=1412)
    validation_loss = cross_validate(reg,X,y
                                     ,scoring="neg_root_mean_squared_error"
                                     ,cv=cv
                                     ,verbose=False
                                     ,n_jobs=-1
                                     ,error_score='raise'  # 如果交叉验证中的算法执行报错，则告诉我们错误的理由
                                    )
    # 交叉验证输出的评估指标是负根均方误差，因此本来就是负的损失
    # 目标函数可直接输出该损失的均值
    return np.mean(validation_loss["test_score"])

# 2.定义参数空间
param_grid_simple = {'n_estimators': (80,100)
                     , 'max_depth':(10,25)
                     , "max_features": (10,20)
                     , "min_impurity_decrease":(0,1)
                    }

# 3.定义优化流程
def param_bayes_opt(init_points, n_iter):
    #定义优化器，先实例化优化器
    opt = BayesianOptimization(bayesopt_objective  # 需要优化的目标函数
                               ,param_grid_simple  # 备选参数空间
                               ,random_state=1412  # 随机数种子，虽然无法控制住
                              )
    # 使用优化器，记住bayes_opt只支持最大化
    opt.maximize(init_points = init_points # 抽取多少个初始观测值
                 , n_iter=n_iter # 一共观测/迭代多少次
                )
    # 优化完成，取出最佳参数与最佳分数
    params_best = opt.max["params"]
    score_best = opt.max["target"]
    
    # 打印最佳参数与最佳分数
    print("\n","\n","best params: ", params_best,
          "\n","\n","best cvscore: ", score_best)
    
    # 返回最佳参数与最佳分数
    return params_best, score_best

# 4.定义验证函数
# 5.执行优化流程
start = time.time()
params_best, score_best = param_bayes_opt(20,280)  # 初始看20个观测值，后面迭代280次
print('It takes %s minutes' % ((time.time() - start)/60))
validation_score = bayes_opt_validation(params_best)
print("\n","\n","validation_score: ",validation_score)
```

##### 11.5.5  hyper_opt

>   Hyperopt中集成了包括随机搜索、模拟退火和TPE（Tree-structured Parzen Estimator Approach）等多种优化算法，是最常用来实现TPE方法的优化器。相比基于高斯过程的贝叶斯优化，基于高斯混合模型的TPE在大多数情况下以更高效率获得更优结果。

1.   定义目标函数

     -   **目标函数的输入必须是符合hyperopt规定的字典**；
     -   **Hyperopt只支持寻找$f(x)$的最小值，不支持寻找最大值**。

2.   定义参数空间

     -   超参数组合会被输入我们定义好的目标函数$f(x)$中，一组一组进行训练；

     -   使用特殊的字典形式来定义参数空间，其中键值对上的键可以任意设置，只要与目标函数中索引参数的键一致即可，键值对的值则是hyperopt独有的hp函数：

         > **hp.quniform("参数名称", 下界, 上界, 步长)** - 适用于均匀分布的浮点数
         >
         > **hp.uniform("参数名称",下界, 上界)** - 适用于随机分布的浮点数
         >
         > **hp.randint("参数名称",上界)** - 适用于[0,上界)的整数，区间为前闭后开
         >
         > **hp.choice("参数名称",["字符串1","字符串2",...])** - 适用于字符串类型，最优参数由索引表示
         >
         > **hp.choice("参数名称",[\*range(下界，上界，步长)])** - 适用于整数型，最优参数由索引表示
         >
         > **hp.choice("参数名称",[整数1,整数2,整数3,...])** - 适用于整数型，最优参数由索引表示
         >
         > **hp.choice("参数名称",["字符串1",整数1,...])** - 适用于字符与整数混合，最优参数由索引表示

         ![hyperopt hp函数](https://cdn.jsdelivr.net/gh/louisyanglu/images/images/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTI3MzU3MDg=,size_16,color_FFFFFF,t_70.png)

         **‼️常常会使用quniform获得均匀分布的浮点数来替代整数**。
         
         对于连续型整数搜索空间采用了quniform的方法进行创建，通过该方法创建的搜索空间最终返回最优解将是一个空间内最优解取值，而非最优解的索引值，如此一来，相比choice创建的搜索空间（返回的是索引），使用quniform则可在定义目标函数时不再区分训练状态和测试状态不同的超参数读取流程。
         
         但这里由两点需要注意：其一，quniform默认是在连续变量之间搜索，虽然通过设置步长可以锁定在几个整数值之间搜索，但默认仍然是假定搜索空间是连续分布的，对于贝叶斯估计来说，尽管对连续分布空间的估计会更快，但连续分布中的估计方式并不适用于本质上仍然是离散取值的一组变量，因此（相比choice方法）估计的**精度会下降**；其二，quniform创建的搜索空间，每次读取的超参数取值都是连续型变量，需要将其**转化为整型**再输出到模型中，否则模型将无法读取参数。

3.   定义优化目标函数的具体流程

     -   有了目标函数和参数空间，接下来我们就可以进行优化了。在Hyperopt中，我们用于优化的基础功能叫做fmin，在fmin中，我们可以自定义使用的代理模型（参数`algo`），一般来说我们有`tpe.suggest`以及`rand.suggest`两种选项，前者指代TPE方法，后者指代随机网格搜索方法。我们还可以通过partial功能来修改算法涉及到的具体参数，包括模型具体使用了多少个初始观测值（参数`n_start_jobs`），以及在计算采集函数值时究竟考虑多少个样本（参数`n_EI_candidates`）
     -   除此之外，Hyperopt当中还有两个值得注意的功能，一个记录整个迭代过程的`trials`，另一个是提前停止参数`early_stop_fn`。其中，`trials`直译为“实验”或“测试”，表示我们不断尝试的每一种参数组合，这个参数中我们一般输入从hyperopt库中导入的方法Trials()，当优化完成之后，我们可以从保存好的trials中查看损失、参数等各种中间信息；而提前停止参数`early_stop_fn`中我们一般输入从hyperopt库导入的方法no_progress_loss()，这个方法中可以输入具体的数字n，表示当损失连续n次没有下降时，让算法提前停止。

4.   定义验证函数（非必须）

     -   对优化算法给出的最优参数进行再验证
     -   **因此原则上来说，只要在目标函数中设置了随机数种子，贝叶斯优化给出的最佳分数一定与我们验证后的分数相同**

5.   执行实际优化流程

```python
import hyperopt
from hyperopt import hp, fmin, tpe, Trials, partial
from hyperopt.early_stop import no_progress_loss

# 1.定义目标函数
def hyperopt_objective(params):
    # 定义评估器
    # 需要搜索的参数需要从输入的字典中索引出来
    # 不需要搜索的参数，可以是设置好的某个值
    # 在需要整数的参数前调整参数类型
    reg = RFR(n_estimators = int(params["n_estimators"])
              ,max_depth = int(params["max_depth"])
              ,max_features = int(params["max_features"])
              ,min_impurity_decrease = params["min_impurity_decrease"]
              ,random_state=1412
              ,verbose=False
              ,n_jobs=-1)
    # 交叉验证结果，输出负根均方误差（-RMSE）
    cv = KFold(n_splits=5,shuffle=True,random_state=1412)
    validation_loss = cross_validate(reg,X,y
                                     ,scoring="neg_root_mean_squared_error"
                                     ,cv=cv
                                     ,verbose=False
                                     ,n_jobs=-1
                                     ,error_score='raise'
                                    )
    # 最终输出结果，由于只能取最小值，所以必须对（-RMSE）求绝对值
    # 以求解最小RMSE所对应的参数组合
    return np.mean(abs(validation_loss["test_score"]))

# 2.定义参数空间
param_grid_simple = {'n_estimators': hp.quniform("n_estimators",80,100,1)
                     , 'max_depth': hp.quniform("max_depth",10,25,1)
                     , "max_features": hp.quniform("max_features",10,20,1)
                     , "min_impurity_decrease":hp.quniform("min_impurity_decrease",0,5,1)
                    }

# 3.定义优化流程
def param_hyperopt(max_evals=1000):
    # 保存迭代过程
    trials = Trials()
    # 设置提前停止
    early_stop_fn = no_progress_loss(50)
    # 定义代理模型
    # algo = partial(tpe.suggest, n_startup_jobs=20, n_EI_candidates=50)
    params_best = fmin(hyperopt_objective  # 目标函数
                       , space = param_grid_simple  # 参数空间
                       , algo = tpe.suggest  # 代理模型你要哪个呢？
                       #, algo = algo
                       , max_evals = max_evals  # 允许的迭代次数
                       , verbose=True
                       , trials = trials
                       , early_stop_fn = early_stop_fn
                      )
    # 打印最优参数，fmin会自动打印最佳分数
    print("\n","\n","best params: ", params_best,
          "\n")
    return params_best, trials

# 4.执行优化流程
params_best, trials = param_hyperopt(1000)
trials.trials[0]  # 打印所有搜索相关的记录
trials.losses()[:10]  # 打印全部搜索的目标函数值
```

##### 11.5.6  optuna

>   Optuna是目前为止最为成熟、拓展性最强的超参数优化框架，是专门为机器学习和深度学习所设计。https://github.com/optuna/optuna

1.   定义目标函数与参数空间

     -   Optuna的目标函数相当特别。在其他优化库中，我们需要单独输入参数或参数空间，优化器会在具体优化过程中将参数空间一一放入我们的目标函数进行优化，但在Optuna中，我们并不需要将参数或参数空间输入目标函数；

     -   **直接在目标函数中定义参数空间**

         -   `suggest_int`：如果您的超参数接受一系列整数类型的数值。

         -   `suggest_categorical`：如果您的超参数接受分类值的选择。

         -   `suggest_uniform`：如果您的超参数接受一系列数值，并且您希望对每个值进行同样的采样。

         -   `suggest_loguniform`：如果您的超参数接受一系列数值，并且您希望在对数域中对每个值进行同样的采样。

         -   `suggest_discrete_uniform`：如果您的超参数接受特定区间内的一系列数值，并且您希望每个值都以同样的可能性进行采样。

         -   `suggest_float`：如果您的超参数接受一系列浮点类型的数值

             ![optuna变量类型](https://cdn.jsdelivr.net/gh/louisyanglu/images/images/optuna%E5%8F%98%E9%87%8F%E7%B1%BB%E5%9E%8B.PNG)

     -   特别的是，Optuna优化器会生成一个指代备选参数的变量trial，该变量无法被用户获取或打开，但该变量在优化器中生存，并被输入到目标函数。在目标函数中，我们可以通过变量trail所携带的方法来构造参数空间

     -   支持最大化、最小化目标函数

2.   定义优化目标函数的具体流程

     -   大部分备选的算法都集中在Optuna的模块sampler中，包括我们熟悉的TPE优化、随机网格搜索以及其他各类更加高级的贝叶斯过程
     -   对于Optuna.sampler中调出的类，我们也可以直接输入参数来设置初始观测值的数量、以及每次计算采集函数时所考虑的观测值量
     -   在Optuna库中并没有集成实现高斯过程GP的方法，但我们可以从scikit-optimize里面导入高斯过程来作为optuna中的`algo`设置

3.   执行实际优化流程

     -   当参数空间较小时，Optuna库在迭代中容易出现抽样BUG。**Optuna会持续抽到曾经被抽到过的参数组合**，并且持续报警告说"算法已在这个参数组合上检验过目标函数了"

         ```python
         import warnings
         warnings.filterwarnings('ignore', message='The objective has been evaluated at this point before.')
         ```

     -   默认打印迭代过程，可手动关闭

         ```python
         optuna.logging.set_verbosity(optuna.logging.ERROR) #关闭自动打印的info，只显示进度条
         # optuna.logging.set_verbosity(optuna.logging.INFO)
         ```

```python
import optuna

# 1.定义目标函数与参数空间
def optuna_objective(trial):
    # 定义参数空间
    n_estimators = trial.suggest_int("n_estimators",80,100,1)  # 整数型，(参数名称，下界，上界，步长)
    max_depth = trial.suggest_int("max_depth",10,25,1)
    max_features = trial.suggest_int("max_features",10,20,1)
    # max_features = trial.suggest_categorical("max_features",["log2","sqrt","auto"])  # 字符型
    min_impurity_decrease = trial.suggest_int("min_impurity_decrease",0,5,1)
    # min_impurity_decrease = trial.suggest_float("min_impurity_decrease",0,5,log=False)  # 浮点型
    
    # 定义评估器
    # 需要优化的参数由上述参数空间决定
    # 不需要优化的参数则直接填写具体值
    reg = RFR(n_estimators = n_estimators
              ,max_depth = max_depth
              ,max_features = max_features
              ,min_impurity_decrease = min_impurity_decrease
              ,random_state=1412
              ,verbose=False
              ,n_jobs=-1
             )
    
    # 交叉验证过程，输出负均方根误差(-RMSE)
    # optuna同时支持最大化和最小化，因此如果输出-RMSE，则选择最大化
    # 如果选择输出RMSE，则选择最小化
    cv = KFold(n_splits=5,shuffle=True,random_state=1412)
    validation_loss = cross_validate(reg,X,y
                                     ,scoring="neg_root_mean_squared_error"
                                     ,cv=cv  # 交叉验证模式
                                     ,verbose=False  # 是否打印进程
                                     ,n_jobs=-1  # 线程数
                                     ,error_score='raise'
                                    )
    # 最终输出RMSE
    return np.mean(abs(validation_loss["test_score"]))

# 2.定义优化流程
def optimizer_optuna(n_trials, algo):
    
    # 定义使用TPE或者GP
    if algo == "TPE":
        algo = optuna.samplers.TPESampler(n_startup_trials = 10, n_ei_candidates = 24)
    elif algo == "GP":

        from optuna.integration import SkoptSampler
        import skopt
        
        algo = SkoptSampler(skopt_kwargs={'base_estimator':'GP',  # 选择高斯过程
                                          'n_initial_points':10,  # 初始观测点10个
                                          'acq_func':'EI'}  # 选择的采集函数为EI，期望增量
                           )
    
    # 实际优化过程，首先实例化优化器
    study = optuna.create_study(sampler = algo  # 要使用的具体算法
                                , direction="minimize"  # 优化的方向，可以填写minimize 或 maximize
                               )

    # 开始优化，n_trials为允许的最大迭代次数
    # 由于参数空间已经在目标函数中定义好，因此不需要输入参数空间
    study.optimize(optuna_objective  # 目标函数
                   , n_trials=n_trials  # 最大迭代次数（包括最初的观测值的）
                   , show_progress_bar=True  # 要不要展示进度条呀？
                  )
    # 可直接从优化好的对象study中调用优化的结果
    # 打印最佳参数与最佳损失值
    print("\n","\n","best params: ", study.best_trial.params,
          "\n","\n","best score: ", study.best_trial.values,
          "\n")
    return study.best_trial.params, study.best_trial.values

# 3.执行优化流程
best_params, best_score = optimizer_optuna(10,"GP")  # 默认打印迭代过程
```

**清除无望 trial 的 LightGBM 回调函数**

`optuna.integration.LightGBMPruningCallback`

```python
"""
Optuna example that demonstrates a pruner for LightGBM.
In this example, we optimize the validation accuracy of cancer detection using LightGBM.
We optimize both the choice of booster model and their hyperparameters. Throughout
training of models, a pruner observes intermediate results and stop unpromising trials.
You can run this example as follows:
    $ python lightgbm_integration.py
"""
import numpy as np
import optuna

import lightgbm as lgb
import sklearn.datasets
import sklearn.metrics
from sklearn.model_selection import train_test_split


# FYI: Objective functions can take additional arguments
# (https://optuna.readthedocs.io/en/stable/faq.html#objective-func-additional-args).
def objective(trial):
    data, target = sklearn.datasets.load_breast_cancer(return_X_y=True)
    train_x, valid_x, train_y, valid_y = train_test_split(data, target, test_size=0.25)
    dtrain = lgb.Dataset(train_x, label=train_y)
    dvalid = lgb.Dataset(valid_x, label=valid_y)

    param = {
        "objective": "binary",
        "metric": "auc",
        "verbosity": -1,
        "boosting_type": "gbdt",
        "lambda_l1": trial.suggest_float("lambda_l1", 1e-8, 10.0, log=True),
        "lambda_l2": trial.suggest_float("lambda_l2", 1e-8, 10.0, log=True),
        "num_leaves": trial.suggest_int("num_leaves", 2, 256),
        "feature_fraction": trial.suggest_float("feature_fraction", 0.4, 1.0),
        "bagging_fraction": trial.suggest_float("bagging_fraction", 0.4, 1.0),
        "bagging_freq": trial.suggest_int("bagging_freq", 1, 7),
        "min_child_samples": trial.suggest_int("min_child_samples", 5, 100),
    }

    # Add a callback for pruning.
    # 用于清除无望 trial 的 LightGBM 回调函数。
    pruning_callback = optuna.integration.LightGBMPruningCallback(trial, "auc")  # Callback for LightGBM to prune unpromising trials.
    # pruning_callback = optuna.integration.XGBoostPruningCallback(trial, "validation-auc")  # Callback for XGBoost to prune unpromising trials.
    gbm = lgb.train(param, dtrain, valid_sets=[dvalid], callbacks=[pruning_callback])

    preds = gbm.predict(valid_x)
    pred_labels = np.rint(preds)
    accuracy = sklearn.metrics.accuracy_score(valid_y, pred_labels)
    return accuracy


if __name__ == "__main__":
    # Add stream handler of stdout to show the messages
    optuna.logging.get_logger("optuna").addHandler(logging.StreamHandler(sys.stdout))
    
    study = optuna.create_study(
        pruner=optuna.pruners.MedianPruner(n_warmup_steps=10),  # 剪枝
        direction="maximize"
    )
    study.optimize(objective, n_trials=100)

    print("Number of finished trials: {}".format(len(study.trials)))

    print("Best trial:")
    trial = study.best_trial

    print("  Value: {}".format(trial.value))

    print("  Params: ")
    for key, value in trial.params.items():
        print("    {}: {}".format(key, value))
```

**用于 LightGBM 的超参数调参器**

`optuna.integration.lightgbm.LightGBMTuner()`

```python
"""
Optuna example that optimizes a classifier configuration for cancer dataset using LightGBM tuner.
In this example, we optimize the cross-validated log loss of cancer detection.
"""
import optuna.integration.lightgbm as lgb

from lightgbm import early_stopping
from lightgbm import log_evaluation
import sklearn.datasets
from sklearn.model_selection import KFold


if __name__ == "__main__":
    data, target = sklearn.datasets.load_breast_cancer(return_X_y=True)
    dtrain = lgb.Dataset(data, label=target)

    params = {
        "objective": "binary",
        "metric": "binary_logloss",
        "verbosity": -1,
        "boosting_type": "gbdt",
    }

    tuner = lgb.LightGBMTunerCV(
        params,
        dtrain,
        folds=KFold(n_splits=3),
        callbacks=[early_stopping(100), log_evaluation(100)],
    )

    tuner.run()

    print("Best score:", tuner.best_score)
    best_params = tuner.best_params
    print("Best params:", best_params)
    print("  Params: ")
    for key, value in best_params.items():
        print("    {}: {}".format(key, value))
```

**可视化**

-   `optuna.visualization.plot_intermediate_values(study)`：绘制一个 study 中所有 trial 的中间值，Visualize the learning curves of the trials
-   `optuna.visualization.plot_optimization_history(study)`：绘制一个 study 中所有 trial 的优化历史记录，有助于查看哪个试验是最佳试验
-   `optuna.visualization.plot_param_importances(study)`：绘制超参数重要性
    -   `plot_param_importances(study, target=lambda t: t.duration.total_seconds(), target_name="duration")`：Learn which hyperparameters are affecting the trial duration with hyperparameter importance
-   `optuna.visualization.plot_parallel_coordinate(study)`：Visualize high-dimensional parameter relationships
    -   `plot_parallel_coordinate(study, params=["bagging_freq", "bagging_fraction"])`：Select parameters to visualize.
-   `optuna.visualization.plot_contour(study)`：Visualize hyperparameter relationships
    -   `plot_contour(study, params=["bagging_freq", "bagging_fraction"])`：Select parameters to visualize.
-   `plot_slice(study)`：将study中的参数关系绘制成切片图
    -   `plot_slice(study, params=["bagging_freq", "bagging_fraction"])`

<div style="page-break-after:always"></div>

------

### 第12章  Adaboost

>   对于任意Boosting算法，我们都需要明确以下几点：
>
>   -   损失函数$L(x,y)$的表达式是什么？损失函数如何影响模型构建？
>   -   弱评估器$f(x)$ 是什么，当下boosting算法使用的具体建树过程是什么？
>   -   综合集成结果$H(x)$是什么？集成算法具体如何输出集成结果？
>   -   是加权求和吗？如果是，加权求和中的权重如何求解？
>   -   训练过程中，拟合的数据$X$与$y$分别是什么？
>   -   模型训练到什么时候停下来最好？

#### 12.1  Adaboost贡献

1.   首次实现根据之前弱评估器的结果**自适应地**影响后续建模过程；
2.   在Boosting算法中，首次实现考虑全部弱评估器结果的输出方式。

#### 12.2  Boosting与Bagging的区别

##### 12.2.1  核心

1.   **Bagging不同算法之间的核心区别在于以不同方式实现“独立性”（随机性）**；
2.   **Boosting的不同算法之间的核心区别就在于上一个弱评估器的评估结果具体如何影响下一个弱评估器的建立过程**。

##### 12.2.2  输出

1.   Bagging算法中统一的回归求平均、分类少数服从多数；
2.   早期的Boosting算法的输出一般是最后一个弱评估器的输出，当代Boosting算法的输出都会考虑整个集成模型中全部的弱评估器。**关于弱评估器的某种结果的加权平均**，其中权重的求解是boosting领域中非常关键的步骤。

|                              | 装袋法 Bagging                                               | 提升法 Boosting                                              |
| ---------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 弱评估器                     | **相互独立**，并行构建                                       | **相互关联**，按顺序依次构建<br>先建弱分类器的预测效果影响后续模型的建立 |
| 建树前的抽样方式             | 样本有放回抽样<br>特征无放回抽样                             | 样本有放回抽样<br>特征无放回抽样<br>先建弱分类器的预测效果可能影响抽样细节 |
| 集成的结果                   | 回归平均<br>分类众数                                         | 每个算法**具有自己独特的规则**，一般来说：<br>(1) 表现为某种分数的加权平均<br>(2) 使用输出函数 |
| 目标                         | **降低方差**<br>提高模型整体的稳定性来提升泛化能力<br>本质是从“平均”这一数学行为中获利 | **降低偏差**<br>提高模型整体的精确度来提升泛化能力<br>相信众多弱分类器叠加后可以等同于强学习器 |
| 单个评估器容易过拟合的时候   | 具有一定的抗过拟合能力                                       | 具有一定的抗过拟合能力                                       |
| 单个评估器的效力比较弱的时候 | 可能失效                                                     | 大概率会提升模型表现                                         |
| 代表算法                     | 随机森林                                                     | 梯度提升树，Adaboost                                         |

#### 12.3  三大基本元素

>   **<font color="green">依据上一个弱评估器$f(x)_{t-1}$的结果，计算损失函数$L(x,y)$，<br>并使用$L(x,y)$自适应地影响下一个弱评估器$f(x)_t$的构建。<br>集成模型输出的结果，受到整体所有弱评估器$f(x)_0$ ~ $f(x)_T$的影响。</font>**

1.   **损失函数$L(x,y)$** ：用以衡量模型预测结果与真实结果的差异；
2.   **弱评估器$f(x)$** ：（一般为）决策树，不同的boosting算法使用不同的建树过程；
3.   **综合集成结果$H(x)$**：即集成算法具体如何输出集成结果。

#### 12.4  Adaboost构筑

**首先，在全样本上建立一棵决策树，根据该决策树预测的结果和损失函数值，增加被预测错误的样本在数据集中的样本权重，并让加权后的数据集被用于训练下一棵决策树**。

上一棵决策树的的结果通过影响样本权重、即影响数据分布来影响下一棵决策树的建立，整个过程是自适应的。当全部弱评估器都被建立后，集成算法的输出$H(x)$等于所有弱评估器输出值的**加权平均**，加权所用的权重也是在建树过程中被自适应地计算出来的。

<img src="https://cdn.jsdelivr.net/gh/louisyanglu/images/images/boostrap-fixed2.png" style="zoom:60%;" />

#### 12.5  Adaboost参数

|            参数             |                   参数含义                   |
| :-------------------------: | :------------------------------------------: |
|     **base_estimator**      |                   弱评估器                   |
|        n_estimators         |           集成算法中弱评估器的数量           |
|      **learning_rate**      |             迭代中所使用的学习率             |
| **algorithm**（分类器专属） |     用于指定分类ADB中使用的具体实现方法      |
|   **loss**（回归器专属）    |       用于指定回归ADB中使用的损失函数        |
|        random_state         | 用于控制每次建树之前随机抽样过程的随机数种子 |

-   参数`base_estimator`

    -   **ADB分类器的默认弱评估器是最大深度为1的“树桩”，ADB回归器的默认评估器是最大深度为3的“树苗”**
    -   可以使用属性`base_estimator_`来查看当前弱评估器
    -   可以使用`estimators_`来查看当前集成模型中所有弱评估器的情况
    -   自建评估器：`base_estimator = DecisionTreeClassifier(max_depth=10, max_features=30)`
        -   为了保证集成算法中的树不一致，AdaBoost会默认消除我们填写在弱评估器中的random_state
    -   **分类任务时，需要是能够输出预测概率的弱评估器**

-   参数`learning_rate`

    -   集成算法的输出$H(x)$往往都是多个弱评估器的输出结果的加权平均结果。但$H(x)$并不是在所有树建好之后才统一加权求解的，而是在算法逐渐建树的过程当中就随着迭代不断计算出来的；
    -   对于样本$x_i$，集成算法当中一共有$T$棵树（也就是参数`n_estimators`的取值），现在正在建立第$t$个弱评估器，则第$t$个弱评估器上$x_i$的结果可以表示为$f_t(x_i)$。假设整个Boosting算法对样本$x_i$输出的结果为$H(x_i)$，则该结果一般可以被表示为$t=1 \rightarrow t=T$过程当中，所有弱评估器结果的加权求和：$$H(x_i) =  \sum_{t=1}^T\phi_tf_t(x_i)$$；
    -   其中，$\phi_t$为第t棵树的权重。对于第$t$次迭代来说，则有：$$H_t(x_i) = H_{t-1}(x_i) + \phi_tf_t(x_i)$$；
    -   每次将本轮建好的决策树加入之前的建树结果时，可以在权重$\phi$前面增加参数$\color{red}\eta$，表示为第t棵树加入整体集成算法时的学习率，对标参数`learning_rate`：$$H_t(x_i) = H_{t-1}(x_i) + \boldsymbol{\color{red}\eta} \phi_tf_t(x_i)$$；
    -   当学习率很大时，$H(x_i)$增长得更快，我们所需的n_estimators更少，当学习率较小时，$H(x_i)$增长较慢，我们所需的n_estimators就更多，因此boosting算法往往会需要在n_estimators与learning_rate当中做出权衡。

-   分类参数`algorithm`

    >   **算法不固定，损失函数固定。**
    >
    >   -   算法可选择"SAMME"与"SAMME.R"两个字符串。这两个字符串分别代表了两种不同的、实现AdaBoost分类的手段；
    >   -   但是损失函数是固定的，只能使用**指数损失函数**（Exponential Loss Function）；
    >   -   分类y标签不是0、1，而是-1、1。

    -   `SAMME`：基于算法输出的具体**分类结果**（例如-1，1，2）进行计算；

    -   `SAMME.R`：在SAMME基础上改进过后、基于弱分配器输出的**概率值**进行计算，能够得到更好的结果；

        -   **二分类**指数损失

            $$L(H(x),y) = e^{-yH^*(x)}$$，y为真实分类，$H^*(x)$则是从集成算法输出的概率结果$H(x)$转换来的向量：$$H^*(x)=\begin{cases}1 & if \ H(x) > 0.5 \\-1 & if \ H(x) < 0.5\end{cases}$$，如果$H(x)$直接输出类别，可不转换。

            >   **根据指数损失的特殊性质，二分类状况下的类别取值只能为-1或1**。因此$y$的取值只能为-1或1。当算法预测正确时，$yH^**(x)$的符号为正，则损失很小。当算法预测错误时，$yH^**(x)$的符号为负，则损失较大。

            <img  src="https://cdn.jsdelivr.net/gh/louisyanglu/images/images/exponential1com.png"  style="zoom:  100%;"  />

        -   **多分类**指数损失

            $$\begin{aligned}L(H(x),y) &=exp \left( -\frac{1}{K}\boldsymbol{y^* · H^*(x)} \right) \\ & = exp \left( -\frac{1}{K}(y^{*1}H^{*1}(x)+y^{*2}H^{*2}(x) \ + \  ... + y^{*k}H^{*k}(x)) \right)\end{aligned}$$

            -   $K$为总类别数，$\boldsymbol{y^*}$与$\boldsymbol{H^*(x)}$都是根据多分类具体情况、以及集成算法实际输出$H(x)$转化出的向量，其中$y^{*1}$与$H^{*1}(x)$的上标1都表示当前类别

            -   一棵决策树我们会输出K个概率，每个样本在第t次建树过程中，都会生成针对于不同类别的结果：

                $$H_{t}^0(x_i) = H_{t-1}^0(x_i) + \phi_tf_t^0(x_i)$$  

                $$H_{t}^1(x_i) = H_{t-1}^1(x_i) + \phi_tf_t^1(x_i)$$  

                $$H_{t}^2(x_i) = H_{t-1}^2(x_i) + \phi_tf_t^2(x_i)$$  

                $$……$$

                $$H_{t}^k(x_i) = H_{t-1}^k(x_i) + \phi_tf_t^k(x_i)$$

                因此，我们可以得到向量$[H^0(x),H^1(x),H^2(x),...,H^k(x)]$，向量中最大值所对应的标签类别k就是多分类算法中的预测标签类别，总共有K个标签。

            -   $$H^*(x)=\begin{cases}1& if \ k = argmaxH(x) \\-\frac{1}{K-1}& if\ k  \neq  argmaxH(x)\end{cases}$$

            -   $$y^*=\begin{cases}1& if \ k=y_i \\-\frac{1}{K-1}& if\  k\neq y_i \end{cases}$$

-   回归参数`loss`

    >   **算法固定，损失函数不固定。**
    >
    >   -   在AdaBoost回归当中，我们能够使用的算法是唯一的。
    >   -   但可以选择三种损失函数："`linear`"（线性）,"`square`"（平方）,"`exponential`"（指数）；
    >   -   线性损失就是我们常说的**MAE**的变体，平方损失就是**MSE**的变体，而指数损失也与分类中的**指数损失**高度相似。

    -   算法：`AdaBoost.R2`

    -   损失函数：

        -   $$D = sup|H(x_i) - y_i|, i = 1,2,...,N$$。

            其中$y_i$为真实标签，$H(x_i)$为预测标签，sup表示“取最大值”，但它与直接写作max的函数的区别在于，max中的元素已是固定的数值，而sup中的元素可以是一个表达式、并让该表达式在i的备选值中循环。上述式子表示，**取出1~N号样本中真实值与预测值差距最大的那一组差异**来作为D的值。

            >   由于D是所有样本中真实值与预测值差异最大的那一组差异，因此任意样本的$L_i$取值范围都只有[0, 1]。

        -   `linear`：线性损失$$L_i = \frac{|H(x_i) - y_i|}{D}$$，

        -   `square`：平方损失$$L_i = \frac{|H(x_i) - y_i|^2}{D^2}$$

        -   `exponential`：指数损失$$L_i = 1 - exp \left( \frac{-|H(x_i) - y_i|}{D} \right)$$

#### 12.6  Adaboost流程

<img src="https://cdn.jsdelivr.net/gh/louisyanglu/images/images/Adaboost%E6%B5%81%E7%A8%8B%EF%BC%88%E6%96%B0%EF%BC%89.png" alt="Adaboost流程（新）" style="zoom:33%;" />

AdaBoost.R2算法是当前AdaBoost实现流程中使用最多的回归类实践方式，它囊括了对数据进行有放回抽样、按损失函数结果调整样本权重、自动计算弱分类器权重、并输出预测结果等AdaBoost算法经典的全流程。假设现有**数据集N，含有样本$M$个，任意样本编号为$i$，同时，弱评估器为决策树$f$，总共学习$T$轮**，则AdaBoost.R2的基本流程如下所示：

1.   **初始化**原始数据集的权重$w_i$，其中任意$w_i = \frac{1}{M}$；

2.   在现有数据集$N$中，**有放回抽样**$M$个样本，构成训练集$N^t$。在每次抽取一个样本时，任意样本被抽中的概率为$P_i^t = \frac{w_i}{\sum w_i}$，很显然，**该概率就是当前样本在训练集$N^t$中的权重**。当从初始权重中抽样时，概率$P_i^1 = \frac{1}{M}$，当后续权重变化时，拥有更大权重的样本被抽中的概率会更大；

3.   在训练集$N^t$上按照**CART树**规则**建立一棵回归树**$f^t$，训练时所拟合的标签为样本的**真实标签**$y^t_i$；

4.   将$N^t$上所有的样本输入$f^t$进行**预测**，得出预测结果$f^t(x_i)$，其中i = 1,2,...M；

5.   计算单一样本$i$上的**损失**函数$L^t_i = L(f^t(x_i),y_i)$，损失函数值域都在[0,1]之间；

     -   求解$D = sup|f^t(x_i) - y_i|, i = 1,2,...,N$

     -   线性损失：$L_i = \frac{|f^t(x_i) - y_i|}{D}$

         平方损失：$L_i = \frac{|f^t(x_i) - y_i|^2}{D^2}$

         指数损失：$L_i = 1 - exp \left( \frac{-|f^t(x_i) - y_i|}{D} \right)$

6.   计算全样本上的**加权平均损失**$\bar{L^t} = \sum_{i=1}^ML_i^tP_i^t$；

     此时$P_i^t$就等于样本的权重。由于$P_i^t = \frac{w_i}{\sum w_i}$，所以$P_i^t$一定位于[0,1]范围内，并且$\sum{P_i^t}, i=1,2,...M$一定为1；

     **当权重之和为1时，加权平均值一定会小于等于单一数值的最大值（同时大于等于单一数值的最小值），因此加权平均的值域不会超出单一平均数的值域；**

     由于所有损失的值域都是[0,1]，因此加权平均值$\bar{L^t}$的值域也是[0,1]。同时，由于损失的最大值为1，而权重$P_i^t$的最大值一定是远远小于1的，因此加权平均值$\bar{L^t}$的最大值一般也是远远小于1的；

     >   二分类：$\bar{L^t} = \sum_{i=1}^MI(H(x_i) \neq y_i)^tP_i^t$
     >
     >   ```python
     >   # Instances incorrectly classified
     >   incorrect = y_predict != y
     >   # Error fraction
     >   estimator_error = np.mean(np.average(incorrect, weights=sample_weight, axis=0))

7.   依据加权平均损失$\bar{L^t}$计算衡量**当前集成算法的置信度评估值**$\beta^t$（计算树的权重，与损失值正相关，越小，置信度越大）；

     $\beta^t = \frac{\bar{L^t}}{1-\bar{L^t} + \lambda}$，其中$\lambda$是为了防止分母为0的常数；

     ![adaboost_beta](https://cdn.jsdelivr.net/gh/louisyanglu/images/images/adaboost_beta.png)

     当**加权平均损失很高时**，**$\beta^t$很大**，因此**置信度小**，当加权平均损失很低时，$\beta^t$很小，因此置信度大。置信度越大，集成算法当前的预测结果越好；

     $\bar{L^t}$的理论值域是[0,1]，因此$\beta^t$的理论值域是[0,$+\infty$]，因此$\beta_t$的值越接近0越好；

     $\bar{L^t}$的实际范围大约都在0.2~0.3之间，因此一般来说$\beta^t$的实际范围基本都是小于1的；

8.   依据置信度评估$\beta_t$**更新样本权重**

     $w_i^{t+1} = w_i^t\beta^{(1-L_i)}$，其中$\beta^t = \frac{\bar{L^t}}{1-\bar{L^t} + \lambda}$

     单一样本的损失越大、$\beta^{(1-L_i)}$也会越大，因此该样本的权重会被更新得越大；

     >   二分类：$w_i^{t+1}=\frac{w_i^t}{Z^t}\times exp(-\phi^ty_iH^t(x_i))$，其中$Z^t=\sum_i[w_i^t\times exp(-\phi^ty_iH^t(x_i))]$

9.   求解迭代过程中**弱分类器$f^t$的权重**；

     $\phi^t = log(\frac{1}{\beta^t})$

     当$\beta$值越接近于0，说明损失越小、置信度越高，则$log(\frac{1}{\beta^t})$的值越大；所以，损失更小的树对应的权重更大，损失更大的树对应的权重更小。

     >   二分类：$\phi^t = \frac{1}{2}log\frac{1-\bar{L^t}+\lambda}{\bar{L^t}}$

10.   求解出当前迭代$t$下**集成算法的输出值**

      $H^t(x_i) = H^{t-1}(x_i) + \eta \phi^t f^t(x_i)$

      >   二分类：$sign(\sum_t\phi^tH^t(x))$，其中$H^t$为第t轮决策树的预测值，$sign=lambda\ x: 1\ if\ x>=0\ else -1$

11.   在步骤2~10中循环，直到迭代次数被使用完毕

理想上来说，Adaboost至少应该迭代到$T$次以满足下列条件：$$\left(\sum_{t:H^t(x) \leq y} log\frac{1}{\beta^t} \right)\ \  \geq \ \ \left(\frac{1}{2}\sum_{t=1}^T log\frac{1}{\beta^t} \right)$$

等同于：$$\left(\sum_{t:H^t(x) \leq y} \phi^t \right)\ \  \geq \ \ \left(\frac{1}{2}\sum_{t=1}^T \phi^t \right)$$

最终算法的输出值是上述等式满足“等于”条件时所对应的$H^t(x)$。对于一个正常迭代的AdaBoost来说，每一轮迭代后获得的$H(x_i)$都是累加结果，因此$H(x_i)$之间应该满足以下关系：$$H^0(x_i) < H^1(x_i) <, ... , < H^T(x_i)$$

在$H^0(x_i)$到$H^T(x_i)$过程中，必然只有部分$H(x_i)$是小于真实标签$y_i$的，假设有$t$次迭代中$H(x_i)$都小于$y_i$，则理想状况下，前$t$次迭代中权重的累加，应该大于0.5 * 所有$T$次迭代中权重的累加。当两者相等时，t就是最佳迭代次数，而$t$对应的$H^t(x)$也就是最佳预测值

<div style="page-break-after:always"></div>

------

### 第13章  GBDT

#### 13.1  GBDT与AdaBoost区别

1.   弱评估器
     -   AdaBoost执行分类任务，其弱评估器是分类器，回归任务用回归器
     -   GBDT**都使用回归器**，分类任务在回归最后一层加Sigmoid/Softmax函数
2.   损失函数$L(x, y)$
     -   AdaBoost损失函数固定选择
     -   GBDT只需要满足**损失函数可微**
3.   影响下一个弱评估器
     -   AdaBoost改变数据分布（样本权重）来间接影响后续弱评估器，即拟合**不同权重的$X$和$y$**
     -   GBDT**拟合残差**，即改变目标来直接影响后续弱评估器，拟合同一权重的$X$和不同的目标$y-H(x)$
4.   抽样
     -   AdaBoost有放回抽样
     -   GBDT允许**对样本和特征进行抽样**来增大评估器之间的随机性，类似于Bagging来降低方差

#### 13.2  GBDT参数

| 类型                   | 参数/属性                                                    |
| ---------------------- | ------------------------------------------------------------ |
| **迭代过程**           | 参数：n_estimators, learning_rate, **<font color="green">loss, alpha, init</font>**<br>属性：<font color="green">**loss\_, init\_, estimators_**</font> |
| **弱评估器结构**       | <font color="green">**criterion**</font>, max_depth, min_samples_split, min_samples_leaf, <br>min_weight_fraction_leaf, max_leaf_nodes,<br>min_impurity_decrease |
| **提前停止**           | 参数：<font color="green">**validation_fraction, n_iter_no_change, tol**</font><br>属性：<font color="green">**n_estimators_**</font> |
| **弱评估器的训练数据** | 参数：subsample, max_features, random_state<br>属性：<font color="green">**oob_improvement, train_score_**</font> |
| **其他**               | ccp_alpha, warm_start                                        |

##### 13.2.1  迭代过程

| 类型         | 参数/属性                                                    |
| ------------ | ------------------------------------------------------------ |
| **迭代过程** | 参数：<br>&emsp;`n_estimators`：集成算法中弱评估器数量，对Boosting算法而言为实际迭代次数<br>&emsp;`learning_rate：Boosting`算法中的学习率，影响弱评估器结果的加权求和过程<br>&emsp;<font color="green">**`loss`, `alpha`**</font>：需要优化的损失函数，以及特定损失函数需要调节的阈值<br>&emsp;<font color="green">**`init`**</font>：初始化预测结果$H_0$的设置<br><br>属性：<br>&emsp;<font color="green">**`loss_`**</font>：返回具体的损失函数对象<br>&emsp;<font color="green">**`init_`**</font>：返回具体的初始化设置<br>&emsp;<font color="green">**`estimators_`**</font>：返回实际建立的评估器列表<br>&emsp;`n_estimators_`：返回实际迭代次数 |


1.   具体迭代次数（弱评估器次数）的参数`n_estimators`与学习率参数`learning_rate`

     -   对于样本$x_i$，集成算法当中一共有$T$棵树，则参数`n_estimators`的取值为T。假设现在正在建立第$t$个弱评估器，则第$t$个弱评估器上$x_i$的结果可以表示为$f_t(x_i)$

     -   假设整个Boosting算法对样本$x_i$输出的结果为$H(x_i)$，则该结果一般可以被表示为t=1~t=T过程当中，所有弱评估器结果的加权求和：$$H(x_i) =  \sum_{t=1}^\boldsymbol{\color{red}T}\phi_tf_t(x_i)$$，其中，$\phi_t$为第t棵树的权重
     -   对于第$t$次迭代来说，则有：$$H_t(x_i) = H_{t-1}(x_i) + \phi_tf_t(x_i)$$
     -   每次将本轮建好的决策树加入之前的建树结果时，可以在权重$\phi$前面增加参数$\color{red}\eta$，表示为第t棵树加入整体集成算法时的学习率，对标参数`learning_rate`，则有：$$H_t(x_i) = H_{t-1}(x_i) + \boldsymbol{\color{red}\eta} \phi_tf_t(x_i)$$

2.   参数`init`：输入计算初始预测结果$H_0$的估计器对象，一般不会主动调节参数`init`

     -   我们建立第一个弱评估器时有：$$H_1(x_i) = H_{0}(x_i) + \phi_1f_1(x_i)$$
     -   可以输入任意评估器、字符串"zero"、或者None对象，默认为None对象
         -   当输入任意评估器时，评估器必须要具备`fit`以及`predict_proba`功能，即我们可以使用决策树、逻辑回归等可以输出概率的模型，如已经训练过的模型；
         -   填写为字符串"zero"，则代表令$H_0 = 0$来开始迭代；
         -   不填写，或填写为None对象，sklearn则会自动选择类`DummyEstimator`中的某种默认方式进行预测作为$H_0$的结果。`DummyEstimator`类是sklearn中设置的使用超简单规则进行预测的类，其中最常见的规则是直接从训练集标签中随机抽样出结果作为预测标签，也有选择众数作为预测标签等选项。
     -   与参数`init`相对的属性就是`init_`，当模型被拟合完毕之后，我们可以使用该属性来返回输出$H_0$的评估器对象。

3.   分类任务

     -   二分类：使用`sigmoid`函数对回归树输出的结果进行处理

         $$H(x_i) =  \sum_{t=1}^{\boldsymbol{\color{red}T}}\phi_tf_t(x_i)$$

         $$ p(\hat{y}_i = 1 |x_i) = \sigma(H(x_i))$$

         其中$\sigma$是`sigmoid`函数，当$p(\hat{y}_i = 1 |x_i)$大于0.5时，样本$x_i$的预测类别为1，反之则为0。

     -   多分类：使用`softmax`函数帮助我们将回归值转化为概率

         当现在的问题是$K$分类、且每个类别为$[1,2,3...k]$时，我们则分别按照$y = 1, y = 2,...,y = k$进行建模，总共建立$K$棵树，每棵树输出的结果为：$$H^1(x_i), H^2(x_i),...,H^k(x_i)$$

         然后，我们分别将$H^1(x_i)$到$H^k(x_i)$的结果输入softmax，来计算出每个标签类别所对应的概率：$$Softmax(H^k(x)) = \frac{e^{H^k(x)}}{\sum_{k=1}^Ke^{H_k(x)}}$$，并求解出相对概率最高的类别

         在执行多分类任务时，如果我们要求模型迭代10次，模型则会按照实际的多分类标签数n_classes建立10 * n_classes个弱评估器

4.   损失函数`loss`、`alpha`

     >   GBDT的贡献之一是**将损失函数从有限的指数损失、MSE等推广到了任意可微函数**

     -   **分类**器中的`loss`：字符串型，可输入"deviance", "exponential"，默认值="deviance"，如果使用指数损失，则相当于执行没有权重调整的AdaBoost算法

         -   `deviance`：交叉熵损失

             **二分类**：$$L = -\left( y\log p(x) + (1 - y)\log(1 - p(x)) \right)$$，其中$y$是真实标签，$\hat{y}$是回归预测标签，$H(x)$是集成算法输出结果，$p(x)$是基于$H(x)$用`Sigmoid`/`Softmax`函数计算的概率值，$p(x_i) = Sigmoid(H(x_i))$。

             **多分类**：$$L = -\sum_{k=1}^Ky^*_k\log(P^k(x))$$，其中$P^k(x)$是概率值，对于多分类GBDT来说，$P^k(x) = Softmax(H^k(x))$，$y^*$是由真实标签转化后的向量，如在3分类情况下，真实标签$y_i$为第2类时，$y^*$为[$y^*_{1}$,$y^*_{2}$,$y^*_{3}$]，取值分别为：

             | $y^*_{1}$ | $y^*_{2}$ | $y^*_{3}$ |
             | :-------: | :-------: | :-------: |
             |    $0$    |    $1$    |    $0$    |

         -   `exponential`：指数损失

             **二分类**：$$L = e^{-yH(x)}$$ 

             **多分类**：

             >   指数损失中的$y^*$与交叉熵损失中的$y^*$不是同样的向量。
             >
             >   -   $$H^*(x)=\begin{cases}1& if \ k = argmaxH(x) \\-\frac{1}{K-1}& if\ k  \neq  argmaxH(x)\end{cases}$$
             >
             >   -   $$y^*=\begin{cases}1& if \ k=y_i \\-\frac{1}{K-1}& if\  k\neq y_i \end{cases}$$

             $$\begin{aligned}L &=exp \left( -\frac{1}{K}\boldsymbol{y^* · H^*(x)} \right) \\ & = exp \left( -\frac{1}{K}(y^1H^1(x)+y^2H^2(x) \ + \  ... + y^kH^k(x)) \right)\end{aligned}$$

     -   **回归**器：可输入{"`squared_error`", "`absolute_error`", "`huber`", "`quantile`"}，默认值="`squared_error`"

         -   平方误差：$$L = \sum{(y_i - H(x_i))^2}$$

         -   绝对误差：$$L = \sum{|y_i - H(x_i)|}$$

         -   huber损失：$$L = \sum{l(y_i,H(x_i))}$$，

             其中：$$l = \begin{split} \begin{cases}\frac{1}{2}(y_i - H(x_i))^2, & |y_i - H(x_i)|\leq\alpha \\\alpha(|y_i - H(x_i)|-\frac{\alpha}{2}),& |y_i - H(x_i)|>\alpha \end{cases}\end{split}, \space \space \alpha \in (0, 1)$$，$\alpha$是阈值

         -   '`quantile`'则表示使用分位数回归中的弹球损失`pinball_loss`：$$L = \sum{l(y_i,H(x_i))}$$

             其中：$$l = \begin{split} \begin{cases}\alpha (y_i - H(x_i)), & y_i - H(x_i) > 0 \\0,   & y_i - H(x_i) = 0 \\(1-\alpha) (y_i - H(x_i)), & y_i - H(x_i) < 0\end{cases}\end{split}, \space \space \alpha \in (0, 1)$$，$\alpha$用于辅助计算损失函数的输出结果，默认$\alpha=0.9$

         >   如何选择`loss`？
         >
         >   工业数据大部分都极度偏态、具有长尾，因此GBDT必须考虑**离群值**带来的影响。
         >
         >   **Boosting是天生更容易被离群值影响的模型、也更擅长学习离群值的模型。**
         >
         >   -   **当高度关注离群值、并且希望努力将离群值预测正确时，选择`MSE`平方误差**
         >   -   **努力排除离群值的影响、更关注非离群值的时候，选择`MAE`绝对误差**
         >   -   **试图平衡离群值与非离群值、没有偏好时，选择`Huber`或者`Quantile`**


##### 13.2.2  弱评估器结构

| 类型             | 参数                                                         |
| ---------------- | ------------------------------------------------------------ |
| **弱评估器结构** | <font color="green">**`criterion`**</font>：弱评估器分枝时的不纯度衡量指标<br>`max_depth`：弱评估器被允许的最大深度，默认3<br>`min_samples_split`：弱评估器分枝时，父节点上最少要拥有的样本个数<br>`min_samples_leaf`：弱评估器的叶子节点上最少要拥有的样本个数<br>`min_weight_fraction_leaf`：当样本权重被调整时，叶子节点上最少要拥有的样本权重<br>`max_leaf_nodes`：弱评估器上最多可以有的叶子节点数量<br>`min_impurity_decrease`：弱评估器分枝时允许的最小不纯度下降量 |

-   `max_depth`

    在随机森林中我们讲到，森林中任意控制过拟合的参数基本都处于“关闭状态”，例如`max_depth`的默认值为None，表示不限深度，`min_samples_splits`的默认值为2，等同于不限制分枝，因此随机森林中长出的树都是剪枝前的树，也因此当随机森林算法处于过拟合状态时，我们可以使用粗或精的方法对弱评估器进行大刀阔斧的剪枝，当随机森林中的树被剪掉之后，可以很好的限制过拟合。

    然而这种情况并不适用于任何集成算法，尤其是以AdaBoost为基础的Boosting算法一族。在原始AdaBoost理论中，AdaBoost中使用的弱分类器都是最大深度为1的树桩或最大深度为3的小树苗，因此基于AdaBoost改进的其他Boosting算法也有该限制，即默认弱评估器的最大深度一般是一个较小的数字。

    **对GBDT来说，无论是分类器还是回归器，默认的弱评估器最大深度都为3**，因此GBDT**默认就对弱评估器有强力的剪枝机制**。

    当随机森林处于过拟合状态时，还可通过降低弱评估器复杂度的手段控制过拟合，但GBDT等Boosting算法处于过拟合状态时，便只能从数据上下手控制过拟合了（例如，使用参数`max_features`，在GBDT中其默认值为None），毕竟当`max_depth`已经非常小时，其他精剪枝的参数如`min_impurity_decrease`一般发挥不了太大的作用。

-   不纯度衡量指标`criterion`

    >   **大部分时候，使用弗里德曼均方误差可以让梯度提升树得到很好的结果**，因此GBDT的默认参数就是`Friedman_mse`。不过许多时候，我们会发现基于平方误差的分割与基于弗里德曼均方误差的分割会得到相同的结果。

    **父节点的不纯度与左右节点不纯度之和之间的差值，这个差值被称为不纯度下降量**

    -   弗里德曼均方误差`friedman_mse`

        **基于弗里德曼均方误差的不纯度下降量**：$$\frac{w_lw_r}{w_l \space + \space w_r} * \left( \frac{\sum_l{(r_i - \hat{y_i})^2}}{w_l} - \frac{\sum_r{(r_i - \hat{y_i})^2}}{w_r}\right)^2$$ = **左右叶子节点上样本量的调和平均 \* (左叶子节点上均方误差 - 右叶子节点上的均方误差)^2**

        其中，$w$是左右叶子节点上的样本量，当我们对样本有权重调整时，$w$则是叶子节点上的样本权重；

        $r_i$大多数时候是样本i上的残差（父节点中样本i的预测结果与样本i的真实标签之差），也可能是其他衡量预测与真实标签差异的指标；

        $\hat{y_i}$是样本$i$在当前子节点下的预测值；

        弗里德曼均方误差使用调和平均数（分子上相乘分母上相加）来控制左右叶子节点上的样本数量，相比普通地求均值，调和平均必须在**左右叶子节点上的样本量/样本权重相差不大**的情况下才能取得较大的值。在决策树进行分枝时，一般不太可能直接将所有样本分成两个不纯度非常低的子集（分别位于两片叶子上）。弗里德曼均方误差**使用两个子集之间的MSE差距来衡量不纯度的下降量**，如果两个子集之间的MSE**差异很大**，则说明**其中一个子集的MSE一定很小**，对整体分枝来说是更有利的。

    -   平方误差squared_error

        计算父节点的平方误差与子节点平方误差的加权求和之间的差异：

        **平方误差的不纯度下降量**：$$\frac{\sum_p{(r_i - \hat{y_i})^2}}{w_l + w_r} - (\frac{w_l}{w_l+w_r} * \sum_l{(r_i - \hat{y_i})^2} + \frac{w_r}{w_l+w_r} * \sum_r{(r_i - \hat{y_i})^2})$$

##### 13.2.3  提前停止

| 类型         | 参数                                                         |
| ------------ | ------------------------------------------------------------ |
| **提前停止** | <font color="green">**validation_fraction**</font>：从训练集中提取出、用于提前停止的验证数据占比<br><font color="green">**n_iter_no_change**</font>：当验证集上的损失函数值连续`n_iter_no_change`次没有下降或下降量不达阈值时，提前停止<br><font color="green">**tol**</font>：损失函数下降量的最小阈值 |

-   **当GBDT已经达到了足够好的效果（非常接近收敛状态），持续迭代下去不会有助于提升算法表现**
-   **GBDT还没有达到足够好的效果（没有接近收敛），但迭代过程中呈现出越迭代算法表现越糟糕的情况**

![](https://cdn.jsdelivr.net/gh/louisyanglu/images/images/53.png)

从训练集中划分出一小部分数据，专用于验证是否应该提前停止。

我们可以规定一个阈值，**当连续`n_iter_no_change`次迭代中，验证集上损失函数的减小值都低于阈值`tol`，或者验证集的分数提升值都低于阈值`tol`的时候**，此时即便我们规定的`n_estimators`或者`max_iter`中的数量还没有被用完，我们也可以认为算法已经非常接近“收敛”而将训练停下

-   `validation_fraction`：从训练集中提取出、用于提前停止的验证数据占比，值域为[0,1]。
-   `n_iter_no_change`：当验证集上的损失函数值连续n_iter_no_change次没有下降或下降量不达阈值时，则触发提前停止
-   `tol`：损失函数下降的阈值，默认值为1e-4

##### 13.2.4  数据抽样与袋外数据

| 类型                   | 参数                                                         |
| ---------------------- | ------------------------------------------------------------ |
| **弱评估器的训练数据** | 参数：<br>&emsp;subsample：每次建树之前，从全数据集中进行有放回随机抽样的比例<br>&emsp;max_features：每次建树之前，从全特征中随机抽样特征进行分枝的比例<br>&emsp;random_state：随机数种子，控制整体随机模式<br><br>属性：<br>&emsp;<font color="green">**oob_improvement_**</font>：每次建树之后相对于上一次袋外分数的增减<br>&emsp;<font color="green">**train_score_**</font>：每次建树之后相对于上一次验证时袋内分数的增减 |

**每建立一棵树，GBDT就会使用当前树的袋外数据对建立新树后的模型进行验证，以此来对比新建弱评估器后模型整体的水平是否提高，并保留提升或下降的结果**。在GBDT当中，这些袋外分数的变化值被储存在属性`oob_improvement_`中，同时，GBDT还会在每棵树的训练数据上保留袋内分数（in-bag）的变化，且储存在属性`train_score_`当中。也就是说，即便在不做交叉验证的情况下，我们也可以简单地通过属性`oob_improvement`与属性`train_score_`来观察GBDT迭代的结果

袋外数据是天然的验证数据，而提前停止时需要使用验证集的功能，但sklearn中并未配置直接使用袋外数据来进行提前停止的功能。

##### 13.2.5  未提供class_weight与n_jobs

sklearn中的GBDT分类器并没有提供调节样本不均衡问题的参数class_weights，也不存在并行参数n_jobs。

不在样本不均衡问题上做文章，或许跟GBDT的弱评估器都是回归器有关，又或许是因为GBDT拥有非常强的学习能力，因此不会轻易被样本不均衡问题左右。如果**样本存在严重不均衡**的状况，那我们可能会**考虑不使用梯度提升树**，或者先对数据进行样本均衡的预处理后，再使用梯度提升树。

GBDT中的树必须一棵棵建立、且后面建立的树还必须依赖于之前建树的结果，因此GBDT很难在某种程度上实现并行，因此sklearn并没有提供n_jobs参数给Boosting算法使用。

#### 13.3  GBDT超参数优化

|                     影响力                     |                             参数                             |
| :--------------------------------------------: | :----------------------------------------------------------: |
|        ⭐⭐⭐⭐⭐<br>几乎总是具有巨大影响力         | n_estimators（整体学习能力）<br>learning_rate（整体学习速率）<br>max_features（随机性）<br> |
|          ⭐⭐⭐⭐<br>大部分时候具有影响力          | init（初始化）<br>subsamples（随机性）<br>loss（整体学习能力） |
| ⭐⭐<br>可能有大影响力<br>大部分时候影响力不明显 | max_depth（粗剪枝）<br>min_samples_split（精剪枝）<br>min_impurity_decrease（精剪枝）<br>max_leaf_nodes（精剪枝）<br>criterion（分枝敏感度） |
|       ⭐<br>当数据量足够大时，几乎无影响        |            random_state<br>ccp_alpha（结构风险）             |

##### 13.3.1  GBDT与随机森林调参对比

-   在随机森林中非常关键的`max_depth`在GBDT中没有什么地位，取而代之的是Boosting中特有的迭代参数学习率`learning_rate`；

    在随机森林中，我们总是在意模型复杂度(`max_depth`)与模型整体学习能力(`n_estimators`)的平衡，单一弱评估器的复杂度越大，单一弱评估器对模型的整体贡献就越大，因此需要的树数量就越少；

    Boosting算法中我们寻找的是`learning_rate`与`n_estimators`的平衡。单一弱评估器对整体算法的贡献由学习率参数`learning_rate`控制，代替了弱评估器复杂度的地位。Boosting算法天生就假设单一弱评估器的能力很弱，参数`max_depth`的默认值也往往较小（在GBDT中`max_depth`的默认值是3），因此我们无法靠降低`max_depth`的值来大规模降低模型复杂度，更难以靠`max_depth`来控制过拟合，自然`max_depth`的影响力就变小了；

-   在随机森林中，精剪枝工具的效用有限，剪枝一般还是大刀阔斧的粗剪枝更有效。

    在GBDT中，由于`max_depth`这一粗剪枝工具的默认值为3，因此在Boosting算法中通过削减模型复杂度来控制过拟合的思路就无法走通。如果无法对弱评估器进行剪枝，最好的控制过拟合的方法就是增加随机性/多样性，因此`max_features`和`subsample`就成为Boosting算法中控制过拟合的核心武器，依赖于随机性、而非弱评估器结构来对抗过拟合；

    当我们使用参数`max_features`与`subsample`构建随机性、并加大每一棵树之间的差异后，模型的学习能力可能受到影响，因此我们可能需要提升单一弱评估器的复杂度。因此在**GBDT**当中，`max_depth`的**调参方向是放大/加深**，以探究模型是否需要更高的单一评估器复杂度。相对的在**随机森林**当中，`max_depth`的**调参方向是缩小/剪枝**，用以缓解过拟合。

##### 13.3.2  调参顺序及范围

|          参数           |                             范围                             |
| :---------------------: | :----------------------------------------------------------: |
|         `loss`          | 回归损失中4种可选损失函数<br>["`squared_error`","`absolute_error`", "`huber`", "`quantile`"] |
|       `criterion`       | 全部可选的4种不纯度评估指标<br>["`friedman_mse`", "`squared_error`", "`mse`", "`mae`"] |
|         `init`          |                 HyperOpt不支持搜索，手动调参                 |
|     `n_estimators`      |   经由提前停止确认中间数，例如50，最后范围定为(25,200,25)    |
|     `learning_rate`     | 以1.0为中心向两边延展，最后范围定为(0.05,2.05,0.05)<br>*如果算力有限，也可定为(0.1,2.1,0.1) |
|     `max_features`      |            所有字符串，外加`sqrt`与`auto`中间的值            |
|       `subsample`       | subsample参数的取值范围为(0,1]，因此定范围(0.1,0.8,0.1)<br>*如果算力有限，也可定为(0.5,0.8,0.1) |
|       `max_depth`       |   以3为中心向两边延展，右侧范围定得更大。最后确认(2,30,2)    |
| `min_impurity_decrease` |         只能放大、不能缩小的参数，先尝试(0,5,1)范围          |

一般在初次搜索时，我们会设置范围较大、较为稀疏的参数空间，然后在多次搜索中逐渐缩小范围、降低参数空间的维度。

#### 13.4  GBDT流程

![GBDT流程](https://cdn.jsdelivr.net/gh/louisyanglu/images/images/GBDT%E6%B5%81%E7%A8%8B.png)

假设现有数据集$N$，含有形如$(x_i,y_i)$的样本$M$个，$i$为任意样本的编号，单一样本的损失函数为$l(y_i,H(x_i))$，其中$H(x_i)$是$i$号样本在集成算法上的预测结果，整个算法的损失函数为$L(y,H(x))$，且总损失等于全部样本的损失之和：$L(y,H(x)) = \sum_il(y_i,H(x_i))$。同时，弱评估器为回归树$f$，总共学习$T$轮。

流程：

1.   初始化数据迭代的起点$H_0(x)$；

     >   -   论文中，当损失函数是平方误差时，$H_0(x)=y_i的均值$；
     >   -   sklearn中，可选0、随机数、None等。

     -   在**最初的论文中**，Friedman定义了如下公式来计算$H_0$：$$\begin{aligned}H_0(x) &= \mathop{argmin}_{C} \sum_{i=1}^M l(y_i,C)\\ \\&= \mathop{argmin}_{C} L(y,C)\end{aligned}$$，其中，$y_i$为真实标签，$C$为任意常数

         找出令$\sum_{i=1}^Ml(y_i,C)$最小的常数$C$值，并输出最小的$\sum_{i=1}^Ml(y_i,C)$作为$H_0(x)$的值

         假设$l$是squared_error，每个样本的平方误差，则有：$$\sum_{i=1}^M l(y_i,C) = \sum^M_{i=1}(y_i - C)^2$$

         对上述式子求导，并令一阶导数等于0：

         $$\begin{aligned}\frac{\partial}{\partial C}\sum_{i=1}^M l(y_i,C) &= \frac{\partial}{\partial C} \sum^M_{i=1}(y_i - C)^2\\&=\sum^M_{i=1}-2(y_i - C)\\&=-2\sum^M_{i=1}y_i + 2MC\\&= 0 \\\end{aligned}$$

         $$\begin{aligned}2\sum^M_{i=1}y_i &= 2MC \\C &= \frac{1}{M}\sum^M_{i=1}y_i \\ \\C &= mean(y_i)\end{aligned}$$

         **当L是平方误差squared error时，令$L(y_i,C)$最小的常数C就是真实标签的均值**；

     -   **在sklearn中，可以使用0、随机数或者任意算法的输出结果作为$H_0(x)$**。

2.   开始循环，for t in 1,2,3...T:

     在现有数据集$N$中，抽样$M$ * `subsample`个样本，构成训练集$N^t$

3.   对任意一个样本$i$，计算伪残差（pseudo-residuals）$r_{it}$

     $$r_{it} = -\frac{\partial{l(y_i,H_{t-1}(x_i))}}{\partial{H_{t-1}(x_i)}}$$

     -   伪残差是一个样本的损失函数对该样本在集成算法上的预测值求导后取负的结果

         假设现在损失函数是平方误差Squared error，则

         $$\begin{aligned}l&= (y_i - H_{t-1}(x_i))^2 \\ \\ \frac{\partial l}{\partial H_{t-1}(x_i)} &= \frac{\partial}{\partial H_{t-1}(x_i)} (y_i - H_{t-1}(x_i))^2\\ \\\frac{\partial l}{\partial H_{t-1}(x_i)} &= -2(y_i - H_{t-1}(x_i))\\ \\ -\frac{\partial l}{\partial H_{t-1}(x_i)}  &= 2(y_i- H_{t-1}(x_i))\\\end{aligned}$$

         伪残差是残差的某种变形，它的值不完全等同于残差的值，但是它衡量的差异与残差衡量的差异完全一致。

         让新建立的弱评估器拟合伪残差，这样算法就会更多地学习当下$H_t(x_i)$与$y_i$之间的差异，新建立的弱评估器预测出的结果也更有可能抹平这种差异

         从直觉上来说，$H_t(x_i)$与$y_i$之间的差异越小，整体损失函数值就会越小，因此**GBDT拟合伪残差是在向着损失函数最小化（偏差最小化）的方向拟合**

         伪残差是损失函数求导后取负的结果。一个函数对自变量求导后得到的结果称为**梯度**，代表字母为$g$，因此**伪残差也被称为负梯度**。也因此，GBDT被称为“**拟合负梯度**”的算法

         不过，在最初的梯度提升机器（Gradient Boosting Machine）中，拟合的的确是残差$y-H(x)$，只不过在后来改进的梯度提升树中，拟合残差过程被修改为拟合伪残差了。

     -   在进行第t次迭代、计算第t个伪残差时，我们使用的前t-1次迭代后输出的集成算法结果。在t=1时，所有伪残差计算中的$H_{t-1}(x_i)$都等于初始$H_0(x)$

4.   求解出伪残差后，在数据集$(x_i, r_{it})$上按照**CART树**规则建立一棵回归树$f_t$，训练时拟合的标签为样本的伪残差$r_{it}$

     只要拟合对象是伪残差$r_{it}$，则$f_t(x_i)$的值一定能让损失函数最快减小

     -   直观类比

         $$\begin{aligned}f_t &= \mathop{argmin}_{f} L(y_i, H_t(x))\\&= \mathop{argmin}_{f} \sum_{i=1}^{M}l(y_i, H_{t-1}(x_i) + f_t(x_i))\end{aligned}$$

         **无论弱评估器$f_t$是什么结构、什么规则、如何建立、如何拟合，其最终的输出值$f_t(x_i)$必须是令整体损失函数$L$最小化的**$f_t(x_i)$，**随着算法逐步迭代，损失函数必然是会越来越小的**。那我们如何保证这一点成立呢？我们可以直接**对整体损失函数进行梯度下降**，找出当前最小值以及最小值对应的$f_t(x_i)$

         在逻辑回归中，$$w_{t} = w_{t-1} - \eta g_t$$，负梯度的方向就是损失函数下降最快的方向

         在GBDT中，我们的损失函数为$L(y_i, H_t(x))$，并且我们的$H_t(x)$是按以下方式迭代的：$$H_t(x) = H_{t-1}(x) + \eta f_t(x)$$

         其中，$H_t(x)$是，第$t$次迭代中全部样本在算法上的输出值，$f_t(x)$则是第$t$次迭代中全部样本在新弱评估器上输出的$f_t(x_i)$。原则上来说，对标传统梯度下降，只要让$f_t(x) = -g_t$，即让$f_t(x_i) = -g_i$，就一定能够保证损失函数$L(y_i,H_t(x))$是随迭代下降的。**每个样本的伪残差$r_i$（负梯度$-g_i$）其实就是能够令损失函数减小最快的$f_t(x_i)$的值**

     -   **数学证明**

         **泰勒级数（无限项）**：$$f(x) = \sum_{n=0}^{\infty}\frac{f^{(n)}(a)}{n!}(x-a)^n$$

         其中(x-a)是非常小的任意实数/复数，$n!$是n的阶乘，$f^{(n)}(a)$是函数$f(x)$的n阶导数在a点的取值。当a为0时，泰勒级数也被叫做麦克劳思级数。

         **一阶泰勒展开**：$$\begin{aligned}f(x) &\approx \sum_{n=0}^{1}\frac{f^{(n)}a}{n!}(x-a)^n \\&\approx f(a) + \frac{f'(a)}{1!}(x-a)\end{aligned}$$

         **二阶泰勒展开**：$$\begin{aligned}f(x) &\approx \sum_{n=0}^{2}\frac{f^{(n)}a}{n!}(x-a)^n \\&\approx f(a) + \frac{f'(a)}{1!}(x-a) + \frac{f''(a)}{2!}(x-a)^2\end{aligned}$$

         **N阶泰勒展开**：$$\begin{aligned}f(x) &\approx \sum_{n=0}^{N}\frac{f^{(n)}a}{n!}(x-a)^n \\&\approx f(a) + \frac{f'(a)}{1!}(x-a) + \frac{f''(a)}{2!}(x-a)^2 + \frac{f'''(a)}{3!}(x-a)^3 + ...\end{aligned}$$

         对单一样本而言，我们有损失函数$l(y_i, H_{t-1}(x_i) + f_t(x_i))$，其中$y_i$是已知的常数，因此损失函数可以被看做是只有$H_{t-1}(x_i) + f_t(x_i)$一个自变量的函数，从而简写为$l(H_{t-1}(x_i) + f_t(x_i))$

         根据一阶泰勒展开，令泰勒展开中的 x = $H_{t-1}(x_i) + f_t(x_i)$，令泰勒展开中的a = $H_{t-1}(x_i)$，则损失函数$l(H_{t-1}(x_i) + f_t(x_i))$​可以被表示为：$$\begin{aligned}l(H_{t-1}(x_i) + f_t(x_i) ) &\approx l(H_{t-1}(x_i)) + \frac{\partial{l(H_{t-1}(x_i))}}{\partial{H_{t-1}(x_i)}} * f_t(x_i) \\\end{aligned}$$

         该式子中$H_{t-1}(x_i)$是常数，因此第一部分$l(y_i, H_{t-1}(x_i))$也是一个常数。同时，第二部分由导数和$f_t$组成，其中导数就是梯度，可以写作$g_i$，所以式子可以化简为：$$\begin{aligned}l(H_{t-1}(x_i) + f_t(x_i) ) &\approx 常数 + g_if_t(x_i) \\\end{aligned}$$

         现在，如果要令$l$最小，$f_t(x_i)$应该等于多少呢？

         $$\begin{aligned}f_t &= \mathop{argmin}_{f} \sum_{i=1}^{M}l(H_{t-1}(x_i) + f_t(x_i)) \\& \approx \mathop{argmin}_{f} \sum_{i=1}^{M} \left( 常数 + g_if_t(x_i) \right)\end{aligned}$$

         $$\begin{aligned}f_t &\approx \mathop{argmin}_{f} \sum_{i=1}^{M} g_if_t(x_i) \\ \\&\approx \mathop{argmin}_{f} \langle g_t f_t(x) \rangle\end{aligned}$$

         $g_t$是包含了所有样本梯度的向量，$f_t(x)$是包含了所有样本在$f_t$上预测值的向量，两个向量对应位置元素相乘后求和，即表示为向量的内积。

         我们希望求解向量内积的最小值、并找出令向量内积最小的$f_t(x)$的取值，那就必须先找出$f_t(x)$的方向，再找出$f_t(x)$的大小。

         -   方向

             $f_t(x)$**的方向应该与$g_t$完全相反**

             向量的内积$\langle g_t f_t(x) \rangle = |g_t||f_t(x)|cos(\alpha)$，其中前两项为两个向量的模长，$\alpha$是两个向量的夹角大小。模长默认为整数，因此当且仅当两个向量的方向完全相反，即夹角大小为180度时，$cos(\alpha)$的值为-1，才能保证两个向量的内积最小。

         -   大小

             当方向相反时，$\langle g_t f_t(x) \rangle$是一个理论上可以取到无穷小的值。**任何大小都无所谓**

             无论$f_t(x)$的大小是多少，我们都可以通过步长$\eta$对其进行调整，只要能够影响$H_(x)$，我们就可以影响损失迭代过程中的常数的大小。**因此在数学上来说，$f_t(x)$的大小可以是$-g_t$的任意倍数**

             $$\begin{aligned}f_t &\approx \mathop{argmin}_{f} \langle g_t f_t(x) \rangle\\&= -g_t\end{aligned}$$

             这就是我们让GBDT当中的弱评估器拟合伪残差/负梯度的根本原因。拟合负梯度其实为GBDT带来了非常多的特点——

             1.   首先，通过直接拟合负梯度，GBDT避免了从损失函数找“最优”的过程，即避免了上述证明中求解$f_t = \mathop{argmin}*_{f} \sum_{i=1}^{M}l(H_{t-1}(x_i) + f_t(x_i))$的过程，从而大大地简化了计算；
             2.   其次，通过拟合负梯度，GBDT模拟了梯度下降的过程，由于结合了传统提升法Boosting与梯度下降，因此才被命名为梯度提升法（Gradient Boosting）。这个过程被称为**函数空间上的梯度下降**；
             3.   最后，最重要的一点是，通过让弱评估器拟合负梯度，弱评估器上的结果可以直接影响损失函数、保证损失函数的降低，从而指向Boosting算法的根本目标：降低偏差。这一过程避免了许多在其他算法中需要详细讨论的问题：例如，每个弱评估器的权重$\phi$是多少，以及弱评估器的置信度如何。

5.   将数据集$N_t$上所有的样本输入$f_t$进行预测，对每一个样本，得出预测结果$f_t(x_i)$

6.   根据预测结果$f_t(x_i)$迭代模型。$$H_t(x_i) = H_{t-1}(x_i) + f_t(x_i)$$

     -   假设输入的步长为$\eta$，则$H_t(x)$应该为：$$H_t(x_i) = H_{t-1}(x_i) + \eta f_t(x_i)$$
     -   对整个算法则有：$$H_t(x) = H_{t-1}(x) + \eta f_t(x)$$

7.   循环结束，输出$H_T(x)$的值作为集成模型的输出值

<div style="page-break-after:always"></div>

------

### 第14章  XGBoost

#### 14.1  XGBoost特点

1.   **第一，实现精确性与复杂度之间的平衡**

     **树模型的学习能力与过拟合风险之间的平衡，就是预测精确性与模型复杂度之间的平衡，也是经验风险与结构风险之间的平衡**

     在过去，我们总是先建立效果优异的模型，再依赖于手动剪枝来调节树模型的复杂度，但在XGBoost中，精确性与复杂度会在训练的每一步被考虑到：

     -   **XGBoost为损失函数$L(y,\hat{y})$加入结构风险项，构成目标函数$O(y,\hat{y})$**

         在AdaBoost与GBDT当中，我们的目标是找到损失函数$L(y,\hat{y})$的最小值，也就是让预测结果与真实结果差异最小，这一流程只关心精确性、不关心复杂度和过拟合情况。为应对这个问题，XGBoost从决策树的预剪枝流程、逻辑回归、岭回归、Lasso等经典算法的抗过拟合流程吸取经验，在损失函数中加入了控制过拟合的结构风险项，并将【$L(y,\hat{y})$ + 结构风险】定义为目标函数$O(y,\hat{y})$。这一变化让XGBoost在许多方面都与其他Boosting算法不同：例如，**XGBoost是向着令目标函数最小化的目标进行训练，而不是令损失函数最小化的方向**。再比如，**XGBoost会优先利用结构风险中的参数来控制过拟合**，而不像其他树的集成模型一样依赖于树结构参数（例如`max_depth`，`min_impurity_decrease`等）

     -   **使用全新不纯度衡量指标，将复杂度纳入分枝规则**

         在之前学过的算法当中，无论Boosting流程如何进化，建立单棵决策树的规则基本都遵循我们曾经学过的**CART树**流程，在**分类树**中，我们使用**信息增益**（information gain）来衡量叶子的质量，在**回归树**中，我们使用**MSE**或者弗里德曼MSE来衡量叶子的质量。这一流程有成熟的剪枝机制、预测精度高、能够适应各种场景，但却可能建立复杂度很高的树。

         为实现精确性与复杂度之间的平衡，XGBoost重新设定了分枝指标**【结构分数】，也被称为质量分数Quality Score）**，以及基于结构分数的**【结构分数增益】**，结构分数增益可以逼迫决策树向整体结构更简单的方向生长。这一变化让XGBoost使用与传统CART略有区别的建树流程，同时在建树过程中大量使用残差（Residuals）或类残差对象作为中间变量，因此XGBoost的数学过程比其他Boosting算法更复杂。

2.   **第二，极大程度地降低模型复杂度、提升模型运行效率，将算法武装成更加适合于大数据的算法**

     -   **使用估计贪婪算法、平行学习、分位数草图算法等方法构建了适用于大数据的全新建树流程**
     -   **使用感知缓存访问技术与核外计算技术，提升算法在硬件上的运算性能**
     -   **引入Dropout技术，为整体建树流程增加更多随机性、让算法适应更大数据**

3.   部分GBDT属性

     -   **无论集成算法整体在执行回归/分类/排序任务，弱评估器一定是回归器**
     -   **拟合负梯度，且当损失函数是0.5倍MSE时，拟合残差**
     -   **抽样思想**

#### 14.2  XGBoost参数

| 类型                   | 参数                                                         |
| ---------------------- | ------------------------------------------------------------ |
| **迭代过程/目标函数**  | **params**: eta, base_score, objective, <font color="green">**lambda, gamma, alpha, max_delta_step**</font><br>**xgb.train()**: num_boost_round |
| **弱评估器结构**       | **params**: max_depth, <font color="green">**booster, min_child_weight**</font> |
| **dart树**             | **params**: <font color="green">**sample_type, normalized_type, rate_drop, one_drop, skip_drop**</font> |
| **弱评估器的训练数据** | **params**: subsample, <font color="green">**sampling_method, colsamle_bytree, colsample_bylevel, colsample_bynode**</font> |
| **提前停止**           | **xgb.train()**: <font color="green">**early_stopping_rounds, evals**</font>, eval_metric |
| **其他**               | **params**: seed, <font color="green">**verbosity, scale_pos_weight, nthread**</font> |

##### 14.2.1  迭代过程

|           参数含义           |              原生代码              |    sklearn API     |
| :--------------------------: | :--------------------------------: | :----------------: |
|      迭代次数/树的数量       | **num_boost_round**<br>(xgb.train) |  **n_estimators**  |
|            学习率            |        **eta**<br>(params)         | **learning_rate**  |
|          初始迭代值          |     **base_score**<br>(params)     |   **base_score**   |
| 一次迭代中所允许的最大迭代值 |   **max_delta_step**<br>(params)   | **max_delta_step** |

-   `num_boost_round`

    对于样本$x_i$，集成算法当中一共有$K$棵树，则参数`num_boost_round`的取值为K。假设现在正在建立第$k$个弱评估器，则第$k$个弱评估器上$x_i$的结果可以表示为$f_k(x_i)$。假设整个Boosting算法对样本$x_i$输出的结果为$H(x_i)$，则该结果一般可以被表示为k=1~k=K过程当中，所有弱评估器结果的加权求和：$$H(x_i) =  \sum_{k=1}^{\boldsymbol{\color{red}K}}\phi_kf_k(x_i)$$  。

    其中，$\phi_k$为第k棵树的权重。特别的，**XGBoost算法不计算树权重**，因此XGBoost的输出结果为：$$H(x_i) =  \sum_{k=1}^{\boldsymbol{\color{red}K}}f_k(x_i)$$。

    对于第$k$次迭代来说，则有：$$H_k(x_i) = H_{k-1}(x_i) + f_k(x_i)$$。

-   `eta`

    在这个一般过程中，每次将本轮建好的决策树加入之前的建树结果时，可以增加参数$\color{red}\eta$，表示为第k棵树加入整体集成算法时的学习率，对标参数`eta`。$$H_k(x_i) = H_{k-1}(x_i) + \boldsymbol{\color{red}\eta} f_k(x_i)$$。

    该学习率参数控制Boosting集成过程中$H(x_i)$的增长速度，是相当关键的参数。当学习率很大时，$H(x_i)$增长得更快，我们所需的`num_boost_round`更少，当学习率较小时，$H(x_i)$增长较慢，我们所需的`num_boost_round`就更多，因此boosting算法往往会需要在`num_boost_round`与`eta`中做出权衡。在XGBoost当中，`num_boost_round`的默认值为10，`eta`的默认值为0.3。

-   `base_score`

    在上述过程中，我们建立第一个弱评估器时有：$$H_1(x_i) = H_{0}(x_i) + \eta f_1(x_i)$$。

    由于没有第0棵树的存在，因此$H_0(x_i)$的值在数学过程及算法具体实现过程中都需要进行单独的确定，而这个值就由`base_score`确定，可以是**任何数值**，不能像GBDT那样传一个评估器。该参数的默认值为0.5，当迭代次数足够多、数据量足够大时，调整算法的$H_0(x_i)$意义不大，因此我们基本不会调整这个参数。

-   `max_delta_step`

    在迭代过程当中，XGBoost有一个独特的参数`max_delta_step`。这个参数代表了每次迭代时被允许的最大$\eta f_k(x_i)$。

    当参数`max_delta_step`被设置为0，则说明不对每次迭代的$\eta f_k(x_i)$大小做限制，如果该参数被设置为正数C，则代表$\eta f_k(x_i) \leq C$，否则就让算法执行，$$H_k(x_i) = H_{k-1}(x_i) + C$$，即设置一个上限。

    通常来说这个参数是不需要的，但有时候这个参数会对极度不均衡的数据有效。如果样本极度不均衡，那可以尝试在这个参数中设置1~10左右的数。

##### 14.2.2  目标函数

>   $$Obj_k = \sum_{i=1}^Ml(y_i,\hat{y_i}) + \boldsymbol{\color{red}\gamma} T + \frac{1}{2}\boldsymbol{\color{red}\lambda}\sum_{j=1}^Tw_j^2 + \boldsymbol{\color{red}\alpha}\sum_{j=1}^Tw_j$$。
>
>   其中，$T$表示当前第$k$棵树上的叶子总量，$w_j$则代表当前树上第$j$片叶子的预测值。

|         参数含义         |        原生代码        |  sklearn API   |
| :----------------------: | :--------------------: | :------------: |
| 乘在叶子节点数量前的系数 | **gamma**<br>(params)  |   **gamma**    |
|       L2正则项系数       | **lambda**<br>(params) | **reg_lambda** |
|       L1正则项系数       | **alpha**<br>(params)  | **reg_alpha**  |

xgboost并不是单纯向着损失函数最小化的方向运行，而是**向着令目标函数最小化的方向运行**。

对任意树$f_k$来说，目标函数有两个组成部分，一部分是任意可微的损失函数，它控制模型的**经验风险**，等于现在树上所有样本上损失函数之和，其中单一样本的损失为$l(y_i,\hat{y_i})$，另一部分是控制模型复杂度的$\Omega(f_k)$，它控制当前树的**结构风险**。

**目标函数 = 损失函数 + 结构风险**：$$Obj_k = \sum_{i=1}^Ml(y_i,\hat{y_i}) + \Omega(f_k)$$。其中，$M$表示现在这棵树上一共使用了M个样本，$l$表示单一样本的损失函数。

**结构风险 = 树结构 + 正则化项**：$$\Omega(f_k) = \boldsymbol{\color{red}\gamma} T + \frac{1}{2}\boldsymbol{\color{red}\lambda}\sum_{j=1}^Tw_j^2 + \boldsymbol{\color{red}\alpha}\sum_{j=1}^Tw_j$$。其中，$\gamma$，$\lambda$与$\alpha$都是可以自由设置的系数，而$T$表示当前第$k$棵树上的叶子总量，$w_j$则代表当前树上第$j$片叶子的叶子权重（leaf weights），**叶子权重实际上就是当前叶子$j$的预测值**。

**完整的目标函数**：$$Obj_k = \sum_{i=1}^Ml(y_i,\hat{y_i}) + \boldsymbol{\color{red}\gamma} T + \frac{1}{2}\boldsymbol{\color{red}\lambda}\sum_{j=1}^Tw_j^2 + \boldsymbol{\color{red}\alpha}\sum_{j=1}^Tw_j$$

-   参数`gamma`：乘在一棵树的叶子总量$T$之前，依照叶子总量对目标函数施加惩罚的系数，默认值为0，可填写任何[0, ∞]之间的数字。当叶子总量固定时，`gamma`越大，结构风险项越大；同时，当`gamma`不变时，叶子总量越多、模型复杂度越大，结构风险项也会越大。**调大`gamma`可以控制过拟合**；
-   参数`alpha`与`lambda`：乘在正则项之前，依照叶子权重的大小对目标函数施加惩罚的系数，也就是正则项系数。`lambda`的默认值为1，`alpha`的默认值为0，因此xgboost**默认使用L2正则化**。**调大`alpha`或`lambda`可以控制过拟合**。

**在实际控制过拟合的过程中，大家可能经常会发现这3个参数“无效”**

实际上，**对于没有上限或下限的参数，我们要关注参数的敏感度**。如果参数值稍稍移动，模型就变化很大，那参数敏感，如果参数值移动很多，模型才能有变化，那参数不敏感。

-   当**树的结构相对复杂**时，**`gamma`会比较敏感**，否则`gamma`可能非常迟钝。
-   当**原始标签数值很大、且叶子数量不多**时，**`lambda`和`alpha`会比较敏感**，如果原始标签数值很小，这两个参数就不敏感。

##### 14.2.3  弱评估器结构与dart树

-   `booster`：可以输入"`gbtree`"、"`gblinear`"或者"`dart`"

    -   输入"`gbtree`"表示使用遵循XGBoost规则的CART树

    -   输入"`dart`"表示使用抛弃提升树，DART是**Dropout Multiple Additive Regression Tree**的简称。这种建树方式受深度学习中的Dropout技巧启发，在建树过程中会随机抛弃一些树的结果，可以更好地防止过拟合。在数据量巨大、过拟合容易产生时，DART树经常被使用，但由于会随机地抛弃到部分树，可能会伤害模型的学习能力，同时可能会需要更长的迭代时间。

        DART树在**每一次迭代**前都会随机地抛弃部分树，即不让这些树参与$H_{k-1}(x_i)$的计算。

        |                 | k=1  | k=2  | k=3  | k=4  | k=5  |
        | :-------------: | :--: | :--: | :--: | :--: | :--: |
        | $\eta f_k(x_i)$ |  1   | 0.8  | 0.6  | 0.5  | 0.3  |

        当建立第6棵树时，普通提升树的$H_{k-1}(x_i)$ = 1+0.8+0.6+0.5+0.3 = 3.2。对于DART树来说，我们可以认为设置抛弃率`rate_drop`，假设抛弃率为0.2，则DART树会随机从5棵树中抽样一棵树进行抛弃。假设抛弃了第二棵树，则DART树的$H_{k-1}(x_i)$ = 1+0.6+0.5+0.3 = 2.4。

        在一般的抗过拟合方法当中，我们只能从单棵树的学习能力角度入手花式对树进行剪枝，但DART树的方法是对整体迭代过程进行控制。在任意以“迭代”为核心的算法当中，我们都面临同样的问题，即**最开始的迭代极大程度地影响整个算法的走向，而后续的迭代只能在前面的基础上小修小补**。这一点从直觉上来说很好理解，毕竟当我们在绘制损失函数的曲线时，会发现在刚开始迭代时，损失函数急剧下降，但随后就逐渐趋于平缓。在这个过程中，没有任何过拟合手段可以从流程上影响到那些先建立的、具有巨大影响力的树，但DART树就可以削弱这些前端树的影响力，大幅提升抗过拟合的能力。

        -   参数`rate_drop`：每一轮迭代时抛弃树的比例；

        -   参数`one_drop`：每一轮迭代时至少有`one_drop`棵树会被抛弃，与`rate_drop`计算得到的数相比，取大；

        -   参数`skip_drop`：每一轮迭代时可以不执行dropout的概率，skip_drop`的权限高于`one_drop。当该参数为0时，则表示每一轮迭代都一定会抛弃树。如果该参数不为0，则有可能不执行Dropout，直接按照普通提升树的规则建立新的提升树。

        -   参数`sample_type`：抛弃时所使用的抽样方法；

            **每一次迭代中的抛弃是相互独立的，因此每一次抛弃都是从所有树中进行抛弃**

            -   填写字符串"`uniform`"：表示均匀不放回抽样
            -   填写字符串"`weighted`"：表示按照每棵树的权重进行有权重的不放回抽样

        -   参数`normalize_type`：增加新树时，赋予新树的权重；

            当随机抛弃已经建好的树时，可能会让模型结果大幅度偏移，因此往往需要给与后续的树更大的权重，让新增的、后续的树在整体算法中变得更加重要。所以DART树在建立新树时，会**有意地给与后续的树更大的权重**。**树的权重其实指的是整棵树上所有叶子权重之和**（XGBoost并不会针对每一棵树计算特定的权重）

            -   填写字符串"`tree`"，表示新生成的树的权重等于所有被抛弃的树的权重的均值
            -   填写字符串"`forest`"，表示新生成的树的权重等于所有被抛弃的树的权重之和

    -   输入"`gblinear`"则表示使用线性模型，当弱评估器类型是"`gblinear`"而损失函数是MSE时，表示使用xgboost方法来集成线性回归。当弱评估器类型是"`gblinear`"而损失函数是交叉熵损失时，则代表使用xgboost来集成逻辑回归。

##### 14.2.4  弱评估器分枝——结构分数

>   在CART树的基础上，XGBoost创新了全新的分枝指标：**结构分数（Structure Score）与结构分数增益（Gain of Structure Score）**（也被叫做结构分数之差），更大程度地保证了CART树向减小目标函数的方向增长。

**XGBoost不接受其他指标作为分枝指标**，并不存在`criterion`参数。

**假设现在目标函数使用L2正则化，控制叶子数量的参数**`gamma`为0。现在存在一个叶子节点$j$，对该节点来说结构分数的公式为：$$ Score_j = \frac{(\sum_{i \in j}g_i)^2}{\sum_{i \in j}h_i + \lambda}$$

其中，$g_i$是样本$i$在损失函数$L$上对预测标签求的一阶导数，$h_i$是样本$i$在损失函数$L$上对预测标签求的二阶导数，$i \in j$表示对叶子$j$上的所有样本进行计算，$\lambda$就是L2正则化的正则化系数

节点$j$的结构分数：$$Score_j = \frac{节点j上所有样本的一阶导数之和的平方}{节点j上所有样本的二阶导数之和 + \lambda}$$

结构分数增益表现为：$$\begin{aligned}Gain &= Score_L + Score_R - Score_P \\ \\&= \frac{(\sum_{i \in L}g_i)^2}{\sum_{i \in L}h_i + \lambda} + \frac{(\sum_{i \in R}g_i)^2}{\sum_{i \in R}h_i + \lambda} - \frac{(\sum_{i \in P}g_i)^2}{\sum_{i \in P}h_i + \lambda}\\ \end{aligned}$$

节点$j$的结构分数增益：$$Gain = 左节点的结构分数 + 右节点的结构分数 - 父节点的结构分数$$

与CART做对比：$$CART树中的信息增益 = 父节点的不纯度 - （左节点的不纯度 + 右节点的不纯度）$$

CART追求的是最大的信息增益，这意味着随着CART树的建立，整体不纯度是在逐渐降低的。无论不纯度衡量指标是基尼系数还是信息熵，不纯度是越小越好。

XGBoost与CART树相反，**随着XGBoost树的建立，整体结构分数是逐渐上升的**，**结构分数越大越好**。

如果，左侧叶子节点上的结构分数为0.125，右侧叶子节点上的结构分数为8.333，这是否意味着左侧叶子比右侧叶子更好呢？

**答案是否定的。与信息熵、基尼系数等可以评价单一节点的指标不同，结构分数只能够评估结构本身的优劣，不能评估节点的优劣**。

**我们利用一棵树上所有叶子的结构分数之和来评估整棵树的结构的优劣**，分数越高则说明树结构质量越高，结构分数也被称为质量分数（quality score）

当`gamma`不为0时，结构分数增益的公式：$$\begin{aligned}Gain &= \frac{1}{2} ( Score_L + Score_R - Score_P ) - \gamma \\ \\&= \frac{1}{2} \left( \frac{(\sum_{i \in L}g_i)^2}{\sum_{i \in L}h_i + \lambda} + \frac{(\sum_{i \in R}g_i)^2}{\sum_{i \in R}h_i + \lambda} - \frac{(\sum_{i \in P}g_i)^2}{\sum_{i \in P}h_i + \lambda} \right) - \gamma\end{aligned}$$

##### 14.2.5  弱评估器剪枝

XGBoost只有三个剪枝参数和一个侧面影响树生长的参数，其中最为我们熟知的剪枝参数是**`max_depth`**，在XGBoost中默认值为6，因此在对抗过拟合方面**影响力不是很大**

-   **参数`min_child_weight`**：可以被广义理解为任意节点上所允许的样本量（样本权重）；

    更严谨的说法是，`min_child_weight`是在任意节点$j$上所允许的最小的$\sum_{i \in j}h_i$值。如果一个节点上的$\sum_{i \in j}h_i$小于该参数中设置的值，该节点被剪枝。$\sum_{i \in j}h_i$其实就是结构分数的分母的一部分。

    假设损失函数为$\frac{1}{2}MSE$，我们推导出任意样本的$h_i = 1$，因此$\sum_{i \in j}h_i$应该等于该叶子节点上的总样本量，**类似于sklearn中的`min_sample_leaf`**。

-   **参数`gamma`**：目标函数中叶子数量$T$前的系数，同时也是允许分枝的最低结构分数增益。当分枝时结构增益不足`gamma`中设置的值，该节点被剪枝；

    -   `gamma`是叶子数量$T$前的系数，放大gamma可以将目标函数的重点转移至结构风险，从而控制过拟合

    -   **任意结构的分数增益不能为负**，即$$\frac{1}{2} \left( \frac{(\sum_{i \in L}g_i)^2}{\sum_{i \in L}h_i + \lambda} + \frac{(\sum_{i \in R}g_i)^2}{\sum_{i \in R}h_i + \lambda} - \frac{(\sum_{i \in P}g_i)^2}{\sum_{i \in P}h_i + \lambda} \right) - \gamma > 0$$。

        当参数`gamma`为0时，任意增益为负的节点都会被剪枝。当`gamma`为任意正数时，任意增益小于`gamma`设定值的节点都会被剪枝，**相当于sklearn中的`min_impurity_decrease`**。

-   参数`lambda`和`alpha`：正则化系数，同时也位于结构分数中能间接影响树的生长和分枝；

    -   当使用L2正则化时，结构分数为：$$ Score_j = \frac{(\sum_{i \in j}g_i)^2}{\sum_{i \in j}h_i + \lambda}$$
        -   当`lambda`越大，结构分数会越小，参数`gamma`的力量会被放大，模型整体的剪枝会变得更加严格
        -   由于`lambda`还可以通过目标函数将模型学习的重点拉向结构风险，因此`lambda`具有双重扛过拟合能力
    -   当使用L1正则化时，结构分数为：$$ Score_j = \frac{(\sum_{i \in j}g_i)^2 + \alpha}{\sum_{i \in j}h_i}$$
        -   当`alpha`越大时，结构分数会越大，参数`gamma`的力量会被缩小，模型整体的剪枝会变得更宽松
        -   然而，`alpha`还可以通过目标函数将模型学习的重点拉向结构风险，因此`alpha`会通过放大结构分数抵消一部分扛过拟合的能力
    -   同时使用两种正则化，则结构分数为：$$ Score_j = \frac{(\sum_{i \in j}g_i)^2 + \alpha}{\sum_{i \in j}h_i + \lambda}$$

##### 14.2.6  弱评估器随机性

-   **样本的抽样**
    -   参数`subsample`：对样本进行抽样的比例，**XGBoost中的样本抽样是不放回抽样**
    -   参数`sampling_method`：对样本进行抽样时所使用的抽样方法，默认均匀抽样
        -   输入"`uniform`"：表示使用均匀抽样，每个样本被抽到的概率一致。如果使用均匀抽样，建议`subsample`的比例最好在0.5或以上
        -   输入"`gradient_based`"：表示使用有权重的抽样，并且每个样本的权重等于该样本的$\sqrt{g_i^2 +\lambda h_i^2}$，不支持XGBoost当中主流的`gbtree`等建树方法，因此一般我们不会用到
-   **特征的抽样**
    -   参数`colsample_bytree`，`colsample_bylevel`，`colsample_bynode`
    -   对于GBDT、随机森林来说，特征抽样是发生在每一次建树之前。但对XGBoost来说，特征的抽样可以发生在建树之前（由`colsample_bytree`控制）、生长出新的一层树之前（由`colsample_bylevel`控制）、或者每个节点分枝之前（由`colsample_bynode`控制）
    -   **全特征集 >= 建树所用的特征子集 >= 建立每一层所用的特征子集 >= 每个节点分枝时所使用的特征子集**

##### 14.2.7  其他参数

-   **提前停止**
    -   参数`early_stopping_rounds`：位于`xgb.train`方法当中
-   **模型监控与评估**
    -   参数`evals`：位于`xgb.train`方法当中，用于规定训练当中所使用的评估指标
    -   参数`verbosity`：用于打印训练流程和训练结果的参数
        -   0：不打印任何内容
        -   1：表示如果有警告，请打印警告
        -   2：请打印建树的全部信息
        -   3：我正在debug，请帮我打印更多的信息
-   **样本不均衡**
    -   参数`scale_pos_weight`：调节样本不均衡问题，类似于sklearn中的class_weight，仅在算法执行分类任务时有效
-   **并行的线程**
    -   参数`nthread`：允许并行的最大线程数，类似于sklearn中的n_jobs，默认为最大

#### 14.3  GBDT超参数优化

|                     影响力                     |                             参数                             |
| :--------------------------------------------: | :----------------------------------------------------------: |
|        ⭐⭐⭐⭐⭐<br>几乎总是具有巨大影响力         |  num_boost_round（整体学习能力）<br>eta（整体学习速率）<br>  |
|          ⭐⭐⭐⭐<br>大部分时候具有影响力          | booster（整体学习能力）<br>colsample_by*（随机性）<br>gamma（结构风险 + 精剪枝）<br>lambda（结构风险 + 间接剪枝）<br> min_child_weight（精剪枝） |
| ⭐⭐<br>可能有大影响力<br>大部分时候影响力不明显 | max_depth（粗剪枝）<br>alpha（结构风险 + 精剪枝）<br>subsamples（随机性）<br>objective（整体学习能力）<br>scale_pos_weight（样本不均衡） |
|       ⭐<br>当数据量足够大时，几乎无影响        |               seed<br>base_score（初始化）<br>               |

##### 14.3.1  XGBoost与GBDT调参对比

-   在随机森林中影响力巨大的`max_depth`在XGBoost中默认值为6，比GBDT中的调参空间略大，但还是没有太多的空间，因此影响力不足。

-   在GBDT中影响力巨大的`max_features`对标XGBoost中的`colsample_by*`系列参数，原则上来说影响力应该非常大，但由于三个参数共同作用，调参难度较高，在只有1个参数作用时效果略逊于`max_features`。

-   精剪枝参数往往不会对模型有太大的影响，但在XGBoost当中，`min_child_weight`与结构分数的计算略微相关，因此有时候会展现出较大的影响力。故而将这个精剪枝参数设置为4星参数。

    在总共有样本1460个，在五折交叉验证中训练集共有1460\*0.8 = 1168个样本。由于CART树是二叉树，我们规定的最大深度为5，因此最多有$2^5 = 32$个叶子节点，平均每个叶子结点上的样本量大概为1168/32 = 36.5个。粗略估计，如果`min_child_weight`是一个小于36.5的值，就可能对模型造成巨大影响。当然，不排除有大量样本集中在一片叶子上的情况。

-   类似于`objective`这样影响整体学习能力的参数一般都有较大的影响力，但XGBoost当中每种任务可选的损失函数不多，因此一般损失函数不在调参范围之内，故认为该参数的影响力不明显。

-   XGBoost的初始化分数只能是数字，因此当迭代次数足够多、数据量足够大时，起点的影响会越来越小。因此我们一般不会对base_score进行调参。

##### 14.3.2  调参顺序及范围

|        参数        |                             范围                             |
| :----------------: | :----------------------------------------------------------: |
| `num_boost_round`  |            学习曲线探索，最后定为<br>(50,200,10)             |
|       `eta`        |     以0.3为中心向两边延展，最后定为<br>(0.05,2.05,0.05)      |
|     `booster`      |                两种选项<br>["gbtree","dart"]                 |
| `colsample_bytree` | 设置为(0,1]之间的值，但由于还有参数`bynode`，因此整体不宜定得太小，因此定为<br>(0.3,1,0.1) |
| `colsample_bynode` |           设置为(0,1]之间的值，定为<br>(0.1,1,0.1)           |
|      `gamma`       |   学习曲线探索，有较大可能需要改变，定为<br>(1e6,1e7,1e6)    |
|      `lambda`      |               学习曲线探索，定为<br>(0,3,0.2)                |
| `min_child_weight` |                学习曲线探索，定为<br>(0,50,2)                |
|    `max_depth`     |      以6为中心向两边延展，右侧范围定得更大<br>(2,30,2)       |
|    `subsample`     |           设置为(0,1]之间的值，定为<br>(0.1,1,0.1)           |
|    `objective`     | 两种回归类模型的评估指标<br>["reg:squarederror", "reg:squaredlogerror"] |
|    `rate_drop`     | 如果选择"dart"树所需要补充的参数，设置为(0,1]之间的值<br>(0.1,1,0.1) |

#### 14.4  XGBoost流程

![XGBoost流程](https://cdn.jsdelivr.net/gh/louisyanglu/images/images/XGBoost%E6%B5%81%E7%A8%8B.png)

假设现有数据集$N$，含有形如$(x_i,y_i)$的样本$M$个，$i$为任意样本的编号，单一样本的损失函数为$l(y_i,H(x_i))$，其中$H(x_i)$是$i$号样本在集成算法上的预测结果，整个算法的损失函数为$L(y,H(x))$，且总损失等于全部样本的损失之和：$L(y,H(x)) = \sum_i l(y_i,H(x_i))$。目标函数中使用L2正则化（$\lambda$为0，$\alpha$为0），并且$\gamma$不为0。

同时，弱评估器为回归树$f$，总共学习$K$轮（注意在GBDT当中我们使用的是大写字母T来表示迭代次数，由于在XGBoost当中字母T被用于表示目标函数中的叶子总量，因此我们在这里使用字母K表示迭代次数）。则XGBoost回归的基本流程如下所示：

1.   **初始化**

     $$\begin{aligned}H_0(x) &= \mathop{argmin}_{C} \sum_{i=1}^M l(y_i,C)\\ \\&= \mathop{argmin}_{C} L(y,C)\end{aligned}$$

     当损失函数为MSE时，令整体初始损失最小的$C$值就是$y$的均值。在xgboost库中我们默认的初始值为0.5

2.   开始循环，for k in 1,2,3...K:

     **抽样**

     在现有数据集$N$中，抽样$M$ * `subsample`个样本，构成训练集$N^k$

3.   **求拟合项**

     对任意一个样本$i$，计算一阶导数$g_{ik}$，二阶导数$h_{ik}$，以及伪残差（pseudo-residuals）$r_{ik}$

     >   $$g_{ik} = \frac{\partial{l(y_i,H_{k-1}(x_i))}}{\partial{H_{k-1}(x_i)}}$$
     >
     >   $$h_{ik} = \frac{\partial^2{l(y_i,H_{k-1}(x_i))}}{\partial{H^2_{k-1}(x_i)}}$$
     >
     >   $$r_{ik} = -\frac{g_{ik}}{h_{ik}}$$

     $$标准写法：g_{ik} = \big[\frac{\partial{l(y_i,H(x_i))}}{\partial{H(x_i)}}\big]_{H(x_i) = H_{k-1}\ \ (x_i)}$$

     **拟合的伪残差到底是什么？**

4.   **建树**

     求解出伪残差后，在数据集$(x_i, r_{ik})$上按`colsample_by*`规则进行抽样，再按照**结构分数增益**规则建立一棵回归树$f_k$，建树过程不影响任何$g_{ik}$与$h_{ik}$的值

     >   叶子节点$j$的结构分数和任意分枝时的结构分数增益的公式为：
     >
     >   $$结构分数：Score_j = \frac{(\sum_{i \in j}g_i)^2}{\sum_{i \in j}h_i + \lambda}$$
     >
     >   $$结构分数增益：Gain = \frac{1}{2} \left( \frac{(\sum_{i \in L}g_i)^2}{\sum_{i \in L}h_i + \lambda} + \frac{(\sum_{i \in R}g_i)^2}{\sum_{i \in R}h_i + \lambda} - \frac{(\sum_{i \in P}g_i)^2}{\sum_{i \in P}h_i + \lambda} \right) - \gamma$$

     为什么要这么建树？

5.   **输出树上的结果**

     建树之后，依据回归树$f_k$的结构输出叶子节点上的输出值（预测值）。叶子节点上的输出值与结构分数很相似，只不过结构分数的分子上是平方，而输出值的分子上没有平方。**该输出值能让目标函数最快减小**

     >   对任意叶子节点$j$来说，输出值为：$$w_j = -\frac{\sum_{i \in j}g_{ik}}{\sum_{i \in j}h_{ik} + \lambda}$$

     为什么要这么输出？

6.   **迭代**

     根据预测结果$f_k(x_i)$迭代模型

     >   $$H_k(x_i) = H_{k-1}(x_i) + f_k(x_i)$$
     >
     >   假设输入的步长为$\eta$，则$H_k(x)$应该为：$$H_k(x_i) = H_{k-1}(x_i) + \eta f_k(x_i)$$
     >
     >   对整个算法则有：$$H_k(x) = H_{k-1}(x) + \eta f_k(x)$$

7.   **循环结束**

     输出$H_K(x)$的值作为集成模型的输出值

#### 14.5  化简目标函数

##### 14.5.1  目标函数的自变量

XGBoost的目标函数含多个变量，选择哪一个作为自变量，来求解最小目标函数？

**XGBoost中目标函数是针对一棵树的目标函数**

假设单一树$f_k$的目标函数为$O_k$，总共有$T$片叶子，该树上任意样本$i$的损失函数为$l((y_i,H(x_i))$，其中$H(x_i)$是$i$号样本在集成算法上的预测结果。树上总共有M个样本，目标函数中使用L2正则化（$\lambda$不为0，$\alpha$为0），并且$\gamma$不为0，则该树的目标函数为：$$O_k = \sum_{i=1}^Ml(y_i,H_k(x_i)) + \gamma T + \frac{1}{2}\lambda\sum_{j=1}^Tw_j^2$$

**我们的目标是令目标函数最小，并找出令目标函数最小的某个自变量**

$$l_k = l(y_i,H_k(x_i)) = l(y_i,H_{k-1}(x_i) + f_k(x_i))$$

当迭代到第$k$次时，损失函数中的$y_i$与$H_{k-1}(x_i)$都是常数，只有$f_k(x_i)$是变量，因此我们只需要在损失函数上对$f_k(x_i)$求导，并找到令整体损失函数最小的预测值$f_k(x_i)$即可。**无论弱评估器$f_k$是什么结构、什么规则、如何建立、如何拟合，只要其最终的输出值$f_k(x_i)$是令整体损失函数$L$最小化的$f_k(x_i)$，那随着算法逐步迭代，损失函数必然会越来越小**。因此，一个适合的$f_k(x_i)$不仅能保证损失持续减小，还可以指导单个评估器的建立。

在GBDT当中，令GBDT整体损失函数最小化的$f_k(x_i)$就是损失函数的负梯度$-g_i$，也因此GBDT在建树时拟合负梯度。当损失函数为$\frac{1}{2}MSE$时，GBDT中的负梯度在数值上就等于残差，因此GBDT是拟合残差的算法。

但问题在于，XGBoost的目标函数中存在多个自变量：$$\begin{aligned} O_k &= \sum_{i=1}^Ml(y_i,H_k(x_i)) + \gamma T + \frac{1}{2}\lambda\sum_{j=1}^Tw_j^2 \\ &= \sum_{i=1}^M l \left( y_i,H_{k-1}(x_i) + \boldsymbol{\color{red}{f_k(x_i)}} \right) + \gamma \boldsymbol{\color{red}T} + \frac{1}{2}\lambda\sum_{j=1}^T\boldsymbol{\color{red}{w_j}}^2 \end{aligned}$$

其中，$T$是第$k$棵树上的叶子总量，$f_k(x_i)$与$w_j$都是模型输出的预测值（叶子上的输出值），对任意位于叶子$j$上的样本$i$而言，数值上$f_k(x_i) = w_j$

对XGBoost来说，只能选择一个变量作为自变量。考虑到$f_k(x_i)$只与单个样本的精确程度有关，而$T$只与树结构有关，XGBoost论文最终选择了即与精确度有关、又与树结构有关的变量**$w_j$**

因此，求解XGBoost目标函数的第一步，就是将目标函数尽量整理成以$w_j$表示的形式。

##### 14.5.2  目标函数泰勒展开

>   **泰勒级数（无限项）**：$$f(x) = \sum_{n=0}^{\infty}\frac{f^{(n)}(a)}{n!}(x-a)^n$$
>
>   **一阶泰勒展开**：$$\begin{aligned}f(x) &\approx \sum_{n=0}^{1}\frac{f^{(n)}(a)}{n!}(x-a)^n \\&\approx f(a) + \frac{f'(a)}{1!}(x-a)\end{aligned}$$
>
>   **二阶泰勒展开**：$$\begin{aligned}f(x) &\approx \sum_{n=0}^{2}\frac{f^{(n)}(a)}{n!}(x-a)^n \\&\approx f(a) + \frac{f'(a)}{1!}(x-a) + \frac{f''(a)}{2!}(x-a)^2\end{aligned}$$
>
>   **N阶泰勒展开**：$$\begin{aligned}f(x) &\approx \sum_{n=0}^{N}\frac{f^{(n)}(a)}{n!}(x-a)^n \\&\approx f(a) + \frac{f'(a)}{1!}(x-a) + \frac{f''(a)}{2!}(x-a)^2 + \frac{f'''(a)}{3!}(x-a)^3 + ...\end{aligned}$$

对目标函数$$O_k = \sum_{i=1}^Ml \left( y_i,H_{k-1}(x_i) + f_k(x_i) \right) + \gamma T + \frac{1}{2}\lambda\sum_{j=1}^T w_j^2$$中，第一部分**损失函数进行泰勒展开**

令泰勒展开中的$x = H_{k-1}(x_i) + f_k(x_i)$，令泰勒展开中的$a = H_{k-1}(x_i)$，则$(x-a) = f_k(x_i)$。据此，损失函数$l(H_{k-1}(x_i) + f_k(x_i))$可以被表示为：$$\begin{aligned}l(H_{k-1}(x_i) + f_k(x_i)) &\approx l(H_{k-1}(x_i)) + \frac{\partial{l(H_{k-1}(x_i))}}{\partial{H_{k-1}(x_i)}} * f_k(x_i) +  \frac{\partial^2{l(H_{k-1}(x_i))}}{2\partial{H^2_{k-1}(x_i)}} * f^2_k(x_i)\\\end{aligned}$$

定义：$$g_{ik} = \frac{\partial{l(y_i,H_{k-1}(x_i))}}{\partial{H_{t-1}(x_i)}}$$，$$h_{ik} = \frac{\partial^2{l(y_i,H_{k-1}(x_i))}}{\partial{H^2_{t-1}(x_i)}}$$

$$\begin{aligned}l(H_{k-1}(x_i) + f_k(x_i)) &\approx l(H_{k-1}(x_i)) + g_if_k(x_i) + \frac{1}{2}h_if^2_k(x_i) \\ &\approx 常数 + g_if_k(x_i) + \frac{1}{2}h_if^2_k(x_i) \end{aligned}$$

将常数从该目标函数中剔除，目标函数变为：$$\begin{aligned} \tilde{O}_k &= \sum_{i=1}^M\left(g_if_k(x_i) + \frac{1}{2}h_if^2_k(x_i)\right) + \gamma T + \frac{1}{2}\lambda\sum_{j=1}^T w_j^2 \\ &= \sum_{i=1}^Mg_if_k(x_i) + \frac{1}{2}\sum_{i=1}^Mh_if^2_k(x_i) + \gamma T + \frac{1}{2}\lambda\sum_{j=1}^T w_j^2\end{aligned}$$

现在目标函数的前两项分别代表所有样本的$g_if_k(x_i)$之和，以及所有样本的$h_if^2_k(x_i)$之和乘1/2。别忘记，我们选择的唯一的自变量是$w_j$，因此我们希望能够将$f_k$以某种方式转化为$w_j$。之前已经提到过多次，对任意位于叶子$j$上的样本$i$而言，数值上$f_k(x_i) = w_j$，我们可以尝试着从一个样本开始进行转化：

>    对于单一样本$i$，假设这个样本位于叶子$j$上，应该有：$$g_if_k(x_i) = g_iw_j$$
>
>    对于一片叶子$j$，我们可以计算这片叶子上所有样本的$g_iw_j$之和：$$\sum_{i \in j} g_iw_j $$
>
>    而一片叶子上所有样本的$w_j$都是一致的，因此一片叶子上的$g_iw_j$​之和可以转变为：$$\begin{aligned}\sum_{i \in j} g_iw_j &= g_1w_j \ + \ g_2w_j \ + \ ... \ + \ g_nw_j，其中1,2...n是叶子j上的样本 \\&= w_j\sum_{i \in j} g_i\end{aligned}$$
>
>    假设现在一共有$T$片叶子，则整棵树上所有样本的$g_iw_j$之和为：$$\sum_{j=1}^T \left( w_j\sum_{i \in j} g_i \right)$$

因此，$$\sum_{i=1}^Mg_if_k(x_i) = \sum_{j=1}^T \left( w_j\sum_{i \in j} g_i \right)$$

同理，$$\sum_{i=1}^Mh_if^2_k(x_i) = \sum_{j=1}^T \left( w^2_j\sum_{i \in j} h_i \right)$$

因此对整个目标函数有：$$\begin{aligned} \tilde{O}_k &= \sum_{i=1}^Mg_if_k(x_i) + \frac{1}{2}\sum_{i=1}^Mh_if^2_k(x_i) + \gamma T + \frac{1}{2}\lambda\sum_{j=1}^T w_j^2 \\ &=\sum_{j=1}^T \left( w_j\sum_{i \in j} g_i + \frac{1}{2}w^2_j\sum_{i \in j} h_i \right) + \gamma T + \frac{1}{2}\lambda\sum_{j=1}^T w_j^2 \\ &= \sum_{j=1}^T \left( w_j\sum_{i \in j} g_i + \frac{1}{2}w^2_j\sum_{i \in j} h_i + \frac{1}{2}\lambda w_j^2 \right) + \gamma T \\ &= \sum_{j=1}^T \left( w_j\sum_{i \in j} g_i + \frac{1}{2}w^2_j(\sum_{i \in j} h_i + \lambda) \right) + \gamma T\end{aligned}$$

整个目标函数变为两项，一项是所有叶子上的（损失+正则）之和，另一项是叶子总量

#### 14.6  求解目标函数

>   首先，令目标函数中的叶子总量最小是不可能的，过度降低叶子总量会大幅度伤害模型的学习能力，因此我们只能考虑令所有叶子上的（损失+正则）之和最小。
>
>   其次，当树建好之后，叶子与叶子之间是相互独立的，因此每片叶子上的（损失+正则）也是相互独立的。我们只要令每片叶子的（损失+正则）都最小，就可以保证全部叶子的（损失+正则）之和最小

$$\begin{aligned}\tilde{O}_k &= \sum_{j=1}^T \left( \boldsymbol{\color{red}{w_j\sum_{i \in j} g_i + \frac{1}{2}w^2_j(\sum_{i \in j} h_i + \lambda)}} \right) + \gamma T\end{aligned}$$

令式子中标注为红色的部分最小，将其命名为$\mu_j$，表示叶子$j$上的损失+正则。则有：$$\mu_j = w_j\sum_{i \in j} g_i + \frac{1}{2}w^2_j(\sum_{i \in j} h_i + \lambda)$$

**对叶子$j$而言**，在$\mu_j$上对唯一自变量$w_j$求导：

$$\begin{aligned}\frac{\partial{\mu_j}}{\partial w_j}&= \frac{\partial{w_j\sum_{i \in j} g_i + \frac{1}{2}w^2_j(\sum_{i \in j} h_i + \lambda)}}{\partial w_j} \\ \\&= \sum_{i \in j} g_i + w_j(\sum_{i \in j} h_i + \lambda)\end{aligned}$$

令一阶导数为0，则有：$$\begin{aligned}\sum_{i \in j} g_i + w_j(\sum_{i \in j} h_i + \lambda) &= 0 \\ \\w_j(\sum_{i \in j} h_i + \lambda) &= -\sum_{i \in j} g_i \\ \\w_j &= -\frac{\sum_{i \in j} g_i}{\sum_{i \in j} h_i + \lambda}\end{aligned}$$

**对一片叶子来说，令目标函数最小的$w_j$就是我们之前提过的叶子权重，也就是XGBoost数学流程当中叶子上的输出值**

##### 14.6.1  拟合值

**如果要令叶子的输出非常接近叶子权重公式，那应该如何拟合每个样本呢？**

**对任意位于叶子$j$上的样本$i$来说**，$$\mu_i = w_jg_i + \frac{1}{2}w^2_jh_i$$（没有$\lambda$）

>   将一片叶子上的$\mu_j$转变成$\mu_i$时，原则上需要将$\mu_j$中的每一项都转换为单个样本所对应的项，然而在转换正则项时则存在问题：与$\sum_{i \in j} g_i$这样可以直接指向单个样本的项不同，**$\lambda$是针对与一片叶子设置的值**，如果要将$\lambda$转变为针对单一样本的正则项，则需要知道当前叶子上一共有多少样本。然而，拟合发生在建树之前，因此在这一时间点不可能知道一片叶子上的样本总量，因此在xgboost的实际实现过程当中，**拟合每一片叶子时不涉及正则项**，只有在计算结构分数与叶子输出值时才使用正则项

对$\mu_i$上唯一的自变量$w_j$求导，则有：$$\begin{aligned}\frac{\partial{\mu_i}}{\partial w_j}&= \frac{\partial{\left( w_jg_i + \frac{1}{2}w^2_jh_i \right)}}{\partial w_j} \\ \\&= g_i + w_jh_i\end{aligned}$$

令一阶导数为0，则有：$$\begin{aligned}g_i + w_jh_i &= 0 \\ \\w_jh_i &= - g_i \\ \\w_j &= -\frac{g_i}{h_i} \end{aligned}$$

**对任意样本$i$而言，令目标函数最小的最优$w_j$就是我们的伪残差$r_i$，也就是XGBoost数学流程当中用于进行拟合的拟合值**

##### 14.6.2  结构分数

把令目标函数最小的最优$w_j$带回到$\mu_j$中，$w_j = -\frac{\sum_{i \in j} g_i}{\sum_{i \in j} h_i + \lambda}$

$$\begin{aligned}\mu_j &= w_j\sum_{i \in j} g_i + \frac{1}{2}w^2_j(\sum_{i \in j} h_i + \lambda) \\&= -\frac{\sum_{i \in j} g_i}{\sum_{i \in j} h_i + \lambda} * \sum_{i \in j} g_i + \frac{1}{2}(-\frac{\sum_{i \in j} g_i}{\sum_{i \in j} h_i + \lambda})^2 * {\sum_{i \in j} h_i + \lambda}\\&= -\frac{(\sum_{i \in j} g_i)^2}{\sum_{i \in j} h_i + \lambda} + \frac{1}{2}\frac{(\sum_{i \in j} g_i)^2}{\sum_{i \in j} h_i + \lambda} \\&= - \frac{1}{2}\frac{(\sum_{i \in j} g_i)^2}{\sum_{i \in j} h_i + \lambda}\end{aligned}$$

因此，一片叶子上的目标函数就是：$$ O_j = -\frac{1}{2}\frac{(\sum_{i \in j} g_i)^2}{\sum_{i \in j} h_i + \lambda} + \gamma$$

对任意叶子，我们希望标注为红色的部分越小越好：$$ O_j = \frac{1}{2}\left( \boldsymbol{\color{red}{-\frac{(\sum_{i \in j} g_i)^2}{\sum_{i \in j} h_i + \lambda}}} \right)+ \gamma$$

故而，我们希望以下式子越大越好：$$\frac{(\sum_{i \in j} g_i)^2}{\sum_{i \in j} h_i + \lambda}$$

**这正是XGBoost用于分枝时的指标“结构分数”（Structure Score）**

##### 14.6.3  结构分数的增益

当分枝的时候，我们希望目标函数越小越好，因此在分枝过程中，父节点的目标函数是大于子节点的目标函数的，因此我们可以使用（父节点目标函数 - 子节点目标函数之和）来衡量分枝的质量

$$\begin{aligned}Gain &= O_p - (O_l + O_r) \\ \\&= -\frac{1}{2}\frac{(\sum_{i \in P} g_i)^2}{\sum_{i \in P} h_i + \lambda} + \gamma - (-\frac{1}{2}\frac{(\sum_{i \in L} g_i)^2}{\sum_{i \in L} h_i + \lambda} + \gamma  -\frac{1}{2}\frac{(\sum_{i \in R} g_i)^2}{\sum_{i \in R} h_i + \lambda} + \gamma) \\ \\&= -\frac{1}{2}\frac{(\sum_{i \in P} g_i)^2}{\sum_{i \in P} h_i + \lambda} + \gamma + \frac{1}{2}\frac{(\sum_{i \in L} g_i)^2}{\sum_{i \in L} h_i + \lambda} - \gamma + \frac{1}{2}\frac{(\sum_{i \in R} g_i)^2}{\sum_{i \in R} h_i + \lambda} - \gamma \\ \\&= \frac{1}{2}\left( \frac{(\sum_{i \in L} g_i)^2}{\sum_{i \in L} h_i + \lambda} + \frac{(\sum_{i \in R} g_i)^2}{\sum_{i \in R} h_i + \lambda} - \frac{(\sum_{i \in P} g_i)^2}{\sum_{i \in P} h_i + \lambda} \right) - \gamma \\ \\&= \frac{1}{2} (Score_L + Score_R - Score_P) - \gamma\end{aligned}$$

其中，$\gamma$是可以设定的超参数，$\frac{1}{2}$为常数，因此：$$Gain = Score_L + Score_R - Score_P$$

**这就是我们在分枝时所使用的结构分数增益了**

XGBoost流程中所使用的全部新公式（包括独特的拟合值、独特的分枝指标、独特的输出值）都是通过令目标函数最小而求解出来的。因此，XGBoost整个流程就保证了目标函数一定是向着最小化方向进行迭代的，新生成的每片叶子上的输出值$w_j$都是会令目标函数最小化的输出值。

<div style="page-break-after:always"></div>

------

### 第15章  特征衍生

#### 15.1  业务背景与数据探索

![15.1 业务背景与数据探索](https://cdn.jsdelivr.net/gh/louisyanglu/images/images/15.1%20%E4%B8%9A%E5%8A%A1%E8%83%8C%E6%99%AF%E4%B8%8E%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2.png)

##### 15.1.1  业务背景

数据来源、业务逻辑、字段含义

##### 15.1.2  数据探索

**数据质量探索**

1.   正确性校验

     -   训练集、测试集字段是否一致

     -   训练集、测试集ID列是否重复

         ```python
         data['customerID'].nunique() == data.shape[0]
         data.duplicated().sum()
         ```

2.   缺失值校验

     ```python
     get_data_info(data)
     plot_missing(data)
     ```

**字段类型探索**

1.   标注连续、离散、时序变量

     -   categorical_features

     -   numeric_features

     -   ordinal_features，从categorical_features中筛选

     -   high_cardinality_features，高基数分类特征

     -   date_features，日期特征

     -   ignore_features，不参与建模的特征

     ```python
     get_variable_category(dat)
     ```

2.   对包含空格的字段进行处理

     ```python
     process_blank_cols(dat)
     ```

**异常值检测**（连续型变量）

>   一般来说，数据分布越倾向于**正态分布**，则通过**三倍标准差**或者**箱线图**检测的异常值会更加准确一些。此外，在很多时候，异常值或许是某类特殊用户的标识，有的时候我们需要围绕异常值进行单独分析，而不是简单的对其进行修改。

1.   孤立森林

     ```python
     find_outliers_by_isoforest(data, numeric_cols, if_plot=True)
     ```

2.   距均值3倍标准差

     ```python
     find_outliers_by_feature(dat, numeric_cols)  # 单变量
     find_outliers_by_modelpred(model, X, y)  # y标签
     ```

3.   箱线图

     ```python
     plot_box(data)
     ```

**相关性探索分析**

1.   y标签分布

     ```python
     sns.displot(y)
     ```

2.   相关性分析

     >   1.   **连续变量之间**相关性可以使用**皮尔逊相关系数**进行计算
     >   2.   **连续变量和离散变量之间**相关性则可以**卡方检验**进行分析
     >   3.   **离散变量之间**则可以从**信息增益**角度入手进行分析

     ```python
     # 初步探查变量之间是否存在相关关系，则可以忽略变量连续/离散特性，统一使用相关系数进行计算
     df_corr = get_pearson_corr(df)  # 将其他所有分类变量转化为哑变量
     plot_heatmap(df_corr)
     plot_bar_corr(df_corr, y_col='target')
     ```

3.   柱状图/堆叠柱状图查看离散变量与target之间的关系

     ```python
     plot_stacked_histogram(data, category_cols, y_col='target')
     ```

#### 15.2  数据预处理

>   缺失值、异常值、重复值处理、数据字段类型调整

#### 15.3  特征创建与检验

>   调整特征结构，使数据规律更容易被模型识别，如特征衍生、时序/文本字段处理等。

##### 15.3.1  基于业务背景来衍生字段

>   衍生的字段能否提升模型效果，可以简单通过计算该字段与标签之间的相关性来进行检验，如果该字段与标签相关性较强，则大概率加入该字段后模型效果会有所提升。

##### 15.3.2  基于数据分布来衍生字段

>   “什么样的特征能更好的帮助模型进行建模结果”。
>
>   特征衍生工作并不是为了创造更多的信息，而是更好的去呈现既有信息。一般来说，如果我们创建的特征对应的不同类别比例差异越大、则该特征就越有利于帮助模型完成训练。

<img src="https://cdn.jsdelivr.net/gh/louisyanglu/images/images/1.%E7%89%B9%E5%BE%81%E5%88%9B%E5%BB%BA%E4%B8%8E%E6%A3%80%E9%AA%8C.png" alt="1.特征创建与检验" style="zoom: 33%;" />

从那些本身对标签有较高区分度的特征（如逾期率/流失率特别大或小的特征）入手进行分析（堆叠柱状图）、多变量交叉分析、IV值计算。

$$IV = \sum^{N}_{i=1}IV_i=\sum^{N}_{i=1}(P_{good}^{(i)}-P_{Bad}^{(i)})*WOE_i=\sum^{N}_{i=1}(P_{good}^{(i)}-P_{Bad}^{(i)})*ln\frac{P_{Good}^{(i)}}{P_{Bad}^{(i)}}$$，其中$i$则表示某特征的不同取值，$P_{Good}$和$P_{Bad}$则是在对应特征某取值下分组汇总后算得出来的1类样本和0类样本占所有1类/0类样本的比例。

| IV值         | 特征效果           |
| ------------ | ------------------ |
| <0.03        | 无效特征           |
| [0.03, 0.09) | 具有较弱判别效果   |
| [0.1, 0.29)  | 具有一定的判别效果 |
| [0.3, 0.49)  | 具有较好的判别效果 |
| >=0.5        | 具有极强的判别效果 |

多个字段组合而成的新字段，在信息量上会和原始字段有些重叠，若是需要通过IV值来判断新字段是否有用，则不能简单看新字段的IV值，而是需要用新字段的IV值和原始字段进行对比，新字段IV值至少要比原始字段IV最小值要大，新字段才是有效字段。

#### 15.4  批量特征衍生

>   批量特征衍生往往会创造出非常多的特征，而这些特征并不是每个都能帮助模型训练的出更好的结果，并且特征列本身过多也会极大程度上影响建模效率。此外，批量特征衍生还将造成另外的一个问题，那就是很多衍生出来的特征并不具备业务层面的可解释性。但是，这并不代表该特征就一定无法帮助模型训练得出一个更好的结果。在机器学习整体都是后验思想为主导的情况下，我们往往不会过于关注批量衍生的特征具体的业务含义，而只考虑最终的建模效果，也就是说，批量特征衍生+特征筛选的策略，完全是一个“依据建模结果说话”的策略。

<img src="https://cdn.jsdelivr.net/gh/louisyanglu/images/images/2.%E7%89%B9%E5%BE%81%E8%A1%8D%E7%94%9F%E6%96%B9%E6%B3%95.png" alt="2.特征衍生方法" style="zoom:33%;" />

##### 15.4.1  单变量特征衍生

![15.4.1 单变量特征衍生](https://cdn.jsdelivr.net/gh/louisyanglu/images/images/15.4.1%20%E5%8D%95%E5%8F%98%E9%87%8F%E7%89%B9%E5%BE%81%E8%A1%8D%E7%94%9F.png)

1.   **单变量**（离散/连续）

     -   优先考虑**分类变量的独热编码**，并同时保留原始变量与独热编码衍生后的变量。独热编码能够丰富树模型生长过程中备选的数据集切分点，因此能够进一步丰富集成学习中不同树模型可能的差异性。但同时也需要注意的是有两种情况不适用于使用独热编码，其一是分类变量取值水平较多（例如超过10个取值），此时独热编码会造成特征矩阵过于稀疏，从而影响最终建模效果；其二则是如果该离散变量参与后续多变量的交叉衍生，则一般需再对单独单个变量进行独热编码；    

     -   优先考虑**连续变量的数据归一化**，尽管归一化不会改变数据集分布，即无法通过形式上的变换增加树生长的多样性，但归一化能够加快梯度下降的执行速度，加快迭代收敛的过程；

     -   在连续变量较多的情况下，可以考虑**对连续变量进行分箱**，原因同第一点。具体分享方法优先考虑聚类分箱，若数据量过大，可以使用MiniBatch K-Means提高效率，或者也可以简化为等频率/等宽分箱；    

     -   不建议对单变量使用多项式衍生方法，相比单变量的多项式衍生，带有交叉项的多变量的多项式衍生往往效果会更好。


##### 15.4.2  双变量特征衍生

![15.4.2 双变量特征衍生](https://cdn.jsdelivr.net/gh/louisyanglu/images/images/15.4.2%20%E5%8F%8C%E5%8F%98%E9%87%8F%E7%89%B9%E5%BE%81%E8%A1%8D%E7%94%9F.png)

1.   **双变量交叉**（离散）

     -   交叉组合后衍生的特征个数是参数交叉组合的特征的取值水平之积，因此交叉组合特征衍生一般**只适用于取值水平较少的分类变量**之间进行，若是分类变量或者取值水平较多的离散变量彼此之间进行交叉组合，则会导致衍生特征矩阵过于稀疏。

     -   参与交叉组合的特征本身分类水平更多，衍生的特征数量也将指数级上涨。例如有10个二分类变量参与交叉衍生，则最终将衍生出$2^{10}=1024$个新特征，而如果是10个三分类变量参与交叉衍生，则最终将衍生出$3^{10}=29049$个新特征。


2.   **基于离散变量的分组统计**（离散+离散/连续）

     A特征根据B特征的不同取值进行分组统计，统计量可以是均值、方差等针对连续变量的统计指标，也可以是众数、分位数等针对离散变量的统计指标。

     -   **分组特征必须是离散变量**，且最好是一些取值较多的离散变量。主要原因是如果B特征取值较少，则在衍生的特征矩阵中会出现大量的重复的行；

     -   在实际计算A的分组统计量时，可以不局限于连续特征只用连续变量的统计量、离散特征只用离散的统计量，完全可以交叉使用；

     -   还会考虑进一步围绕特征A和分组统计结果进行再一次的四则运算特征衍生，例如用月度消费金额减去分组均值，则可以比较每一位用户与相同时间入网用户的消费平均水平的差异；

     -   在进行分组统计时，需要注意某些统计指标在计算过程中可能造成缺失值，需要在执行完特征衍生后再进行缺失值查找。


3.   **双变量多项式衍生**（连续）

     -   不会随意组合连续变量来进行多项式衍生，而是只针对我们判断**非常重要的特征来进行多项式衍生**，强化重要特征的表现形式；

     -   一般来说伴随着多项式阶数的增加，各列数值也会呈现指数级递增（或递减），因此往往我们只会衍生3阶左右。


4.   **双变量二阶统计特征**（离散+连续）

     当我们已经完成了一些特征衍生后，还会考虑以衍生特征为基础，进一步进行特征衍生，这也就是所谓的二阶特征衍生。

     不过，在大多数情况下，二阶甚至是更高阶的特征衍生（以下简称高阶特征衍生）往往伴随着严重的信息衰减，大多数高阶衍生出来的特征其本身的有效性也将急剧下降，外加高阶特征衍生是在已有的大量衍生出来的一阶特征基础上再进行衍生，其计算过程往往需要消耗巨大的计算量，外加需要从一系列高阶衍生特征中挑选出极个别有用的特征也较为繁琐，因此，高阶衍生往往性价比较低，除非特殊情况，否则并不建议在广泛特征基础上进行大量高阶特征衍生的尝试。

5.   **目标编码**

     将标签在某特征上的分组统计结果作为特征。

     -   有两点需要注意，其一是由于目标编码带入了标签数据，而测试集标签未知，因此目标编码是一定需要划分训练集和测试集的，并且将训练集上的编码结果带入测试集。
     -   其二需要注意的是，带入标签信息进行特征衍生是极容易造成模型过拟合的。

     为了避免目标编码可能导致的过拟合问题，一方面我们要尽可能控制分组时分组的数量（即计量避免过多特征的交叉组合），其二则是可以借助K折交叉统计方法来执行目标编码，以期尽量避免标签的直接泄露。

     <img src="https://cdn.jsdelivr.net/gh/louisyanglu/images/images/X67neFAgdTwRlmY.png" alt="X67neFAgdTwRlmY" style="zoom:30%;" /><img src="https://cdn.jsdelivr.net/gh/louisyanglu/images/images/SyGZVeNFmoB4jlQ.png" alt="SyGZVeNFmoB4jlQ" style="zoom:22%;" /><img src="https://cdn.jsdelivr.net/gh/louisyanglu/images/images/tBp49kXNOmelJcg.png" alt="tBp49kXNOmelJcg" style="zoom:30%;" />

     <img src="https://cdn.jsdelivr.net/gh/louisyanglu/images/images/lKo98urN4pji2Ad.png" alt="lKo98urN4pji2Ad" style="zoom:33%;" />

     

##### 15.4.3  多变量特征衍生

![15.4.3 多变量特征衍生](https://cdn.jsdelivr.net/gh/louisyanglu/images/images/15.4.3%20%E5%A4%9A%E5%8F%98%E9%87%8F%E7%89%B9%E5%BE%81%E8%A1%8D%E7%94%9F.png)

1.   **多变量交叉**（离散）

     伴随着交叉组合特征数量的增加、以及每个特征取值水平增加，衍生出来的特征数量将呈指数级上涨趋势，例如3个包含两个分类水平的离散变量进行交叉组合时，将衍生出$2^3=8$个特征，而如果是10个包含三个分类水平的离散变量进行交叉组合，则将衍生出$3^{10}=59049$个特征。

     在m个n分类特征的交叉组合过程中，假设总共有k条数据，则0值的占比为：$$\frac{n^m*k-k}{n^m*k}=1-\frac{1}{n^m}$$。即如果是3个2分类水平的特征进行交叉组合衍生，则新的特征矩阵中0值占比为$1-\frac{1}{8}=\frac{7}{8}=87.5$%；而如果是10个三分类变量进行交叉组合衍生，则新特征矩阵中0值占比为$1-\frac{1}{3^{10}}=99.99831$%。

     **一般来说，如果有多个特征要进行交叉组合衍生，我们往往优先考虑两两组合进行交叉组合衍生**，只有在人工判断是极为重要的特征情况下，才会考虑对其进行三个甚至更多的特征进行交叉组合衍生。

2.   **多变量分组统计**（离散变量交叉组合+离散/连续）

     在双变量分组特征衍生时，我们是选择某个特征为KeyCol（关键特征），然后以KeyCol的不同取值为作为分组依据，计算其他特征的统计量。而在多变量分组特征衍生的过程中，我们将考虑采用不同离散变量的交叉组合后的取值作为分组依据，再进行分组统计量的计算。

     多变量分组统计特征衍生能够更细粒度的呈现数据集信息，因此，有限范围内的多变量分组统计特征衍生，是能达到更好的效果的。但同时需要注意的是，这种“细粒度”的呈现并不是越细粒度越好，我们知道，参与分组的交叉特征越多、分组也就越多，而在相同数据集下，分组越多、每一组的组内样本数量就越少，而在进行组内统计量计算时，如果组内样本数量太少，统计量往往就不具备代表性了。

     **一般来说，对于人工判断极重要的特征，可以考虑两个或三个特征进行交叉组合后分组。**

3.   **多变量多项式衍生**（连续）

     多变量的多项式衍生和多变量两两交叉多项式衍生的差异主要体现在多个变量的交叉项上，当然伴随着多项式阶数增加，多变量交叉项本身也会更多更复杂，二者差异也会更加明显。当然，多个特征的交叉组合乘积也同样会增加特征的表现，但同时也会增加伴随着多变量多项式衍生的变量数量增加以及阶数的增加，特征数量也会呈指数级增加趋势，并且衍生特征的取值也将变得非常不稳定，会伴随着阶数增加绝对值快速趋近于0或者一个非常大的数。因此，和此前的多变量特征衍生方法的使用场景类似，一般是针对人工判断的非常重要的特征可以考虑进行多变量的三阶甚至四阶多项式衍生。

##### 15.4.4  **时序特征衍生**

![15.4.4 时序特征衍生](https://cdn.jsdelivr.net/gh/louisyanglu/images/images/15.4.4%20%E6%97%B6%E5%BA%8F%E7%89%B9%E5%BE%81%E8%A1%8D%E7%94%9F.png)

首先就需要将时间字段转化为年-月-季度的基本格式。

时序字段衍生的本质：增加分组。而对用户进行分组之所以能够帮助模型进行建模与训练，其根本原因也是因为有的时候，同一组内（或者是多组交叉）的用户会表现出相类似的特性（或者规律），从而能够让模型更快速的对标签进行更准确的预测。

##### 15.4.5  **NLP特征衍生**

![15.4.5 NLP特征衍生](https://cdn.jsdelivr.net/gh/louisyanglu/images/images/15.4.5%20NLP%E7%89%B9%E5%BE%81%E8%A1%8D%E7%94%9F.png)

NLP特征衍生并不是真的去处理文本字段，而是借助文本字段的处理方法与思想，来处理数值型的离散变量，来衍生出更多有效特征。

1.   **CountVectorizer**，词频词向量转化方法。

     >   CountVectorizer是简单的单词计数，单词出现的次数越高、我们往往就认为该单词对文本的表意就起到了越关键的作用。向量的转化过程其本质就是一个对序列进行有效信息提取的过程，这里指的有效信息实际上就是指对后续建模有帮助的信息。

     将数据集类比于一个文本。这里首先将OnlineSecurity、OnlineBackup和DeviceProtection视作文本中的不同单词（Term），并根据tenure不同取值对用户进行分组，每个分组视作一个Document，则可将原数据集转化为文本数据，然后再使用CountVectorizer进行计算。

<img src="https://cdn.jsdelivr.net/gh/louisyanglu/images/images/osv7ECDTV8zmNZX.png" alt="osv7ECDTV8zmNZX" style="zoom: 33%;" />

2.   **TF-IDF**，也就是所谓的词频-逆向词频统计。

-   >   TF-IDF的计算总共分为两部分，其一是TF（term frequency），也就是每个单词出现的次数，和vectorizer结果一致，这里用$tf(d,t)$表示；第二部分是IDF（inverse document frequency），也就是所谓的逆向文件频率，指的是包含该单词的文本占总文本的比例的倒数，用$idf(t)$表示，$$idf(t) = log [ \frac{n}{df(t)} ] + 1$$。
    >
    >   而TF-IDF就是二者的乘积：$$TF-IDF=tf(d,t)*idf(t)$$。
    >
    >   此外，sklearn的TF-IDF的计算过程中还有额外的平滑性选项，即可以在实例化评估器时选择smooth_idf为True：$$idf(t) = log [ \frac{n+1}{df(t)+1} ] + 1$$。

    <img src="https://cdn.jsdelivr.net/gh/louisyanglu/images/images/IWZx31Nnv2utKgR.png" alt="IWZx31Nnv2utKgR" style="zoom:33%;" />

#### 15.5  特征衍生API

![15.5 特征衍生API](https://cdn.jsdelivr.net/gh/louisyanglu/images/images/15.5%20%E7%89%B9%E5%BE%81%E8%A1%8D%E7%94%9FAPI.png)

<img src="https://cdn.jsdelivr.net/gh/louisyanglu/images/images/0.%E7%89%B9%E5%BE%81%E8%A1%8D%E7%94%9FAPI.png" alt="0.特征衍生API" style="zoom:33%;" />

#### 15.6  特征衍生流程总结

![15.6 特征衍生流程总结](https://cdn.jsdelivr.net/gh/louisyanglu/images/images/15.6%20%E7%89%B9%E5%BE%81%E8%A1%8D%E7%94%9F%E6%B5%81%E7%A8%8B%E6%80%BB%E7%BB%93.png)

<div style="page-break-after:always"></div> 

------

### 第16章  特征筛选

#### 16.1  特征包含信息量指标

##### 16.1.1  缺失值比例计算

根据比例删除缺失值比例较高的特征，同时将其他缺失值统一填补为fn的值。

``````python
MissingValueThreshold(X_train_temp, X_test_temp, threshold=0.95, fn=-99999)
``````

##### 16.1.2  单变量方差

>   样本方差：$$Var[X] = \frac{\sum^{n}_{i=1}(x_i-\bar x)^2}{n}$$    $\Rightarrow$  `df.var(ddof=0)`
>
>   总体方差：$$Var[X] = \frac{\sum^{n}_{i=1}(x_i-\bar x)^2}{n-1}$$  $\Rightarrow$  `df.var()`

根据样本方差删除方差较低的特征。`VarianceThreshold`只能计算样本方差，不能修改为计算总体方差。

1.   **连续变量**

     ```python
     VarThreshold(X_train_temp, X_test_temp, threshold=0)
     ```

     -   我们可以通过`df.var(ddof=0)`查看每一列的方差，在对连续特征方差分布有一定的了解后，设置阈值并剔除方差较小的列。在对连续特征方差分布有一定的了解后,设置阈值并剔除方差较小的列。

         方差大小也会受到特征取值大小影响，即某特征本身取值越大，方差计算结果也越大。例如某列取值放大10倍，则方差会放大100倍。**除非我们很明确各连续特征的量纲一致，否则设置阈值筛选特征的意义不大**。

         因此，大多数时候我们只会考虑利用`VarianceThreshold`剔除那些方差为0的连续变量。

     -   标准化并不能达到消除量纲影响、同时又保留方差能够衡量特征信息量的功能。

         -   z-score标准化会将特征转化为均值为0、标准差为1的特征，此时除了原本方差为0的特征，其他所有特征的方差都会转化为1；
         -   0-1标准化有可能打乱原始方差的大小顺序。

         **切忌先对连续变量进行标准化再进行方差筛选**。

2.   **二分类离散变量**

     对于二分类离散变量来说，我们会假设其满足伯努利分布，然后通过每一类样本的占比与方差之间的映射关系，$$\mathrm{Var}[X] = p(1 - p)$$。

     通过衡量少数类占比是否少于某一比例(或者多数类样本是否多于某一比例)来判断是否需要剔除某列。如我们想剔除少数类样本占比少于5%的特征，则可以进行如下计算: 0.05 * 0.95=0.0475。

#### 16.2  基于假设检验的参数方法来评估特征与标签关联度

>   统计分析方法的根本思路，是借助样本和总体这一理论体系，通过样本的特性判断总体的特性，进而“先验”的判断其他来自同一总体的数据的情况。而要做到这点，最重要的环节就是假设检验与统计推断，其中推断是目的、假设检验是手段。
>
>   -   假设检验的目的：证明结论；
>
>   -   假设检验的准备工作：组织实验与采集数据；
>
>   -   假设检验的第一步：提出假设；
>
>       假设检验的过程往往是采用了类似“**反证法**”的方法进行论证，例如如果我想证明这枚硬币是质地均匀的，那么在论证之前，我需要提出一个相反的假设，即这枚硬币有问题、质地不均匀，该假设会被记为$H_0$，也就是所谓的零假设。当然既然是假设，就肯定有假设不成立的时候，此时假设结论的对立假设就是这枚硬币没有问题、是质地均匀的，该假设会被记为$H_1$，也被称为备择假设或者对立假设。
>
>   -   假设检验涉及的核心概念：概率与分布；
>
>   -   假设检验的核心观点：小概率事件在单独一次实验中不可能出现；
>
>       一般来说我们会将概率小于0.05或0.01（显著性水平）的事件化为小概率事件。
>
>   -   假设检验与统计推断。
>
>       推翻或者接受假设其实都是完成了推断，本质上都是一个通过既有数据对未来进行了推断。

<img src="https://cdn.jsdelivr.net/gh/louisyanglu/images/images/kC5vZdeLun2OY3g.png" alt="假设检验流程" style="zoom:40%;" />

##### 16.2.1  卡方检验与F检验

<img src="https://cdn.jsdelivr.net/gh/louisyanglu/images/images/16.2.1%20%E5%8D%A1%E6%96%B9%E6%A3%80%E9%AA%8C.png" alt="16.2.1 卡方检验" style="zoom:100%;" />

![16.2.2 F检验](https://cdn.jsdelivr.net/gh/louisyanglu/images/images/16.2.2%20F%E6%A3%80%E9%AA%8C.png)

##### 16.2.2  离散变量与离散标签的卡方检验

>   卡方检验是针对于**离散变量**的独立性检验，卡方检验的零假设为两个离散变量相互独立。

1.   提出假设

     -   $$H_0:Contract字段和标签Churn相互独立$$

     -   $$H_1:Contract字段和标签Churn不相互独立$$

2.   采集数据

     对原始数据集进行关联汇总，统计分组频数

     ```python
     df_count = pd.crosstab(y_train, X_train['Contract'], margins=True)
     ```

3.   设计随机变量

     >   设计统计量的最终目的是为了能够量化的判断当前数据所表现出的情况是否能够支持或者拒绝原假设。
     >
     >   如果假设成立，即两个变量真的相互独立，那么在总体数据量不变的情况下，两个变量的列联表是可以有一个期望观测值的，通过对比理论上的期望观测值和真实值，我们就能够判断假设是否成立。

     $$\mathcal{X}^2 = \sum_{i=1}^{m}\sum_{j=1}^{n}\frac{(O_{i,j}-E_{i,j})^2}{E_{i,j}}$$。其中i、j代表列联表的行和列，$O_{i,j}$表示i行j列的观测值（observe）、$E_{i,j}$表示期望值。而此处的$\mathcal{X}^2$就是**卡方值**，也就是卡方检验中的统计量。**$\mathcal{X}^2$越大，说明实际结果和期望结果差异越大**。

     卡方值会受到单元格数量的影响，因此我们需要用某种方式表示单元格对其的影响，对于卡方检验来说，就是所谓的**自由度**（degree of freedom）。对于二维列联表来说，**自由度**就是$(m-1)*(n-1)$，行数-1和列数-1的乘积。

     比如在抛硬币的例子中，抛了10次硬币，如果“硬币质地均匀”的原假设成立，则最有可能发生的情况就是5次正面5次反面，而由于实验数据距离期望假设较远，我们最终在二项分布统计量提供的概率结果协助下，拒绝了原假设。

     根据分组频数，计算每一个变量取值的期望概率：$$P(Contract=0) = \frac{Contract=0}{total}$$。

     依据零假设，𝐶𝑜𝑛𝑡𝑟𝑎𝑐𝑡和𝐶ℎ𝑢𝑟𝑛相互独立，因此对于任意一名用户，同时𝐶𝑜𝑛𝑡𝑟𝑎𝑐𝑡=0且𝐶ℎ𝑢𝑟𝑛=0的概率为：$$P(Contract=0, Churn=0) = P(Contract=0) * P(Churn=0)$$

     因此在零假设的情况下，𝐶𝑜𝑛𝑡𝑟𝑎𝑐𝑡=0且𝐶ℎ𝑢𝑟𝑛=0的用户总数期望为：$$E_{0, 0} = P(Contract=0, Churn=0) * total$$

     很明显，当实际人数和期望人数的差异越大，我们就越有理由怀疑零假设，即变量之间可能相关

4.   计算事件发生概率与统计推断

     通过观察卡方分布表我们也发现，自由度越大，卡方检验对频数分布的期望与实际层面的差异的容忍度越高。

     **自由度越大，同一置信度水平下要求的差异越大，才能说明两者不独立**。

**利用scipy做卡方检验**

**卡方值越大、p值越小  $\Rightarrow$  不相关的假设越不成立、变量越相关**

```python
from scipy import stats

# chi2_contingency函数返回了四个结果，分别是卡方值、概率值、自由度以及期望频数表
df_count = pd.crosstab(y_train, X_train['Contract'], margins=True)
stats.chi2_contingency(observed=df_count)
'''这里的p值既是事件发生的概率，同时也是我们后续在进行特征筛选时的一个评分，类似相关系数，p值越小说明越不独立，也就是说明这两个变量关联性越强'''
```

##### 16.2.3  连续变量与离散标签的卡方检验

sklearn中只**要求y标签是离散**的，变量可以是连续的。

对于连续变量来说，无法通过列联表的方式进行频数的汇总统计：

1.   首先我们需要求得连续特征总和total；

2.   然后计算标签的不同取值占比t0、t1；

3.   用总值total分别乘以t0和t1，算得在0类用户和1类用户中的期望总值$E0 = tol * t0, E1 = tol * t1$；

4.   计算0类用户和1类用户在连续变量上的实际总值；

5.   通过计算出的真实值和期望值的分布，构建卡方统计量来衡量二者的差异，$$\mathcal{X}^2 = \sum_{i=1}^{m}\sum_{j=1}^{n}\frac{(O_{i,j}-E_{i,j})^2}{E_{i,j}}$$；

6.   在连续变量和离散变量的卡方检验中，自由度是离散变量类别数-1；

7.   计算p值。

     ```python
     scipy.special.chdtrc(自由度, 卡方值)
     ```

需要注意的是，连续变量的取值毕竟不是频数结果，最终的卡方值会严重**受到**连续变量的**量纲影响**。因此，在实际进行连续变量的卡方检验过程中，建议先对原始变量进行**标准化处理**，该过程会将所有连续变量取值放缩至类似水平，同样也会将p值和卡方值放缩至同样水平，然后我们在**单独针对连续变量进行BestK筛选**，而**不建议同时比较连续变量和离散变量**的K值然后在一个流程中进行筛选（因为连续变量的p值和卡方值没有绝对大小的意义）。

##### 16.2.4  sklearn中的卡方检验

```python
'''sklearn其实是采用类似连续变量的卡方检验流程来进行的离散变量卡方检验，并且计算过程中的自由度也不再是列联表行数-1和列数-1相乘的结果，而是标签取值水平-1，并不是标准意义上的卡方检验
在最终的SelectKBest筛选过程，实际上是按照卡方值的大小（卡方值不会存在负数情况），筛选卡方值最大的k个特征(不是按照p值进行筛选)'''
from sklearn.feature_selection import chi2

KB_chi2 = SelectKBest(chi2, k=10)
KB_chi2.fit(X_train, y_train)
KB_chi2.scores_
KB_chi2.pvalues_
```

##### 16.2.5  连续变量与离散标签的ANOVA方差分析

1.   提出假设

     选取“月消费额”和标签“是否流失”作为分析对象

     -   $$H_0:流失用户群体和非流失用户群体的月消费金额没有差异$$

     -   $$H_1:流失用户群体和非流失用户群体的月消费金额存在显著差异$$

     如果月消费金额这一字段对标签取值的预测能够起到帮助作用，一定是因为**这个字段对标签具备一定的区分度**，如果流失用户和非流失用户，这两批用户在月消费金额的角度完全看不出差异，那么月消费金额这一字段也不太可能对后续建模提供任何有效信息。

     统计学里判别两个样本是否存在差异，其实是在**判别这两个样本是否取自不同的总体**，也就是说这两个样本的差异（如果有的话），是否是统计误差导致、还是因为抽样自不同的总体。如果能判断样本取自不同的总体，则能判断两类样本存在明显差异，反之则不行。

2.   采集数据

     分为流失用户和非流失用户

3.   设计统计量F

     构造统计量来判断两类样本均值差异程度

     n条数据被分成k组（即标签有k个类别），其中第j个类别中包含$n_j$条样本，并且$x_{i,j}$表示第j个类别的第i条样本，则有：

     -   **样本整体偏差SST**计算公式如下：$$SST = \sum^k_{j=1}\sum^{n_j}_{i=1}(x_{ij}-\bar x)^2$$，此处$\bar x = \frac{\sum^k_{j=1}\sum^{n_j}_{i=1}x_{ij}}{n}$

     -   **每个组内的样本与均值的差值的平方和**：$$SSE_j = \sum^{n_j}_{i=1}(x_{ij}-\bar {x_j})^2$$，其中$\bar {x_j} = \frac{\sum_{i=1}^{n_j}x_{ij}}{n_j}$，为第j组数据的组内均值

     -   **k个分组的组内偏差总和**为：$$SSE = \sum_{j=1}^k SSE_j = \sum_{j=1}^k\sum^{n_j}_{i=1}(x_{ij}-\bar {x_j})^2$$

     -   **组间偏差平方和**：$$SSB=SST-SSE=\sum_{j=1}^k n_j (\bar{x_j}-\bar x)^2$$，即**每个组的均值和总体均值的差值的平方加权求和**的结果，其中**权重就是每个组的样本数量**

     在总体偏差不变的情况下(给定一组数据，就会有一个固定的SST)，如果**SSB很大、SSE很小**，则说明不同组的组间差异越大、组内差异较小，此时我们会更倾向于判断不同组**是取自不同总体**；而反之，如果SSB很小而SSE很大，则倾向于判断不同组是取自同一个总体。

     在实际计算过程中，**SST、SSE和SSB都可以看成是方差计算**，其中**SST衡量的数据整体方差**、**SSE衡量的组内方差**，而**SSB则衡量的是每一组的均值分布的方差，即每一组均值和整体均值的离散程度**。

     构造统计检验量F：$$F=\frac{MSB}{MSE}=\frac{SSB/df_B}{SSE/df_E}=\frac{SSB/(k-1)}{SSE/(n-k)}$$

     -   $df_B$就是统计量SSB的自由度，用于**修正分组数量对SSB的影响**；

     -   $df_E$就是SSE的自由度，用于**修正样本数量对SSE计算结果的影响**；

     而F作为统计检验量，也是有对应概率分布的，即满足F(k-1, n-k)的概率分布，**F值越大**则SSB相比SSE越大，也就是组间差异越大、不同组的数据更倾向于抽样自不同总体、**零假设成立的可能性（p值）越低**。

4.   事件发生概率计算与统计推断

     ```python
     scipy.special.fdtrc(k-1, n-k, F_score)  # 需要求自由度、F-score
     
     scipy.stats.f_oneway(cat_0, cat_1)  # 直接代入不同组的样本（y==0、y==1）
     ```

##### 16.2.6  ANOVA与卡方检验的关系

>   ANOVA中的统计检验量F是借助卡方分布构建的。

从理论上来说，F计算量的分子和分母都是服从卡方分布的，$F=\frac{SSB/(k-1)}{SSE/(n-k)}$中，分子是服从自由度为k-1的卡方分布，而分母是服从自由度为n-k的卡方分布，且能够证明二者相互独立。

只要是相互独立的、服从卡方分布的随机变量，相除构成的随机变量都是服从F分布的：F统计量的标准表达公式如下：$$F=\frac{X_1/d_1}{X_2/d_2}$$。其中$X_1$和$X_2$相互独立且服从自由度为$d_1$、$d_2$的卡方分布，此时随机变量F服从自由度为($d_1,d_2$)的F分布。

```python
from sklearn.feature_selection import f_classif
```

方差分析并不适用于两个离散变量之间的检验。针对分类问题，f_classif与chi2两个评分函数搭配使用，就能够完成一次完整的特征筛选，其中chi2用于筛选离散特征、f_classif用于筛选连续特征。

##### 16.2.7  连续变量与连续标签的f_regression检验方法

f_classif和chi2检验能够很好的解决分类问题的特征筛选。而如果是回归问题，f_regression和方差分析类似。

1.   提出假设
     -   $$H_0:两个连续变量间不存在线性相关关系$$
     -   $$H_0:两个连续变量间存在线性相关关系$$

f_regression构建了一个如下形式的F统计量：$$F = \frac{r^2_{xy}}{1-r^2_{xy}} * (n-2)$$，其中$r_{xy}$为两个连续变量的相关系数，并且满足自由度为(1,n-2)的F分布。

统计量F和$r_{xy}^2$变化方向一致，即与相关系数绝对值的变化保持一致，本质上和相关系数一样，也是衡量了两个变量之间的相关性，并且是一种线性相关关系，并且数值越大、线性相关关系越强，反之则越弱。

为什么$\frac{r^2_{xy}}{1-r^2_{xy}} * (n-2)$会服从F分布呢？

相关系数

-   计算公式是用xy的协方差除以x的标准差和y的标准差之积：$$r_{xy} = \frac{\sum^n_{i=1} (x_i-\bar x)(y_i-\bar y)}{\sqrt{\sum_{i=1}^n(x_i-\bar x)^2}\sqrt{\sum_{i=1}^n(y_i-\bar y)^2}}$$

-   另一种解释方法是相互解释的变异占变异的比例。

    定义总变差(Total variation)为SST：$$SST = \sum_{i=1}^n(x_i-\bar x)^2\sum_{i=1}^n(y_i-\bar y)^2$$

    已经解释的变差(Explained variation)为SSR：$$SSR=(\sum_{i=1}^n ( x_i-\bar x)(y_i-\bar y))^2$$

    则有：$$r_{xy}^2=\frac{SSR}{SST}$$

    未解释的变差部分我们也可以用SSE来进行表示，即SSE=SST-SSR。

$$\frac{r^2_{xy}}{1-r^2_{xy}}=\frac{SSR/SST}{1-SSR/SST}=\frac{SSR}{SSE}$$，就是已解释的变差和未解释的变差比例

统计量：$$F = \frac{r^2_{xy}}{1-r^2_{xy}} * (n-2)=\frac{SSR/1}{SSE/(n-2)}$$，(n-2)实际上就是自由度，是对统计量的修正

$\frac{r^2_{xy}}{1-r^2_{xy}} * (n-2)\sim F(1, n-2)$

尽管f_regression巧妙的构建了一个F统计量，并借此成功的借助假设检验来判断变量之间是否存在线性相关关系，但f_regression仍然存在较大局限：

-   首当其冲当然是f_regression**只能挖掘线性相关关系**，也就是两个变量的同步变化关系，但除了线性关联关系外，变量之间存在其他类别的“关联关系”也是有助于模型建模，而其他类型的关系，无法被f_regression识别；
-   其二就是由于离散变量（尤其是名义型变量）的数值大小是没有意义的，因此判断离散变量和其他变量的“线性关系”意义不大，因此f_regression**只能作用于两个连续变量之间**。

综上所述，f_regression唯一适用的场景就是用于线性回归的连续变量特征筛选的过程中。

#### 16.3  基于互信息的非参数方法来评估特征与标签关联度

##### 16.3.1  离散变量的互信息法

>   互信息法就是借助互信息这一评估指标来进行特征筛选。

1.   **信息熵**

     信息熵，以离散变量为例，指的是某个数组（更多时候指的是标签）取值的混乱程度，数组取值越不纯、信息熵数值越大。

     $$H(X) = -\sum^n_{i=1}p(x_i)log(p(x_i))$$，其中$p(x_i)$表示多分类问题中第$i$个类别出现的概率，$n$表示类别总数，通常来说信息熵的计算都取底数为2，并且规定$log0=0$。

     ```python
     scipy.stats.entropy([1/4, 3/4], base=2)

2.   **信息增益**

     信息增益，则表示如果以某一列数组对另一列数组进行划分，划分前数组信息熵和划分后子数据集信息熵的差值

     $$\begin{aligned}I(D\,;A) & = H(D) - H(D|A) = H(D) - \sum\limits_{v=1}^\mathcal{V}\frac{|D^v|}{|D|} H(D^v)  \end{aligned}$$

     对于信息增益来说，还有另外一种理解角度，即某个变量对另一个变量的解释程度，或者说某个变量所包含另一个变量的信息，而从本质上来说，**信息增益其实就是互信息**，而互信息中的“互”，其实也就是两个变量相互包含对方信息的意思：

     <img src="https://cdn.jsdelivr.net/gh/louisyanglu/images/images/AykP87JQ9r1qVij.png" alt="image-20220407155034722" style="zoom: 15%;" />

     其中，$H(X)、H(Y)$表示X和Y的信息熵，$H(X|Y)$则表示在Y确定时X不确定的部分，$H(Y|X)$表示在X确定时Y不确定的部分，这些也被称为条件熵。而$I(X;Y)$则表示两个变量能相互解释的部分，即互信息。

     在互信息法的特征筛选过程中，我们将互信息视作每个特征的评分，然后挑选那些评分较高的特征带入模型进行训练。

     **互信息具有对称性**：既然是两个变量相互包含对方的信息被称作“互信息”，那么很明显，用A来解释D还是用D来解释A，其实都不存在任何差异。

     ```python
     from sklearn.metrics import mutual_info_score
     ```

     互信息的取值范围其实是在**0到参与计算的两个特征的熵值最大值**之间。

3.   **变量分布**

     除了能够从信息熵和信息增益的角度理解互信息外，还可以从变量分布的角度进行理解。其实不难发现，对于两个离散变量来说，如果取值分布较为一致，则互信息肯定也比较大。

     KL散度：$$D_{KL}(P||Q)=\sum ^n_{i=1}P(x_i)log(\frac{P(x_i)}{Q(x_i)})$$，判断从Q分布出发，还需要额外多少信息才能表达P分布。

     此处如果我们将P分布改为A和D的联合分布p(x,y)，而Q分布改为各自原始分布（边缘分布）之积，则此时KL散度公式如下：$$ D_{KL}(p(x,y) || p(x)p(y))  = \sum\limits_{y \in \mathcal{Y}}\sum\limits_{x \in \mathcal{X}} p(x,y) \,\text{log}\left(\frac{p(x,y)}{p(x)p(y)}\right) $$，此时$D_{KL}(p(x,y) || p(x)p(y))$表示用边缘分布之积表示联合分布的差距，等价于信息增益。$$ D_{KL}(p(x,y) || p(x)p(y))  = \sum\limits_{y \in \mathcal{Y}}\sum\limits_{x \in \mathcal{X}} p(x,y) \,\text{log}\left(\frac{p(x,y)}{p(x)p(y)}\right)=H(Y)-H(Y|X)=H(X)-H(X|Y)$$

     $$\begin{align*}I(X;Y) = I(Y;X)&= \sum\limits_{y \in \mathcal{Y}}\sum\limits_{x \in \mathcal{X}} p(x,y) \,\text{log}\left(\frac{p(x,y)}{p(x)p(y)}\right) \\& = -\sum\limits_y\sum\limits_x p(x,y)\,\text{log}\,p(y) + \sum\limits_x\sum\limits_y p(x,y)\text{log} \left(\frac{p(x,y)}{p(x)}\right) \\& = -\sum\limits_y p(y)\,\text{log}\,p(y) + \sum\limits_x\sum\limits_y p(x)p(y|x)\text{log}\, p(y|x) \\& = -\sum\limits_y p(y)\,\text{log}\,p(y) + \sum\limits_x p(x) \sum\limits_y p(y|x)\text{log}\, p(y|x)  \\& = H(Y) - \sum\limits_x p(x)H(Y|X=x) \\& = H(Y) - H(Y|X)\end{align*}$$

4.   **卡分检验与互信息的对比**

     -   卡方检验能够给出明确的p值用于评估是否是小概率事件，而互信息法只能给出信息增益的计算结果，很多时候由于信息增益的计算结果是在0到最小信息熵之间取值，因此信息增益的数值在判断特征是否有效时并**不如p值那么直观**；
     -   卡方检验的p值源于假设检验统计量服从卡方分布，这种有假设分布的方法也被称为参数方法，而互信息法并不涉及任何假定的参数分布，因此是一种非参数方法。不难发现，参数方法是借助样本估计总体，然后根据总体进行推断的过程，而非参数方法则无需总体信息即可计算。非参数方法会更加简单，但**无法对小样本进行合理的预估**；

     -   参数方法会考虑到样本数量这一影响因素，如果样本数量较少，则参数方法会更加趋于保守、更加趋于保留原假设，即二者独立。但非参数方法则是“所见即所得”，结论并不受样本数量影响（KL散度公式中的p是代表概率，但实际上只是由当前的样本计算得出的比例）；

     -   如果分类变量**样本偏态非常严重，也会影响互信息的结果**，但不会影响卡方检验结果。

##### 16.3.2  连续变量的互信息法

>   互信息法不仅可以分析挖掘离散变量之间的关联性，还可以挖掘离散变量与连续变量、以及连续变量彼此之间的关联性。由于参与计算的一方变成了连续变量，无论是信息增益还是KL散度的计算公式都将发生变化：$$I(X;Y) = \int_{\mathcal{Y}}\int_{\mathcal{X}} p(x,y) \,\text{log}\left(\frac{p(x,y)}{p(x)p(y)}\right) dxdy  $$，不过积分运算在机器学习领域并不好实现，因此sklearn中将这个过程等价于一个**K近邻过程**，即通过K近邻过程来**计算带入连续变量的互信息**。

**最近邻计算**

互信息中用到的是无监督的最近邻算法，该算法较为简单，就是单纯的进行最近邻元素的搜索与半径的计算。

```python
# 通过设置最近邻的个数来查找最近邻
from sklearn.neighbors import NearestNeighbors
nn = NearestNeighbors(n_neighbors=2)
nn.fit(a.reshape(-1, 1))
nn.kneighbors()  # 返回的第一个结果是距离两个最近邻之间的距离，第二个结果则是两个最近邻的索引

# 通过设置一个距离范围半径，来查找半径范围内的所有可能的近邻
from sklearn.neighbors import KDTree
kd = KDTree(a.reshape(-1, 1))
kd.query_radius(X=a.reshape(-1, 1), r=1)  # 返回的结果就是每个元素在给定半径r=1时，搜索到的距离小于等于1的元素的索引，KDTree在根据距离查找最近邻时，会将自己也算作近邻之一
```

1.   **连续变量和离散变量**

     >   基本思路仍然是根据离散变量的不同取值对连续变量进行分组，然后通过衡量组内差异和组间差异来判断如此分组是否有效。
     >
     >   该思路和方差分析的思路完全一致，只不过方差分析通过构建了一个F统计量来量化的衡量组间差异的程度，并且是一种参数方法，而互信息则是借助K近邻来衡量组内差异和组间差异。

     在给定半径范围内，组内最近邻和跨组最近邻个数之间的差别，其实就是衡量组内差异与组间差异的指标。这里给定的半径，是根据给定组内最近邻的个数通过KDTree算出来的。每一个组划定的半径范围是根据组内数据分布情况（即最近邻情况）决定的，而非人工设置。

     我们不妨设想，如果对于某一种分组情况来说，在组内3个最近邻决定的半径r内，如果包含了多个跨组最近邻，则说明相比组内差异、**组间差异较小，此时离散变量对连续变量的区分效力较弱**，此时连续变量和离散变量的关联性也较弱，此时的直观理解就是不同分组的数据彼此交叉；反之，如果在组内3个最近邻决定的半径r内，只包含少量跨组最近邻，则说明相比组内差异、组间差异较大，此时的直观理解就是不同分组的数据各自处于不同区间，此时离散变量对连续变量的区分效力较强，此时连续变量和离散变量的关联性也较强。

     我们知道跨组最近邻个数越少、两个变量的关联性就越强，并且已经能够算出整体最近邻个数，但我们仍然需要采用某种计算流程量化的衡量这种根据跨组最近邻个数算得的关联性，可以借助**伽马函数的对数导函数——`digamma`函数**来进行计算。`digamma`函数**在正实数域上是单调递增的，并且增速随着X增加而逐步放缓**。

     <img src="https://cdn.jsdelivr.net/gh/louisyanglu/images/images/image-20230226133940467.png" alt="image-20230226133940467" style="zoom:36%;" />

     最终的互信息MI值：$$MI(X,Y)=Ψ(k)−<Ψ(n_x+1)+Ψ(n _y+1)>+Ψ(N)$$

     $mi=digamma(n\_samples)+np.mean(digamma(k\_all)) -\\ np.mean(digamma(label\_counts))-np.mean(digamma(m\_all + 1))$

     其中n_samples是样本总数、k_all是每一组的k近邻个数、label_counts是每一组的元素个数、m_all + 1是整体最近邻个数。随着这些值的增加digamma也会增加，并且会呈现出一种增速逐渐放缓的增加趋势。

     -   伴随着样本数量增加和最近邻K的增加，互信息也将增加，而伴随着每一组的元素个数增加和整体最近邻（组内最近邻+跨组最近邻）个数增加，互信息将减少；
     -   在样本总数固定的情况下，离散变量的分类水平越多、每个组的组内样本数量就越少，np.mean(digamma(label_counts))就越小、而MI就会越大，因此互信息法在离散变量与连续变量的筛选过程中，会更加倾向于将分类水平更多的离散变量筛选出来；
     -   最近邻K的个数选取也会影响最终的MI计算结果。随着K的增加，方差将会减少而偏差将增加。这里的方差，指的是相同分组内的元素的整体最近邻个数将趋于一致，而偏差指的是MI指标的判别效力将逐渐下降。因此K建议就设置为默认值3，以确保在方差和偏差中保持平衡。**k越大方差越小偏差越大、k越小方差越大偏差越小**；
     -   整体最近邻个数m_all对MI的影响，需要结合np.mean(digamma(k_all))一起来进行观察。组内最近邻个数k_all是确定的，而m_all表示整体最近邻个数。跨组最近邻元素个数越多、组间差异越小、np.mean(digamma(k_all))-np.mean(digamma(m_all + 1))越小、MI值越小；
     -   MI的计算结果会明显受到离散变量取值个数的影响，取值个数越多、MI计算结果也越大，该趋势会在样本数量增加后被削弱，因此**小样本仍然建议采用方差分析**这一参数方法以保证效果。

     ```python
     from scipy.special import digamma
     tensorflow.math.digamma(x=arr)
     ```

2.   **连续变量与连续变量**

     仍然是采用了最近邻的计算过程，并且采用了一种名为切比雪夫距离（Chebyshev distance）的计算流程：$$Chebyshe\_distance(P,Q) = \max{(|x_1-x_2|,|y_1-y_2|)}$$

     -   Step 1.根据给定的最近邻个数𝑛_𝑛𝑒𝑖𝑔ℎ𝑏𝑜𝑟𝑠（往往也是3）计算每个样本的切比雪夫半径距离r；

     -   Step 2.根据半径r，进一步计算每个样本x和y单维度上的最近邻个数，$n_x、n_y$ ;

     -   Step 3.根据$n_x和n_y$，参照如下公式计算互信息MI：$$MI=(digamma(n\_samples)+digamma(n\_neighbors)-mean(digamma(n_x))-mean(digamma(n_y)))$$

         伴随$n_x、n_y$的增加，MI也将逐渐减少，MI越小则两个变量的关联性越不明显。


3.   **优势**

     -   互信息法确实能够判别各种类型的关联关系，如非线性关系，就这点而言，相比相关性的F检验，互信息法拥有较大优势。

     -   所有的非参数方法都将极大程度受到样本数量影响，而能够挖掘任意关联关系的连续变量间的互信息计算过程也是如此，并且也是因为能够挖掘任意关联关系，连续变量之间的MI计算结果尤其受到样本数量影响严重。如果是需要挖掘线性关系，则样本量大小影响不大，而如果要挖掘非线性关系，需要更大量的样本才能获得更加准确的结果。

4. **使用**

    底层计算函数：

    -   mutual_info_classif+离散变量：`mutual_info_score`

    -   mutual_info_classif+连续变量：`_compute_mi_cd`

    -   mutual_info_regression+离散变量：`_compute_mi_cd`

    -   mutual_info_regression+连续变量：`_compute_mi_cc`

    ```python
    from sklearn.feature_selection import mutual_info_regression,mutual_info_classif
    
    # discrete_features: 人工输入离散变量的列
    # random_state: mutual_info_regression和mutual_info_classif函数中会随机小幅修改离散变量的值，以确保不存在重复的连续变量值并且和离散变量的MI值保持在同一水平，因此如果是进行带有连续变量的MI计算，结果会有一定的随机性
    mask = [True]*len(category_cols) + [False]*len(numeric_cols)
    MIC = mutual_info_classif(X_train_OE, y_train, discrete_features=mask, random_state=21)
    MIC = pd.Series(MIC, index=category_cols + numeric_cols)
    ```

    SelectKBest特征筛选评估器在调用score_func时只能使用默认参数，即把密集矩阵视作连续变量、稀疏矩阵视作离散变量，并且一个X特征矩阵只能有一种类别判定。因此若要调用特征筛选评估器借助MI进行特征筛选，则**只能分连续变量和离散变量分别进行筛选**。如果要对离散变量进行特征筛选，则需要**先将离散变量转化为稀疏矩阵**。

    如果是针对**分类问题对离散变量进行特征筛选**，则还可以选择`normalized_mutual_info_score`和`adjusted_mutual_info_score`两个指标，两个指标都是对mutual_info_score进行的修正，二者都是借助分类变量的信息熵构建了F统计量，并借助这个F统计量对原始mutual_info_score过程进行修改，normalized_mutual_info_score能够将最终的评分放缩到0-1范围内，从而进一步方便进行数值层面上的比较，而adjusted_mutual_info_score则是修正了分类变量的类别数越大、MI值越高的问题，使得最终能够更好的比较不同分类水平下的离散变量的关联性。

    ```python
    from sklearn.metrics import normalized_mutual_info_score,adjusted_mutual_info_score
    
    NMI = pd.Series(0, index=category_cols)
    for col in category_cols:
        NMI[col] = normalized_mutual_info_score(X_train_OE[col], y_train)
        
    AMI = pd.Series(0, index=category_cols)
    for col in category_cols:
        AMI[col] = adjusted_mutual_info_score(X_train_OE[col], y_train)
    ```

#### 16.4  基于模型的特征筛选

>   相比特征评价指标（互信息、卡方值、ANOVA方差分析等），带入模型的特征筛选会更加耗费计算资源，但同时也会更加精准。
>
>   针对大规模数据集，往往是特征评价指标进行粗筛、而模型特征筛选进行更精细的特征筛选。

过多的特征会影响模型的训练速度，但实际上，冗余无用的特征也是会影响最终模型结果的，尤其是决策树以及以树模型为基础的集成学习。

从严格的算法原理层面来说，冗余无用的特征是并不会影响树模型的建模流程的，但包括sklearn在内的诸多机器学习框架，为了更快速的找到合适的树模型的生长切分点，往往会采用一种更加模糊的搜索方式，也就是说，每次树的生长并不一定是选择那个最优的切分点，而此时，冗余无用的特征就会影响最终模型预测结果。也就是说，某些时候，模型会选择冗余无用特征提供的次优切分点进行树的生长。

##### 16.4.1  线性方程coef_

线性方程中的自变量系数，也就是coef_参数。包括线性回归、Lasso、岭回归和逻辑回归在内，自变量系数的绝对值越大、则说明自变量对因变量的取值影响越大、该特征也就越重要。

##### 16.4.2  树模型feature_importances_

决策树的feature_importances是一个累计结果，决策树每生长一次就会进行一次importances的计算，即计算一次本次生长中标签不纯度下降数值，并将其累计到本次生长对应的特征的重要性中。而这里的一次生长过程中不纯度下降值，是父节点的权重\*父节点的标签不纯度，减去左右两边子节点的权重\*子节点标签不纯度，这里父节点、子节点的权重就是各数据集样本数在总样本中的占比。并且为了方便比较，决策树最终输出的feature_importances_实际上是不同特征重要性的占比，总和为1。

>   首先是模型层面，为了提供更加可信的feature_importances_结果，模型训练一定要借助交叉验证或者超参数优化器共同执行、以训练一个泛化能力更强的模型；
>
>   其次是运算效率方面，很明显，带入模型的特征筛选过程需要耗费更大的算力，往往更加适合于小范围高精度的特征筛选；其三，这个特征筛选过程其实已经有Embedding的影子在里面了，在训练模型的同时筛选出了一组有效特征，如果第一次训练的模型就是最优模型、并且特征子集就是最优子集，则上述过程就是一个完整的Embedding过程。

-   feature_importances_的随机性

    通过查看DecisionTreeClassifier的random_state参数解释不难发现，这种随机性源于CART树对切分点的选取。根据评估器的说明，哪怕是max_features=n_features（即每次训练带入全部特征、而max_features<n_features时则每次切分带入部分特征、此时随机性更强），在进行决策树生长时也经常遇到拥有相同效力的备选切分点（即基于基尼系数的信息增益相同），此时只能随机挑选其中一个备选点进行切分，而选取哪个切分点，就必然给对应的特征累计更多的重要性。这也就是为何相同的数据在多次建模时特征重要性会各不相同的原因。

-   feature_importances_受建模过程影响

    所有的特征评估其实都是为了找到一组能够更好的帮助模型提升结果和泛化能力的特征，而在过拟合情况下，查看树模型的特征重要性计算结果，其可信度并不高。

    对于sklearn的CART树来说，出现剔除部分特征后模型效果反而上升的原因，其实还是在于CART树切分点选取的随机性上，尽管CART树的原理要求遍历所有可能切分点然后寻找最优切分点，但实际代码执行过程中会小幅牺牲精度以换取执行效率，即这个对比的过程是一个粗精度的对比过程。而当特征减少后，需要对比的备选切分点数量明显减少，尽管仍然是粗精度的对比，但备选切分点的减少使得干扰项也随之减少，进而能够小幅提升效果。

##### 16.4.3  RFE特征筛选

只有模型本身有效，模型产出的feature_importances才具有可信度。RFE过程尽管会用到feature_importances进行特征筛选，但RFE过程只是对模型进行简单训练，并未进行超参数搜索等模型优化，这会使得每一轮的模型都是过拟合的，而**基于过拟合模型产出的feature_importances进行的特征筛选，结果并不可靠**。

**解决办法**：在实例化RFE评估器时带入一个**已经调参后的模型**，即可每一轮特征重要性评估时使用已经训练好的模型，而该模型是已经经过剪枝的决策树模型，不会再表现出过拟合倾向。

-   Step 1.在全量样本上训练一个经过超参数搜索优化后的模型，或者找到一组优化后的超参数；
-   Step 2.将这个训练后的模型带入RFE搜索过程，并设置RFE参数n_features_to_select=1，在step=1时，RFE过程将每次剔除当前数据集中最不重要的特征，然后根据输入模型的超参数再次进行模型训练，以此往复，遍历全部特征。
-   Step 3.根据RFE评估器的ranking_查看每个特征的重要性排名。

当特征池拥有**海量特征**时，假设有一万条特征，将训练好的集成模型带入RFE过程，按照step=500进行搜索，即每次剔除最不重要的500个特征，并最终保留500个特征（n_features_to_select=500），借此对这一万个特征进行10000/500=20个等级的划分，并根据最终实际情况确定带入后续模型训练环节的特征个数。

**RFE高效特征筛选 vs 特征评估指标 vs 单模型feature_importances_**

-   首先，带入模型的特征评估由于是和模型直接挂钩，因此最终结果肯定要比特征评估指标更加精准。对于RFE来说，其容错率会高很多，无论feature_importances计算数值如何、特征feature_importances排名如何，只要能判断当前数据集中最弱的特征即可。
-   另外，RFE的这种动态计算feature_importances的过程，能够很好的对每个特征进行评估，而决策树单模型的feature_importances只能在当前模型能接受的最大范围内对特征进行评估，特征过多则会出现大量的feature_importances=0的情况。

**更加严谨的RFE流程**

-   每一轮剔除一个特征、并且每一轮都重新训练一个模型并对其进行调优。

    >   效果会更好，但影响不大

-   交叉验证

    >   RFE中的n_features_to_select代表一直递减到设置的特征个数为止；而RFECV中的min_features_to_select则表示在最多递减到设置的数值，也有可能在不到这个数值之前就停止迭代了

    -   Step 1：根据给定的评估器，在当前数据集A1上进行训练，得到模型结果r1，并计算每个特征的重要性，即计算每个特征的coef或feature_importances；
    -   Step 2：剔除最不重要的特征，即特征重要性计算结果最小的特征，得到特征子集A2，然后再次训练模型，得到模型结果r2，并计算剩余特征的特征重要性；
    -   Step 3：如果r2优于r1，则保留A2，并在A2基础上进一步剔除最不重要的特征得到特征子集A3，并进行模型训练，得到此时模型结果r3，以及A3各特征重要性，并不断重复该过程；反之如果r1优于r2，则保留A1，停止迭代；或者在多轮迭代过程中，任意子集的建模效果弱于父集，则停止迭代。

-   每一轮重新训练模型+RFECV

    >   最高精度的特征筛选

##### 16.4.4  通用特征筛选方法

```python
from sklearn.feature_selection import SequentialFeatureSelector
```

1.   **向前/向后特征搜索（Sequential Feature Selection）**

     >   无论是向前逐步搜索还是向后逐步搜索，搜索过程都是每次前进一步，而前进的这一步，也是出于当前局部最优考虑，即加入一个能让当前模型效果提升最大、或者删除一个能让当前模型损失最小的特征，这种每次都采用局部最优策略的算法也被称为贪心算法。不过需要注意的是，局部最优不一定能导向全域最优，也就是说，向前逐步搜索或者向后逐步搜索出来的特征子集，只是有较大概率也是最优子集、或者和最优子集差距不大，但不一定就是最优子集。不过呢，这个搜索过程，相比枚举法，效率更高，其实也是一种牺牲精度换取效率的做法，也会在很多场合被使用。

     假设数据集有A、B、C三个特征，现在要求搜索出包含两个特征的最优组合，即要求只带入两个特征的情况下，带入哪两个特征能够训练出一个最优的模型。

     -   **枚举法**：计算量较大

         考虑A、B、C的三种不同两两组合形式，分别是{A、B}、{A、C}、{B、C}，分别带入这三组特征进行模型训练，并根据最终模型结果找出最优组合。
     
     -   **向前搜索**
     
         先在三个特征中找到最有效的那一个特征，即单独带入A、B或者C，查看建模效果，假设单独特征情况下A特征效果最好，此时再在B、C中进行搜索，分别和A进行组合，查看哪个组合效果更好，然后挑选更好的组合作为两个特征时最佳特征组合。每次搜索加入一个新的特征，此为向前搜索。
     
     -   **向后搜索**
     
         先带入三个全部特征进行建模，然后依次剔除A、B或者C，查看剔除某特征后模型效果变化情况，选择能够使得模型效果提升最大或者损失最小的策略进行特征剔除，最终得到一个包含两个元素的特征子集。     


2.   **SelectFromModel特征筛选**

     >   根据输入的评估器计算特征重要性，然后根据给定的阈值进行特征筛选。

     这种方法其实是一种“启发式”的方法，也就是在阈值设置时，有的时候“没有理由”或者是“长期经验”得到的结果，往往也会有不错的效果，例如上述我们以特征重要性的均值、中位数、或者0.1\*均值等为阈值，来进行特征筛选。诚然，启发式方法并不适用于小样本内高精度的特征筛选，但是却是超大规模样本数据集确定特征筛选数量的方法之一，或者说是确定筛选特征数量的依据之一。

##### 16.4.5  实战

```python
# 1.缺失值过滤、方差过滤
MissingValueThreshold(X_train_temp, X_test_temp, threshold=0.95, fn=-99999)
VarThreshold(X_train_temp, X_test_temp, threshold=0)

# 2.时序特征衍生
timeSeries_Creation(timeSeries_train, timeSeries_test, timeStamp=None, precision_high=False)

# 3.交叉组合特征：【全部离散变量】、【连续变量分箱】、【时序变量】
Cross_Combination(colNames, X_train, X_test, multi=False, OneHot=True)
# 3.1 组合特征方差过滤：少数类样本比例低于1:99的特征，即以0.01 * 0.99 = 0.0099为阈值，进行方差过滤
sklearn.feature_selection.VarianceThreshold(threshold=0.0099)
# 3.2 组合特征卡方检验：
feature_selection_chi(X, y, threshold=0.01)
# （可选）3.3 组合特征互信息：设置所有互信息值的0.1 * mean为阈值,与卡方检验筛选的特征取交集/并集
feature_selection_mic(X, y, discrete_features=True, threshold_coef=0.1)

# 4.多项式衍生特征：【连续变量】
Polynomial_Features(numeric_cols, degree=3, X_train, X_test, multi=False)
# 4.1 多项式衍生特征方差过滤：以0为阈值
VarThreshold(X_train_temp, X_test_temp, threshold=0)
# 4.2 ANOVA方差分析
feature_selection_f(X, y, threshold=0.01)
# （可选）4.3 互信息
feature_selection_mic(X, y, discrete_features="auto", threshold_coef=0.1)

# 5.分组统计特征：【全部离散变量】、【连续变量分箱】、【时序变量】、【连续变量】
# 5.1 挑选KeyCol：【全部离散变量】、【连续变量分箱】、【时序变量】卡方检验、互信息取交集
chi2_select_cols = feature_selection_chi(X, y, threshold=0.01)  # 卡方检验
MI_select_cols = feature_selection_mic(X, y, discrete_features=True, threshold_coef=0.1)  # 互信息法
keycol = list(set(chi2_select_cols) & set(MI_select_cols))
cat_rest = []  # 创建一个未被选中离散变量的list
for col in cat_all:
    if col not in keycol:
        cat_rest.append(col)
# 5.2 分组统计特征衍生
col_temp = keycol.copy()  # 创建容器
GroupStat_train = pd.DataFrame()
GroupStat_test = pd.DataFrame()
for i in range(len(col_temp)):
    keyCol = col_temp.pop(i)
    features_train1, features_test1, colNames_train, colNames_test = Group_Statistics(
        keyCol, X_train, X_test, 
        col_num=numeric_cols,  # 连续型变量
        col_cat=col_temp + cat_rest,  # 除分组变量外的其他离散变量
        extension=True)
    GroupStat_train = pd.concat([GroupStat_train, features_train1],axis=1)
    GroupStat_test = pd.concat([GroupStat_test, features_test1],axis=1)
    col_temp = keycol.copy()
# 5.3 分组统计特征筛选
"""分组统计衍生特征从原理层面来看应该属于离散变量，这些特征取值大小本身不仅具有标记作用，而且具有数值绝对大小意义（都是统计量的计算结果）。但同时，这些特征的数值分布和KeyCol一致，也就是尽管是连续变量，但取值个数有限。"""
# 5.3.1 0方差过滤
VarThreshold(X_train_temp, X_test_temp, threshold=0)
"""分组统计的特征本质上其实是连续变量，因此可以考虑方差分析与互信息法特征筛选，进行标签关联度指标特征筛选。"""
# 5.3.2 ANOVA分析
feature_selection_f(X, y, threshold=0.01)
# 5.3.3 互信息
feature_selection_mic(X, y, discrete_features="auto", threshold_coef=0.1)

# 6.目标编码
col_cat = [target]  # 标签，参与计算的y标签
TarEnc_train = pd.DataFrame()  # 创建容器
TarEnc_test = pd.DataFrame()
for keyCol in cat_all:  # 较强的KeyCol不一定能衍生出较强的特征，因此需要带入全部离散特征进行计算
    features_train1, features_test1, colNames_train_new, colNames_test_new = Target_Encode(
        keyCol, X_train, y_train, X_test, 
        col_cat=col_cat,  # y标签 
        extension=True)
    TarEnc_train = pd.concat([TarEnc_train, features_train1],axis=1)
    TarEnc_test = pd.concat([TarEnc_test, features_test1],axis=1)
# 6.1 目标编码0方差过滤
VarThreshold(X_train_temp, X_test_temp, threshold=0)
# 6.2 目标编码ANOVA分析
"""目标编码衍生出来的特征都是间接统计出来的结果，因此从数值层面上来看，衍生特征和标签的关联度或者和标签分布的一致性都会比较弱，但这并不代表这些特征在建模过程中无法提供有效信息，因此在进行特征筛选时可以略微放宽条件。"""
feature_selection_f(X, y, threshold=0.05)
# （可选）6.3 目标编码互信息
"""因为目标编码衍生的特征和标签关联度较弱，因此互信息计算结果整体数值较小，建议加上随机数种子以确保结果可以重复。其二则是这里也可以考虑放宽筛选条件，但由于互信息的筛选阈值是基于均值制定的，无论是否放宽筛选条件，互信息的阈值总是能一定程度确保最后筛选出来的特征数量。"""
feature_selection_mic(X, y, discrete_features="auto", threshold_coef=0.01)

# 7.NLP方法特征衍生
"""和分组统计特征过程类似，衍生过程需要采用更强的KeyCol以增强特征衍生效果，而筛选过程则是将衍生特征视作连续变量，采用0值方差过滤、方差分析以及互信息法进行特征筛选。
首先，围绕较强原始特征的TF-IDF特征衍生，
然后，以这些较强原始特征为KeyCol来进行分组CountVectorizer和TF-IDF计算。"""
col_temp = keycol.copy()  # 关键变量
NLP_train, NLP_test, colNames_train_new, colNames_test_new = NLP_Group_Stat(
    X_train, X_test, col_cat=col_temp)  # 单变量if-idf计算
for i in range(len(col_temp)):  # 以强原始特征作为keycol进行分组NLP特征衍生
    keyCol = col_temp.pop(i)
    features_train1, features_test1, colNames_train, colNames_test = NLP_Group_Stat(
        X_train, X_test, 
        col_cat=col_temp+cat_rest,  # 除分组变量外的其他离散变量
        keyCol)
    NLP_train = pd.concat([NLP_train, features_train1],axis=1)
    NLP_test = pd.concat([NLP_test, features_test1],axis=1)
    col_temp = keycol.copy()
# 7.1 NLP衍生0方差过滤
VarThreshold(X_train_temp, X_test_temp, threshold=0)
# 7.2 NLP衍生ANOVA分析
feature_selection_f(X, y, threshold=0.01)
# 7.3 NLP衍生互信息
feature_selection_mic(X, y, discrete_features="auto", threshold_coef=0.1)
```

<div style="page-break-after:always"></div> 

------

### 第17章  模型融合

#### 17.1  基本概念

##### 17.1.1  算法集成

>   算法集成分为集成方法、集成范式与集成算法。

1.   集成方法

     >   指的是把不同模型的输出结果融合为一个结果的过程，例如随机森林模型在输出最终结果时所采用的投票法、均值法等。

     -   统计方面：通常情况下，假设空间会非常大，基于有限的训练集无法进行有效的探索；有些情况下，甚至会有多个不同的假设在训练集上取得相同的准确率。如果学习算法从中选取一个，一旦误选，就会产生无法很好预测未知数据的风险。采用集成方法能够很好的结合这些假设，从而降低错选假设的风险；

     -   计算方面：许多学习算法在搜索时会陷入局部最优解。即便有足够多的训练数据，寻找最优解仍然是一件困难的事情。集成方法从多个不同的起点进行搜索，可以更大概率寻找到一个更优的解；

     -   表示能力方面：在很多机器学习任务中，潜在的真是假设不能被假设空间的任一假设所表示。通过集成方法，能够结合多种假设，可以拓展假设空间，因此，学习算就可能得到对真实未知假设更精准的近似。

         总结来说，对模型进行有效的集成能大幅提升模型判别效力，同时降低方差和偏差带来的影响。

2.   集成范式

     >   指的是不同模型的“组合”方法，例如Bagging是一种类似于并联的模型组合方法，而Boosting则是一种类似于串联的模型组合方法。

     集成范式规定了待集成的这些模型的基本训练方法，是拥有完整理论体系的复杂方法，任何集成过程只要能满足这类范式的理论条件，都能达到集成的理论效果，换而言之，集成范式是保证集成效果的理论依据，而Bagging和Boosting也是目前最通用也最著名的两种集成范式。

3.   集成算法

     >   集成范式+集成方法的结果，例如分类随机森林，实际上就是Bagging（集成范式）+投票法（集成方法）。

     集成范式只有一个理论层面可行的模型训练思路，在集成算法落地的过程中还需要设计很多关键环节，如如何确保分类器独立性等，这也就是基于一个集成范式可能诞生多个不同集成算法的原因。

##### 17.1.2  模型融合

尽管集成算法+集成方法的思路并不复杂，但缺少了集成范式的支持，最终模型融合的效果其实是很难保障的。例如，在大多数情况下随机森林效果都要好于决策树，但对于投票法的模型融合，我们很难说三个集成算法的投票结果就一定好于单独一个集成算法的预测结果。

要如何解决这个问题，熟知Bagging和Boosting等集成范式的算法工程师们决定借鉴这些范式的基本思路，例如**Bagging要求基础分类器尽可能的存在差异性**，差异越明显最终结果越好（最好彼此之间相互独立），因此如果是要通过投票的方式进行模型融合，则可以尝试尽可能让参与融合的这些算法各自差异性更加明显一些，例如通过构造**样本多样性、特征多样性、算法多样性**等方法来达成这一目的。再比如，**Boosting**通过串联的方式让模型在不同阶段侧重学习数据的部分成分，甚至可以通过层级设计，让模型逐步拟合误差，以提高模型效果，受此启发算法工程师们决定采用最早诞生于1992年的**Stacking方法**，分层设计融合策略——即上一层输出的结果可以作为下一层的训练数据，通过**类似拟合误差**的方法来获得一个更好的预测效果；同时，经过一段时间的实践人们发现，由于集成学习本身极强的学习能力，模型融合过程**极容易过拟合**，因此诞生了Stacking的**改良型算法——Blending**。

从模型融合的大类上来划分，其实是可以分为基于过程的模型融合和基于结果的模型融合：

1.   **基于过程的模型融合**

     所谓的**集成算法**其实都是基于结果的模型融合，这类方法会根据最终输出结果来回调参与融合（或者集成）的基础模型超参数，例如随机森林在训练时为了提高泛化能力，往往会对参与集成的决策树进行剪枝操作，而深度森林其实也会根据最终结果来调整参与集成的每个森林的超参数；

2.   **基于结果的模型融合**

     而所谓的基于结果的模型融合，则会在模型已经给出最终预测结果的情况下，更多的考虑这些结果应该如何融合，也就是前面所说的集成方法的使用，并围绕集成方法来进行优化和调整，例如**投票法**。

##### 17.1.3  深度森林

偏理论的算法学术工作者则探索了一套拥有完整集成范式理论基础的集成算法的集成方法，其中最有名的算法就是周志华教授提出的[**深度森林（Deep Forest， 2010）**](**https://arxiv.org/pdf/1702.08835.pdf**)。该算法的前生是在周志华教授2018提出的gcForest（多粒度级联森林）算法，通过类DNN的层级架构来提升模型复杂度、并且通过集成随机森林（以及完全随机树森林）来提升模型效果，其基本集成范式（算法架构）如下所示：

<img src="https://cdn.jsdelivr.net/gh/louisyanglu/images/images/T1jhiCVox5gWv6J.png" alt="image-20220514205154541" style="zoom:50%;" />

在这个基本架构下，每一层接收到的数据都是上一层的预测输出结果以及原始特征（或者原始特征的一部分），而输出的则是这一层所有随机森林的预测结果。并且支持根据特征相关性对其进行分组，然后不同组输入到不同层进行训练，以最大化利用特征中提供的有效信息。可以说，深度森林是目前“基于集成算法的集成算法”中最著名也是表现最好的一个，同时也是自2017年CatBoost发表之后近五年来最值得期待的集成算法。

```python
from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier
from deepforest import CascadeForestClassifier

# 加载数据集
X_train, y_train = load_train_data()
X_test, y_test = load_test_data()

# 构建深度森林模型
rf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)
et = ExtraTreesClassifier(n_estimators=100, max_depth=10, random_state=42)
df = CascadeForestClassifier(base_estimator=rf, n_layers=3, n_trees=100, max_depth=10, random_state=42)

# 拟合模型
rf.fit(X_train, y_train)
et.fit(X_train, y_train)
df.fit(X_train, y_train)

# 预测结果
rf_pred = rf.predict(X_test)
et_pred = et.predict(X_test)
df_pred = df.predict(X_test)

# 计算准确率
rf_acc = accuracy_score(y_test, rf_pred)
et_acc = accuracy_score(y_test, et_pred)
df_acc = accuracy_score(y_test, df_pred)

print("随机森林准确率：", rf_acc)
print("极限森林准确率：", et_acc)
print("深度森林准确率：", df_acc)
```

#### 17.2  基本方法

##### 17.2.1  投票法：分类任务

Hard Voting：投票法会根据少数服从多数的规则进行结果输出。

##### 17.2.2  平均法：回归任务

平均法，则是基于连续型预测结果进行平均。

一般来说，N个相互独立且误差为err的分类器进行简单平均法融合，最终得到的融合结果的误差为$\frac{err}{N}$。

##### 17.2.3  概率均值法：分类任务

平均法并不是只能针对回归问题的预测结果进行平均，对于分类问题，有时候我们也可以对分类问题的概率预测结果进行平均，即计算每个样本不同模型的预测概率平均值，然后根据给定阈值计算该样本最终类别，这种方法也被称作概率均值法。

概率均值法也被称作软投票法Soft Voting，对应的，基于类别的投票法则被称为硬投票法Hard Voting。而从理论角度出发，软投票的性能理论上限与硬投票类似。

尽管从数值层面来看，软投票的数值表现更丰富——都是高精度浮点数运算，并且配如果可以进一步配合阈值移动或者加权融合，则有较大的调优空间。不过呢，硬投票实际上也有自己的优势，其中最大的优势就在于硬投票的过程实际上自带一个将概率转化为投票的过程，而这个过程实际上是非线性的，即概率小于0.5时输出为0、概率大于0.5时输出为1，而这个非线性的过程就极有可能进一步提升最终融合效果。sklearn中默认采用**硬投票**的计算方法。

```python
from sklearn.ensemble import VotingClassifier
```

**参数**

|Name|Description|
|:--:|:--:|
|estimators|由**（评估器名称，评估器）**所组成的列表|
|voting|融合的方式，包括此前介绍的硬投票和软投票两种|
|weights|融合过程中各评估器的权重|
|flatten_transform|在软投票时打印结果方式|

##### 17.2.4  几何平均数融合方法

当平均法效果不好时，可将平均法求均值的过程，改为求几何平均数的过程。

$$算术平均数：\bar x = \frac{x_1+x_2+...+x_n}{n}$$

$$几何平均数：G_n = \sqrt[n]{x_1*x_2*x_3*...*x_n}$$

几何平均数也是很多场景下求均值的最佳方法，例如复利下的平均利率、平均发展速度等。

##### 17.2.5  排序平均法

这是一种专为提升ROC-AUC指标量身定制的方法。

1.   对预测结果进行**排序**；
2.   对排序序号进行**平均**；
3.   对平均排序序号进行**归一化**。

<img src="https://cdn.jsdelivr.net/gh/louisyanglu/images/images/image-20230226202344231.png" alt="image-20230226202344231" style="zoom:21%;" /><img src="https://cdn.jsdelivr.net/gh/louisyanglu/images/images/image-20230226202621344.png" alt="image-20230226202621344" style="zoom:32%;" />

1. 训练多个基本分类器，例如决策树、随机森林、支持向量机等。

2. 对于每个测试样本，将基本分类器的输出结果按照概率值从大到小排序，得到一个排名列表。

3. 将所有排名列表的对应位置上的排名值求平均，得到一个平均排名列表。

4. 将平均排名列表中的排名值转化为概率值，作为最终的集成分类结果。

对于算术平均法：模型1几乎没有给模型2带来增益。

排序平均法的优点是可以有效地提高分类模型的性能指标，特别是在处理不平衡数据集时效果更佳。然而，它也存在一些缺点，例如对基本分类器的选择比较敏感，需要耗费较多的计算资源等。

##### 17.2.6  绝对多数投票法

在投票法范畴，除了简单投票外，还有一种更加严格的投票方法——绝对多数投票法。不同于投票法的少数服从多数，绝对多数票法要求票数达到某个临界值后才能输出结果，而如果没达到这个临界值，则不进行预测、而是暂时以某个其他的数值对结果进行标记。当然这个临界值肯定是多于半数票的。

一般来说，为了方便区分，我们也会将遵循少数服从多数的投票法称为相对多数票法，在3个分类器的情况下，相对多数票其实就等价于临界值为2的绝对多数票法，而如上所示，如果我们提高这个临界值，则会直接导致两个结果：其一是输出的判别结果更加可信；但同时也将输出大量无法判别类别的样本。如何对剩余样本进行进一步的类别预测？一般来说有两种思路，其一是单独带入这些不确定的样本进行模型训练，然后再进行融合；其二则是采用别的融合方法在现有模型基础上进行预测。而无论采用哪种策略，其实本质上都是一种两阶段建模的方法。**把不太确定类别的样本单独筛选出来再进行建模**，其实非常类似于Boosting的思想。

##### 17.2.7  阈值移动法

>   一般来说，最佳阈值会在0.5附近，不会低于0.4也不会超过0.6。

如果说有什么方法一定能够在投票&平均法基础上提升融合效果，那么一定阈值移动一定榜上有名。所谓阈值移动，其实就是改变判别样本类别时的阈值。此前无论是平均法还是几何平均法，在最终将平均后的概率转化为类别预测结果时，其实都是以0.5为阈值进行的判别——当平均后的概率大于0.5时判别为1类、小于0.5时判别为0类。但实际上这个阈值是可以改变的，就像此前逻辑回归模型优化时阈值移动一样，很多时候我们甚至可以**将阈值视作一个超参数**来进行优化。并且，相比后面要讨论的加权平均，阈值移动的过拟合风险更小，是融合阶段必不可少的尝试方法。

```python
class logit_threshold(BaseEstimator, ClassifierMixin, TransformerMixin):
    """
    继承了3个基类：
    	BaseEstimator：提供get_params()和set_params()两个方法
    	ClassifierMixin：相当于标注该评估器是一个Classifier，提供了score()方法
    	TransformerMixin：提供了fit_transform()方法
    """
    
    def __init__(self, penalty='l2', C=1.0, max_iter=1e8, solver='lbfgs', l1_ratio=None, class_weight=None, thr=0.5):  # 设置分类器参数
        self.penalty = penalty
        self.C = C
        self.max_iter = max_iter
        self.solver = solver
        self.l1_ratio = l1_ratio
        self.thr = thr
        self.class_weight = class_weight
        
    def fit(self, X, y):  # 训练分类器
        clf = LogisticRegression(penalty = self.penalty, 
                                 C = self.C, 
                                 solver = self.solver, 
                                 l1_ratio = self.l1_ratio,
                                 class_weight=self.class_weight, 
                                 max_iter=self.max_iter, 
                                 random_state=12)
        clf.fit(X, y)
        self.coef_ = clf.coef_
        self.clf = clf
        return self
        
    def predict_proba(self, X):  # 返回预测的概率
        res_proba = self.clf.predict_proba(X)
        return res_proba
    
    def predict(self, X):  # 返回预测的结果
        res = (self.clf.predict_proba(X)[:, 1]>=self.thr) * 1
        return res
    
# 设置转化器流
logistic_pre = ColumnTransformer([
    ('cat', preprocessing.OneHotEncoder(drop='if_binary'), category_cols), 
    ('num', 'passthrough', numeric_cols)
])

num_pre = ['passthrough', preprocessing.StandardScaler(), preprocessing.KBinsDiscretizer(n_bins=3, encode='ordinal', strategy='kmeans')]

# 实例化逻辑回归评估器
logistic_model = logit_threshold(max_iter=int(1e8))

# 设置机器学习流
logistic_pipe = make_pipeline(logistic_pre, logistic_model)

# 设置超参数空间
cw_l = [None, 'balanced']
#cw_l.extend([{1: x} for x in np.arange(1, 4, 0.2)])
logistic_param = [
    {'columntransformer__num':num_pre, 'logit_threshold__thr': np.arange(0.1, 1, 0.1).tolist(), 'logit_threshold__penalty': ['l1'], 'logit_threshold__C': np.arange(0.1, 1.1, 0.1).tolist(), 'logit_threshold__solver': ['saga'], 'logit_threshold__class_weight':cw_l}, 
    {'columntransformer__num':num_pre, 'logit_threshold__thr': np.arange(0.1, 1, 0.1).tolist(), 'logit_threshold__penalty': ['l2'], 'logit_threshold__C': np.arange(0.1, 1.1, 0.1).tolist(), 'logit_threshold__solver': ['lbfgs', 'newton-cg', 'sag', 'saga'], 'logit_threshold__class_weight':cw_l}, 
]

# 实例化网格搜索评估器
logistic_search = GridSearchCV(estimator = logistic_pipe,
                               param_grid = logistic_param,
                               scoring='accuracy',
                               n_jobs = 15)

s = time.time()
logistic_search.fit(X_train_OE, y_train)
print(time.time()-s, "s")
```

```python
class VotingClassifier_threshold(BaseEstimator, ClassifierMixin, TransformerMixin):
    
    def __init__(self, estimators, voting='hard', weights=None, thr=0.5):
        self.estimators = estimators
        self.voting = voting
        self.weights = weights
        self.thr = thr
        
    def fit(self, X, y):
        VC = VotingClassifier(estimators = self.estimators, 
                              voting = self.voting, 
                              weights = self.weights)
        
        VC.fit(X, y)
        self.clf = VC
        
        return self
        
    def predict_proba(self, X):
        if self.voting == 'soft':
            res_proba = self.clf.predict_proba(X)
        else:
            res_proba = None
        return res_proba
    
    def predict(self, X):
        if self.voting == 'soft':
            res = (self.clf.predict_proba(X)[:, 1] >= self.thr) * 1
        else:
            res = self.clf.predict(X)
        return res
    
    def score(self, X, y):
        acc = accuracy_score(self.predict(X), y)
        return acc
    

from hyperopt import hp, fmin, tpe
# 定义超参数空间
params_space = {'thr': hp.uniform("thr", 0.4, 0.6)}

# 定义目标函数
def hyperopt_objective_val(params):
    thr = params['thr']
    
    # 创建带阈值的平均法评估器
    VC_soft_thr = VotingClassifier_threshold(estimators, voting='soft', thr=thr)  # 自定义函数

    # 输出验证集上的平均得分
    val_score = cross_val_score(VC_soft_thr, 
                                X_train, 
                                y_train, 
                                scoring='roc_auc', 
                                n_jobs=-1,
                                cv=3).mean()
    return 1-val_score

# 定义优化函数
def param_hyperopt_val(max_evals):
    params_best = fmin(hyperopt_objective_val,
                       space=params_space,
                       algo=tpe.suggest,
                       max_queue_len=5,
                       max_evals=max_evals, 
                       rstate=np.random.default_rng(17))    
    return params_best
```

#### 17.3  加权平均法

>   所谓加权平均，实际上就是在平均的过程中给不同项以不同权重，从而增强最终结果表现。

$$\bar X = \frac{x_1*w_1+x_2*w_2+x_3*w_3+...+x_n*w_n}{w_1+w_2+w_3+...+w_n}$$

其中$w_1$到$w_n$是n个项的权重，而$x_1$到$x_n$则是各个评估器预测的概率结果。

除了软投票中我们可以用权重乘以概率然后求加权平均之外，在硬投票中也是可以有加权投票的，并且权重也是可以任意数值，如此一来最终得到的票数也可能是非整数结果。

##### 17.3.1  **权重的理论最优值**

>   先确定理论层面最优结论不可用之后再使用超参数搜索方法。

分类问题：通过理论推导能够得出，在各分类器彼此独立的情况下，每个分类器的最佳权重为：$$w_i = log\frac{p_i}{1-p_i}$$。其中$p_i$是第i个分类器的分类精度，即准确率。

##### 17.3.2  **经验法**

理论结果和实践效果之间有差异，以及无法满足模型独立性假设，理论层面给出的最优权重可能无法在实践过程中有效得出最优解。根据长期实践经验，给出一组“应该还不错”的权重。

-   其一是以平均为主的思路

    整体给不同评估器分配比较均匀的权重，即仍然希望综合采纳各个模型的不同意见，博采众长；

    -   或许我们不应该以训练集的准确率作为权重，而应该采用更能代表模型泛化能力的验证集的平均准确率作为权重；

    -   评分之间的差异过小，会导致加权效果不明显。

        如何放大不同模型之间的差异，其实很多时候都是“启发式”的。例如我们可以简单根据模型评分进行排序，效果最差的模型权重为1、次优的模型权重为2、最好的模型权重为3，此时就相当于次优的模型权重是最差的模型的两倍、最优的模型的权重是最差模型的3倍。

        总的来说，我们可以模型排名的倒序为基础分配权重，然后不断尝试不断修改，修改的方向有三个，分别是**放大差异**、**缩小差异**以及**分配不同差异**。

        <img src="https://cdn.jsdelivr.net/gh/louisyanglu/images/images/qCPHEsKRbzSDUGA.png" alt="image-20220520162248584" style="zoom:33%;" />

-   其二则是以某一个评估器为核心，剩下评估器为辅助

    >   这里需要注意，只能进行小幅修改，并且手动测试效果，而不是利用优化器进行高精度的搜索，甚至是权重+阈值进行协同搜索，其实也是因为高精度的阈值搜索极容易导致过拟合，这里我们采用更加原始更加简单的手动调整权重策略，看似精度不足，实际上是为了对冲过拟合风险。

    核心评估器的权重占比超过90%，而辅助的评估器权重只占10%，主要起到局部修正核心评估器判断结果的作用。比如按照指数关系设计评估器权重，即按照1：10：100进行权重设计和调整。

    在根据指数级差异设计权重时，大多数情况下加权硬投票都会失效，其主要原因也是因为当只有三个评估器参与投票、而其中某个评估器的权重比其他所有评估器权重之和还要大的时候，其他评估器的票数总和也抵不上核心评估器的一票有效，因此最后投票输出结果必然是核心评估器这一个评估器的预测结果，而如此一来，融合也是去了其意义，因此一般来说，指数级权重差异设计并不适用于硬投票的情况。

    而软投票则有所不同，有的时候当核心评估器对某些样本“摇摆不定”时，微弱的来自其他评估器的概率值加合就可能影响最终的结果。

##### 17.3.3  **权重搜索**

>   **权重搜索非常容易过拟合**：模型在验证集上能得到一个不错的结果，但仍然无法在测试集上获得相类似的好的结果。最根本的问题，在于**加权融合这个“模型”（或者说算法）本身的泛化能力**。

```python
# 定义超参数空间
params_space = {'voting':hp.choice("voting", ['soft', 'hard']),
                'thr': hp.uniform("thr", 0.4, 0.6), 
                'weight1': hp.uniform("weight1",0,1),
                'weight2': hp.uniform("weight2",0,1),
                'weight3': hp.uniform("weight3",0,1)}
# 定义目标函数
def hyperopt_objective_weight(params):
    voting = params['voting']
    thr = params['thr']
    weight1 = params['weight1']
    weight2 = params['weight2']
    weight3 = params['weight3']
    weights = [weight1, weight2, weight3]
    # 创建带阈值的平均法评估器
    VC_weight_search = VotingClassifier_threshold(estimators=estimators, 
                                                  weights=weights,
                                                  voting=voting, 
                                                  thr=thr)
    # 输出验证集上的平均得分
    val_score = cross_val_score(VC_weight_search, 
                                X_train_OE, 
                                y_train, 
                                scoring='accuracy', 
                                n_jobs=15,
                                cv=3).mean()
    return -val_score
```

我们知道，任何通用有效的机器学习算法其实都是有一整套完整的计算流程和模型框架的，这个基本框架也是经过理论验证切实有效的，例如线性模型实际上是基于线性方程的框架进行的模型设计，决策树模型底层实际上是一个分层的决策流程，我们训练模型实际上训练的就是这个框架的参数，如线性方程的系数、决策树的分叉节点、决策树的深度等，而模型预测时也是依据这个框架来进行判别，例如带入数据到线性方程中算出预测结果，带入数据到决策树中进行判别等，这些模型的训练和预测都是通过这个算法框架来执行。而反观加权融合这个“模型”，我们只是希望三组数以一个最佳的权重加出一个最好的结果，尽管这个过程足够灵活，但其底层没有受到任何模型框架的约束。而正是因为这个底层框架的缺失，导致其泛化能力有限。

**解决办法**

1.  基于经验法，手动调整参数搜索空间。

    根据经验法得出的基本结论，对搜索空间进行差异化设置。这个过程其实也就相当于是经验法挑选阈值+超参数搜索阈值结合的过程。

    ```python
    # 定义超参数空间
    params_space = {'thr': hp.uniform("thr", 0.4, 0.6), 
                    'weight1': hp.uniform("weight1",0.05,0.1),
                    'weight2': hp.uniform("weight2",0,0.01),
                    'weight3': hp.uniform("weight3",0.5,1)}
    ```

2.  强化信息隔离，提升验证集效力

    在模型训练过程中彻底阻隔验证集的影响，以提升验证集的“验证”方面的效力。

    我们知道现在带入进行融合的这几个模型原始状态下是在全部训练集上训练的结果，包括模型的参数和超参数。尽管我们在调用cross_val_score函数进行交叉验证的时候，实际上是在训练集中再进行了（五折）划分，然后用不同数据训练了5个模型，但是需要注意的是，这个阶段训练的是模型的参数，而不是超参数，也就是说每个模型经过cross_val_score训练得到的5个模型，其实是拥有和原始模型相同的超参数，而这些超参数实际上是在全部数据集上训练得到，也就是说，cross_val_score训练得出的模型其实早已被泄露了验证集的信息，而泄露的途径实际上就是这些模型共同的超参数。

    要如何改进这个问题，很简单，我们只需要**手动划分训练集和验证集**，然后**单独在划分后的训练集上进行模型训练和超参数搜索**即可，由此一来即可避免验证集信息泄露的问题，从而提高验证集结果的可信度，进而提升交叉验证结果的泛化能力。不过需要注意的是，这么做其实会降低每个单独模型的预测能力（训练超参数的数据量变少了），但整体来看能提升融合结果的泛化能力。并且，这不仅是加权融合过程的需要，也是Stacking方法的需要。

    对每个训练数据集进行模型训练与超参数优化，两种基本方法：

    首先，最简单的方法就是每个模型在5组训练数据下分别训练和超参数优化，每类模型需要训练并优化得到5个不同的模型；

    其二则是批量模型超参数搜索，可以考虑设置一个非常大的超参数空间，然后循环带入五组训练数据集，进行五个模型训练和超参数优化，若每个模型的超参数都正好落在超参数搜素空间内，则五个模型都是最优模型，而如果某个模型的超参数正好落在搜索边界上，则需要围绕这个模型（带入对应的训练数据）再次设置超参数空间并进行超参数搜索。

    前者需要大量手动操作但较为节省时间，后者更加自动化但需要耗费更大量的计算时间。对于决策树和逻辑回归这种搜索过程较快的模型，可以采用批量搜索的方法，而对于随机森林，考虑到单个模型的超参数优化就会比较耗时，因此建议单独手动训练模型。

    ```python 
    from sklearn.model_selection import KFold
    # 实例化KFold评估器
    kf = KFold(n_splits=5, random_state=12, shuffle=True)
    train_part_index_l = []
    eval_index_l = []
    
    for train_part_index, eval_index in kf.split(X_train_OE, y_train):
        train_part_index_l.append(train_part_index)
        eval_index_l.append(eval_index)
    # 训练集特征
    X_train1 = X_train_OE.loc[train_part_index_l[0]]
    X_train2 = X_train_OE.loc[train_part_index_l[1]]
    X_train3 = X_train_OE.loc[train_part_index_l[2]]
    X_train4 = X_train_OE.loc[train_part_index_l[3]]
    X_train5 = X_train_OE.loc[train_part_index_l[4]]
    
    # 验证集特征
    X_eval1 = X_train_OE.loc[eval_index_l[0]]
    X_eval2 = X_train_OE.loc[eval_index_l[1]]
    X_eval3 = X_train_OE.loc[eval_index_l[2]]
    X_eval4 = X_train_OE.loc[eval_index_l[3]]
    X_eval5 = X_train_OE.loc[eval_index_l[4]]
    
    # 训练集标签
    y_train1 = y_train.loc[train_part_index_l[0]]
    y_train2 = y_train.loc[train_part_index_l[1]]
    y_train3 = y_train.loc[train_part_index_l[2]]
    y_train4 = y_train.loc[train_part_index_l[3]]
    y_train5 = y_train.loc[train_part_index_l[4]]
    
    # 验证集标签
    y_eval1 = y_train.loc[eval_index_l[0]]
    y_eval2 = y_train.loc[eval_index_l[1]]
    y_eval3 = y_train.loc[eval_index_l[2]]
    y_eval4 = y_train.loc[eval_index_l[3]]
    y_eval5 = y_train.loc[eval_index_l[4]]
    
    train_set = [(X_train1, y_train1), 
                 (X_train2, y_train2), 
                 (X_train3, y_train3), 
                 (X_train4, y_train4), 
                 (X_train5, y_train5)]
    eval_set = [(X_eval1, y_eval1), 
                (X_eval2, y_eval2), 
                (X_eval3, y_eval3), 
                (X_eval4, y_eval4), 
                (X_eval5, y_eval5)]
    # 分别训练5个不同超参数的模型
    
    # 对第一个训练集进行模型训练和超参数优化，受限于样本量，当前训练集上得到的模型效果并不如完整数据集上的模型效果。
    # 设置超参数空间
    parameter_space = {
        "min_samples_leaf": range(4, 7), 
        "min_samples_split": range(1, 4),
        "max_depth": range(7, 11),
        "max_leaf_nodes": [None] + list(range(31, 34)), 
        "n_estimators": range(93, 96), 
        "max_features":['sqrt', 'log2'] + list(range(5, 8)), 
        "max_samples":[None, 0.49, 0.5, 0.51]}
    
    # 实例化模型与评估器
    RF_1 = RandomForestClassifier(random_state=12)
    grid_RF_1 = GridSearchCV(RF_1, parameter_space, n_jobs=15)
    
    # 模型训练
    grid_RF_1.fit(X_train1, y_train1)
    RF_1 = grid_RF_1.best_estimator_
    # 训练其他4组模型...
    RF_2 = grid_RF_2.best_estimator_
    RF_3 = grid_RF_3.best_estimator_
    RF_4 = grid_RF_4.best_estimator_
    RF_5 = grid_RF_5.best_estimator_
    # 得到一组5个子模型
    RF_l = [RF_1, RF_2, RF_3, RF_4, RF_5]
    ```

    然后，先将5个验证集拼凑成一个完整的“训练集”，计算这个“训练集”上的准确率等评估指标。

    <img src="https://cdn.jsdelivr.net/gh/louisyanglu/images/images/bPyRBSnD8ZwmQI9.png" alt="image-20220510162151351" style="zoom:36%;" />

    ```python
    # 验证集上的预测结果
    eval1_predict_proba_RF = pd.Series(RF_l[0].predict_proba(X_eval1)[:, 1], index=X_eval1.index)
    eval2_predict_proba_RF = pd.Series(RF_l[1].predict_proba(X_eval2)[:, 1], index=X_eval2.index)
    eval3_predict_proba_RF = pd.Series(RF_l[2].predict_proba(X_eval3)[:, 1], index=X_eval3.index)
    eval4_predict_proba_RF = pd.Series(RF_l[3].predict_proba(X_eval4)[:, 1], index=X_eval4.index)
    eval5_predict_proba_RF = pd.Series(RF_l[4].predict_proba(X_eval5)[:, 1], index=X_eval5.index)
    eval_predict_proba_RF = pd.concat([eval1_predict_proba_RF, 
                                       eval2_predict_proba_RF, 
                                       eval3_predict_proba_RF, 
                                       eval4_predict_proba_RF, 
                                       eval5_predict_proba_RF]).sort_index()
    # 测试集上的预测结果
    test_predict_proba_RF = []
    for i in range(5):
        test_predict_proba_RF.append(RF_l[i].predict_proba(X_test_OE)[:, 1])
    test_predict_proba_RF = np.array(test_predict_proba_RF)
    test_predict_proba_RF = test_predict_proba_RF.mean(0)  # 按行求均值，计算每条测试数据的平均预测概率
    
    # 再用其他算法训练5个子模型
    ```

    最后，再进行权重搜索。

    由于模型训练过程中，我们进行了非常严格的信息隔离，因此验证集上的表现应该能够较好的衡量模型泛化能力，可进行全域搜索，无需根据经验进行大量反复尝试，只需要按部就班的训练好一组组模型，然后设置一个较大的迭代次数进行TPE搜索即可。

    <img src="https://cdn.jsdelivr.net/gh/louisyanglu/images/images/ZJs9oHAFQ2wa8Vt.png" alt="image-20220523213524224" style="zoom:33%;" />

    ```python
    # 定义超参数空间
    # 全域搜索
    params_space = {'thr': hp.uniform("thr", 0.4, 0.6), 
                    'weight1': hp.uniform("weight1",0,1),
                    'weight2': hp.uniform("weight2",0,1),
                    'weight3': hp.uniform("weight3",0,1)}
    # 定义目标函数
    def hyperopt_objective_weight(params):
        thr = params['thr']
        weight1 = params['weight1']
        weight2 = params['weight2']
        weight3 = params['weight3']
        
        weights_sum = weight1 + weight2 + weight3
    
        predict_probo_weight = (eval_predict_proba_lr * weight1 + 
                                eval_predict_proba_tree * weight2 + 
                                eval_predict_proba_RF * weight3) / weights_sum
    
        res_weight = (predict_probo_weight >= thr) * 1
    
        eval_score = accuracy_score(res_weight, y_train)
        
        return -eval_score
    # 定义优化函数
    def param_hyperopt_weight(max_evals):
        params_best = fmin(fn = hyperopt_objective_weight,
                           space = params_space,
                           algo = tpe.suggest,
                           max_evals = max_evals, 
                           rstate = np.random.default_rng(17))    
        return params_best
    ```

    **整个交叉训练模型的过程其实就非常类似于抽取自助集然后进行Bagging集成。决策树本身稳定性较差，样本上的差异就能构成模型结果的较大差异，因此会非常适合Bagging集成。而反观RF、XGB等，其本身学习能力较强、稳定性也非常强，因此简单的交叉训练并不能造成模型之间非常明显的差异，反而因为样本量的减少较大程度上影响了随机森林模型的学习效果，导致整体判别能力下降。**

    总的来说，上述流程还可以有至少两个优化的方向：

    -   首先，我们完全可以把每个模型看成是独立的模型，独立的在验证集上进行权重搜索，独立的参与测试集的预测，由此获得更灵活的验证集结果表现，借此提升融合效果：**细粒度权重搜索方案**。
    -   第二，可以考虑将每一组模型简单看成是一个数据集上训练得到的5个模型（就像第一小节中在完整数据集上训练的逻辑回归、决策树和随机森林），然后组内进行加权融合，通过对训练集的预测得到每个模型的权重（也就是VotingClassifier+cross_val_score过程），然后，当每一组内都分别训练得到一组权重，并且分别得到了3个不同的训练集上的加权预测结果后，再计算组间权重：**分层融合**。


##### 17.3.4  **细粒度权重搜索方案**

<img src="https://cdn.jsdelivr.net/gh/louisyanglu/images/images/8mIKPwJOGoZRcL2-20230226225015305.png" alt="image-20220524232358976" style="zoom:33%;" />

例如lr_1、tree_1和RF_1模型，都是在Part 1-4数据集上进行的训练模型，这些三个模型就可以围绕Part 5数据集进行加权融合，分别训练得到三个模型不同的权重，类似的其他模型也可以按照此方法进行训练，最终得到每个模型单独的权重，然后在预测的过程中，每个模型单独对测试集进行预测，然后通过加权的方式输出最终预测结果。

```python
# 定义超参数空间
params_space = {'thr': hp.uniform("thr", 0.4, 0.6), 
                'weight_lr1': hp.uniform("weight_lr1",0,1),
                'weight_lr2': hp.uniform("weight_lr2",0,1),
                'weight_lr3': hp.uniform("weight_lr3",0,1), 
                'weight_lr4': hp.uniform("weight_lr4",0,1), 
                'weight_lr5': hp.uniform("weight_lr5",0,1), 
                'weight_tree1': hp.uniform("weight_tree1",0,1),
                'weight_tree2': hp.uniform("weight_tree2",0,1),
                'weight_tree3': hp.uniform("weight_tree3",0,1), 
                'weight_tree4': hp.uniform("weight_tree4",0,1), 
                'weight_tree5': hp.uniform("weight_tree5",0,1), 
                'weight_RF1': hp.uniform("weight_RF1",0,1),
                'weight_RF2': hp.uniform("weight_RF2",0,1),
                'weight_RF3': hp.uniform("weight_RF3",0,1), 
                'weight_RF4': hp.uniform("weight_RF4",0,1), 
                'weight_RF5': hp.uniform("weight_RF5",0,1)}
# 定义目标函数
def hyperopt_objective_weight(params):
    thr = params['thr']
    weight_lr1 = params['weight_lr1']
    weight_lr2 = params['weight_lr2']
    weight_lr3 = params['weight_lr3']
    weight_lr4 = params['weight_lr4']
    weight_lr5 = params['weight_lr5']
    
    weight_tree1 = params['weight_tree1']
    weight_tree2 = params['weight_tree2']
    weight_tree3 = params['weight_tree3']
    weight_tree4 = params['weight_tree4']
    weight_tree5 = params['weight_tree5']
    
    weight_RF1 = params['weight_RF1']
    weight_RF2 = params['weight_RF2']
    weight_RF3 = params['weight_RF3']
    weight_RF4 = params['weight_RF4']
    weight_RF5 = params['weight_RF5']
    
    eval1_predict_proba_weight = (pd.Series(lr_1.predict_proba(X_eval1)[:, 1], index=X_eval1.index) * weight_lr1 + pd.Series(tree_1.predict_proba(X_eval1)[:, 1], index=X_eval1.index) * weight_tree1 + pd.Series(RF_1.predict_proba(X_eval1)[:, 1], index=X_eval1.index) * weight_RF1) / (weight_lr1 + weight_tree1 + weight_RF1)

    eval2_predict_proba_weight = (pd.Series(lr_2.predict_proba(X_eval2)[:, 1], index=X_eval2.index) * weight_lr2 + pd.Series(tree_2.predict_proba(X_eval2)[:, 1], index=X_eval2.index) * weight_tree2 + pd.Series(RF_2.predict_proba(X_eval2)[:, 1], index=X_eval2.index) * weight_RF2) / (weight_lr2 + weight_tree2 + weight_RF2)    
    
    eval3_predict_proba_weight = (pd.Series(lr_3.predict_proba(X_eval3)[:, 1], index=X_eval3.index) * weight_lr3 + pd.Series(tree_3.predict_proba(X_eval3)[:, 1], index=X_eval3.index) * weight_tree3 + pd.Series(RF_3.predict_proba(X_eval3)[:, 1], index=X_eval3.index) * weight_RF3) / (weight_lr3 + weight_tree3 + weight_RF3)    
    
    eval4_predict_proba_weight = (pd.Series(lr_4.predict_proba(X_eval4)[:, 1], index=X_eval4.index) * weight_lr4 + pd.Series(tree_4.predict_proba(X_eval4)[:, 1], index=X_eval4.index) * weight_tree4 + pd.Series(RF_4.predict_proba(X_eval4)[:, 1], index=X_eval4.index) * weight_RF4) / (weight_lr4 + weight_tree4 + weight_RF4)    
    
    eval5_predict_proba_weight = (pd.Series(lr_5.predict_proba(X_eval5)[:, 1], index=X_eval5.index) * weight_lr5 + pd.Series(tree_5.predict_proba(X_eval5)[:, 1], index=X_eval5.index) * weight_tree5 + pd.Series(RF_5.predict_proba(X_eval5)[:, 1], index=X_eval5.index) * weight_RF5) / (weight_lr5 + weight_tree5 + weight_RF5)        
    
    eval_predict_proba_weight = pd.concat([eval1_predict_proba_weight,
                                           eval2_predict_proba_weight, 
                                           eval3_predict_proba_weight, 
                                           eval4_predict_proba_weight, 
                                           eval5_predict_proba_weight]).sort_index()
    
    eval_predict = (eval_predict_proba_weight >= thr) * 1
    
    eval_acc = accuracy_score(eval_predict, y_train)
    
    return -eval_acc
def muti_weight_test_acc(params):
    thr = params['thr']
    weight_lr1 = params['weight_lr1']
    weight_lr2 = params['weight_lr2']
    weight_lr3 = params['weight_lr3']
    weight_lr4 = params['weight_lr4']
    weight_lr5 = params['weight_lr5']
    
    weight_lr_l = np.array([weight_lr1, weight_lr2, weight_lr3, weight_lr4, weight_lr5])
    weight_lr_sum = weight_lr_l.sum()
    
    weight_tree1 = params['weight_tree1']
    weight_tree2 = params['weight_tree2']
    weight_tree3 = params['weight_tree3']
    weight_tree4 = params['weight_tree4']
    weight_tree5 = params['weight_tree5']
    
    weight_tree_l = np.array([weight_tree1, weight_tree2, weight_tree3, weight_tree4, weight_tree5])
    weight_tree_sum = weight_tree_l.sum()
    
    weight_RF1 = params['weight_RF1']
    weight_RF2 = params['weight_RF2']
    weight_RF3 = params['weight_RF3']
    weight_RF4 = params['weight_RF4']
    weight_RF5 = params['weight_RF5']
    
    weight_RF_l = np.array([weight_RF1, weight_RF2, weight_RF3, weight_RF4, weight_RF5])
    weight_RF_sum = weight_RF_l.sum()
    # 测试集：3组15个子模型，加权求平均
    test_predict_proba = (lr_1.predict_proba(X_test_OE)[:, 1] * weight_lr1 + 
                          lr_2.predict_proba(X_test_OE)[:, 1] * weight_lr2 + 
                          lr_3.predict_proba(X_test_OE)[:, 1] * weight_lr3 + 
                          lr_4.predict_proba(X_test_OE)[:, 1] * weight_lr4 + 
                          lr_5.predict_proba(X_test_OE)[:, 1] * weight_lr5 + 
                          tree_1.predict_proba(X_test_OE)[:, 1] * weight_tree1 + 
                          tree_2.predict_proba(X_test_OE)[:, 1] * weight_tree2 + 
                          tree_3.predict_proba(X_test_OE)[:, 1] * weight_tree3 + 
                          tree_4.predict_proba(X_test_OE)[:, 1] * weight_tree4 + 
                          tree_5.predict_proba(X_test_OE)[:, 1] * weight_tree5 + 
                          RF_1.predict_proba(X_test_OE)[:, 1] * weight_RF1 + 
                          RF_2.predict_proba(X_test_OE)[:, 1] * weight_RF2 + 
                          RF_3.predict_proba(X_test_OE)[:, 1] * weight_RF3 + 
                          RF_4.predict_proba(X_test_OE)[:, 1] * weight_RF4 + 
                          RF_5.predict_proba(X_test_OE)[:, 1] * weight_RF5) / (weight_lr_sum + weight_tree_sum + weight_RF_sum)
    
    test_predict = (test_predict_proba >= thr) * 1
    
    test_acc = accuracy_score(test_predict, y_test)
    return test_acc
```

很明显，该方案通过给每个模型单独分配权重，能够大幅提升测试集上的效果上限，但如此规模的（连续变量）超参数对TPE的搜索过程会造成一定的压力，尽管上限较高，同时验证集仍然可信，但TPE却不一定能搜索得到哪怕是验证集上的最优解，因此实际效果并不一定比原始策略更好。

##### 17.3.5  **分层融合**

>   将每一组模型简单看成是一个数据集上训练得到的5个模型，然后组内进行加权融合，通过对训练集的预测得到每个模型的权重。
>
>   1.   组内融合
>   2.   组间融合

其实多级分层融合最终的目的也是为了让每个评估器拥有独立的权重，这点和细粒度权重搜索方案类似，而所不同的是，多级分层融合的组内融合过程会泄露一部分验证集信息（同一个模型在全部数据上进行交叉验证），而换来的却是每一次搜索的高效。换而言之，两种方案的对比就是，细粒度搜索融合效果上限更高、但不容易达到，瓶颈在于超参数优化器，而多级分层搜索上限较低，但更容易达到。可以说两种方法各有优劣。

<img src="https://cdn.jsdelivr.net/gh/louisyanglu/images/images/HErYdURczIotaZW.png" alt="image-20220525010307470" style="zoom:50%;" />

<img src="https://cdn.jsdelivr.net/gh/louisyanglu/images/images/lpJdSjZtenRYP7C.png" alt="image-20220525010429071" style="zoom:50%;" />

```python
# 第一个模型：做组内加权融合，求出5个子模型的权重
estimators_RF = [('RF_1',RF_1), ('RF_2',RF_2), ('RF_3',RF_3), ('RF_4',RF_4), ('RF_5',RF_5)]
# 定义超参数空间
params_space = {'thr': hp.uniform("thr", 0.4, 0.6), 
                'weight1': hp.uniform("weight1",0,1),
                'weight2': hp.uniform("weight2",0,1),
                'weight3': hp.uniform("weight3",0,1), 
                'weight4': hp.uniform("weight4",0,1), 
                'weight5': hp.uniform("weight5",0,1)}
# 定义目标函数
def hyperopt_objective_weight(params):
    thr = params['thr']
    weight1 = params['weight1']
    weight2 = params['weight2']
    weight3 = params['weight3']
    weight4 = params['weight4']
    weight5 = params['weight5']
    
    weights = [weight1, weight2, weight3, weight4, weight5]
    
    # 创建带阈值的平均法评估器
    VC_weight_search = VotingClassifier_threshold(estimators=estimators_RF, 
                                                  weights=weights,
                                                  voting='soft', 
                                                  thr=thr)

    # 输出验证集上的平均得分
    val_score = cross_val_score(VC_weight_search, 
                                X_train_OE, 
                                y_train, 
                                scoring='accuracy', 
                                n_jobs=15,
                                cv=5).mean()
    
    return -val_score
def weights_extract(best_params):
    thr = best_params['thr']
    weight1 = best_params['weight1']
    weight2 = best_params['weight2']
    weight3 = best_params['weight3']
    weight4 = best_params['weight4']
    weight5 = best_params['weight5']

    weights_sum = (weight1 + weight2 + weight3 + weight4 + weight5)

    weight1 = weight1 / weights_sum
    weight2 = weight2 / weights_sum
    weight3 = weight3 / weights_sum
    weight4 = weight4 / weights_sum
    weight5 = weight5 / weights_sum

    weights = [weight1, weight2, weight3, weight4, weight5]
    return weights
# 验证集
eval_predict_proba_RF = 0

for i in range(5):
    eval_predict_proba_RF += (RF_l[i].predict_proba(X_train_OE)[:, 1]) * RF_weights[i]
# 测试集：组内加权求和
test_predict_proba_RF = 0

for i in range(5):
    test_predict_proba_RF += (RF_l[i].predict_proba(X_test_OE)[:, 1]) * RF_weights[i]

# 第2-n个模型...

# 组间融合

# 定义超参数空间
params_space = {'thr': hp.uniform("thr", 0.4, 0.6), 
                'weight1': hp.uniform("weight1",0,1),
                'weight2': hp.uniform("weight2",0,1),
                'weight3': hp.uniform("weight3",0,1)}
# 定义目标函数
def hyperopt_objective_weight(params):
    thr = params['thr']
    weight1 = params['weight1']
    weight2 = params['weight2']
    weight3 = params['weight3']
    
    weights_sum = weight1 + weight2 + weight3

    predict_probo_weight = (eval_predict_proba_lr * weight1 + 
                            eval_predict_proba_tree * weight2 + 
                            eval_predict_proba_RF * weight3) / weights_sum

    res_weight = (predict_probo_weight >= thr) * 1

    eval_score = accuracy_score(res_weight, y_train)
    
    return -eval_score
```

#### 17.4  用模型代替权重搜索：Stacking

>   过拟合问题的根源在于没有模型框架，那么釜底抽薪之计当然就是考虑采用某个成熟的机器学习模型来代替这个搜索的过程。

<img src="https://cdn.jsdelivr.net/gh/louisyanglu/images/images/eGR4Cl3dsFDpAES.png" alt="image-20220522174140320" style="zoom:33%;" />

我们先来回顾下加权融合的整个过程，其实所谓的加权融合，其实就是根据单独模型的预测结果，通过加权求和以及一个分段函数输出结果，并用这个结果尽可能去拟合真实标签，不难发现，其实**这个过程的本质就是用一组连续变量（各模型的预测结果）去拟合真实标签，其实也就是一个分类问题**，完全可以由很多机器学习模型来完成。当然，如果是硬投票的加权融合过程，则是根据离散变量去拟合离散变量。而无论哪种情况，只要是这个预测过程采用机器学习模型，其本质就不再是加权融合了，而是一种名为**Stacking**的融合方法。

Stacking是希望通过训练一个模型（而非找到某种加权平均的过程），来完成结合这一过程，在这个过程中，原始的个体学习器也被称为一级学习器，而结合过程用到的模型，则被称为二级学习器，或者元学习器（meta model），或者最终学习器（final model）。

<img src="https://cdn.jsdelivr.net/gh/louisyanglu/images/images/image-20220919215031456.png" alt="image-20220522174140320" style="zoom:50%;" />

和其他结合方法一样，Stacking等学习结合器也有非常完整的基础理论，但同样，由于一级模型无法保证其独立性，因此大多数理论并不能很好的指导Stacking模型融合过程。

##### 17.4.1  **参数**

```python
from sklearn.ensemble import StackingClassifier
```

|      参数       |                             解释                             |
| :-------------: | :----------------------------------------------------------: |
|   estimators    |       一级评估器，由（模型名称、模型）所组成的一个列表       |
| final_estimator | 二级评估器，只需要实例化一个sklearn中的评估器即可，默认是逻辑回归 |
|       cv        |                   一级评估器基交叉训练折数                   |
|  stack_method   | 选择概率结果还是类别结果进行元学习器的训练，一般为`predict_proba` |
|   passthrough   |  是否额外带入原始数据特征进行元学习器的训练，一般为`False`   |

`stack_method`：可选'auto'、'`predict_proba`'、'decision_function'、'predict'四个不同取值。

>   当输入'predict_proba'时，即带入样本类别概率进行训练，而'decision_function'则是SVM特殊的一种模型输出结果，代表样本到分割超平面的（置信）距离，同样也可以充当类似概率的作用，距离越短，则模型判断越不肯定（相当于概率越趋近于0.5），而'predict'则是样本类别结果，相当于是Stacking“硬投票”，在默认情况下，参数选择为'auto'，即根据不同模型，按照'predict_proba'>'decision_function'>'predict'的优先级进行参数选择。

`passthrough`：是否额外带入原始数据集特征进行元学习器训练，默认参数是`False`。

>   只带入一级学习器的预测结果训练元学习器。但当我们选择参数为True时，会拼凑一个由一级学习器输出结果和原始特征共同拼接而成的数据集，用于元学习器的训练。该操作本质上其实是一种特征增强方法，常常用于层级堆叠结构的模型训练过程，包括某些Boosting、深度森林的级联训练等。

但是，特征增强本身是一项较为复杂的技术，其实现过程非常灵活，可以在一个堆叠的模型结构的任意层增加任意任意特征，甚至是衍生特征，但目前来看，除了深度森林和Blending给出了明确的能提升效果的特征增强方法外，其他场景的特征增强方法效果都不确定，也就是说需要反复多次尝试，来找到可能能提升效果的特征增强方法。

在sklearn中，**Stacking评估器中训练的多组模型，每一组模型的超参数是固定的**，并不能像手动实现过程那样非常精细的去给每一组的每一个模型进行超参数优化。很明显，每一组模型共用一组超参数，还是会一定程度影响融合性能。

##### 17.4.2  特点

-   Stacking与Boosting

    如果说投票法&均值法和Bagging的集成过程一致，那么Stacking则和Boosting算法有着千丝万缕的联系。从技术衍化发展角度来说，Stacking是Boosting的前身，Stacking为Boosting集成范式提供了非常多的基础理论支撑，可以说，正是由于Stacking方法的发明，才有了后续Boosting算法的突破；而从算法原理角度来说，Stacking和Boosting本质也是类似，Stacking也可以看成是是堆叠多层学习器，并通过不断拟合误差来提升效果。只不过相比之下Stacking作为结合方法，其过程会相对简单，适用的模型也更加广泛，而Boosting则是严谨的集成范式，只能借助某些某型来构建某种集成算法。

-   一级学习器的同质或异质性

    在一级学习器不独立的情况下，经过长期实践发现，异质的一级学习器要明显好于同质的一级学习器。

-   Stacking过程中的“硬投票”或者“软投票”

    可以带入一级学习器的概率预测结果到元学习器中参与训练（类似于软投票的过程），我们还可以以一级学习器输出的类别预测结果作为特征，带入到元学习器中进行训练（类似于硬投票的过程）。不过需要注意的是，无论是Stacking的相关理论（Ting & Witten**[**1999**]**），还是长期的实践征明，带入概率预测结果进行元学习器训练，不进行任何优化的情况下，和Stacking“软投票”效果不分伯仲，而如果带入某些优化方法，则Stacking“软投票”效果会好很多。

-   过拟合

    无论是带入类别预测结果还是概率结果，元学习器最终都表现出了一定程度的过拟合。这当然也是Stacking“理论缺陷”必然导致的结果。为解决这个问题，截至目前，能适用于Stacking融合过程的只有**交叉训练**这一种方法。对于Stacking来说，同样是因为交叉训练能够非常好的做到信息隔离，从而能够一定程度提高元学习的泛化能力。

    <img src="https://cdn.jsdelivr.net/gh/louisyanglu/images/images/image-20220920160449348.png" alt="image-20220920160449348" style="zoom:50%;" />

##### 17.4.3  **Stacking优化**——一级学习器优化

>   Stacking模型融合和投票法&均值法类似，原理不难，但要获得一个稳定的优化效果却并没有那么简单。并且相比投票法&均值法，Stacking过程采用模型来学习一级评估器的输出结果和标签之间的关系，过拟合的倾向会更加明显。当然，关于Stacking容易过拟合的另一个理解的角度是：由于第一层学习器就已经提取了和标签更有关联度的特征，因此元学习器的学习难度偏弱，元学习器更容易过拟合。
>
>   1.   **一、二级学习器优化**：元学习器优化是每个Stacking过程都必须要进行的基础优化策略。
>   2.   **多层Stacking**：多层Stacking实际应用场景中出现的不多。
>   3.   **特征增强**：真正能够大幅提升Stacking融合效果的方法其实是特征增强。投票法&均值法在进行模型融合时，发挥效果的方式类似于Bagging，会更适用于“合而不同”的一组评估器的融合，即只要不同模型输出结果不同，就有可能融合得到一个更好的结果。但**Stacking**完全不同，根据Stacking的基本原理，该过程其实**更适用于一组能够有效学习不同特征的一级评估器的融合**。而如何能让一级学习器来各有所偏重的学习不同特征？特征增强肯定是最佳选择。例如我们完全可以给不同模型分配不同特征的衍生特征，从而让不同模型的学习重点各有不同，进而提升Stacking最终效果。此外，在元学习器中添加一些一级学习器中没有充分学习的衍生特征（例如特征重要性偏低的特征），也是能提升Stacking效果的。

1.   方法一：直接带入**原始参数评估器**进行交叉训练，即每一组模型内部都共用一组模型原始超参数。由于没有进行超参数优化，因此该种方式能够非常快速的训练一组模型，并可以借助sklearn中Stacking评估器来快速执行。

     最终Stacking的结果表现出了**较为明显的过拟合倾向**。除非是希望快速验证某些建模过程，否则一般不建议采用该种方式进行一级学习器的训练。

     ```python
     # 实例化一级评估器（默认超参数）
     logistic = LogisticRegression()  # 原始参数评估器
     tree = DecisionTreeClassifier()  # 原始参数评估器
     RF = RandomForestClassifier()    # 原始参数评估器
     
     # 实例化Stacking评估器
     estimators = [('lr', logistic), ('tree', tree), ('rf', RF)]
     clf = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())
     
     # 在训练集上训练
     clf.fit(X_train_OE, y_train)
     
     # 输出训练集和测试集评分
     clf.score(X_train_OE, y_train), clf.score(X_test_OE, y_test)

2.   方法二：先**在全部训练集上训练一级学习器，并进行超参数优化**。在确定每个一级学习器的超参数取值后，再进行交叉训练，交叉训练过程只训练每个一级学习器的参数而非超参数。尽管此时每一组模型内部超参数仍然是相同取值，但由于这组超参数毕竟是训练集上训练得到，因此方案二的Stacking结果的泛化能力要强于方案一。

     <img src="https://cdn.jsdelivr.net/gh/louisyanglu/images/images/image-20221008113027435.png" alt="image-20221008113027435" style="zoom:50%;" />

     ```python
     # 实例化一级评估器（超参数优化后的模型）
     logistic_search = load('./models/logistic_search.joblib') 
     tree_model = load('./models/tree_model.joblib') 
     RF_0 = load('./models/RF_0.joblib') 
     
     # 实例化Stacking评估器
     estimators = [('lr', logistic_search.best_estimator_), ('tree', tree_model), ('rf', RF_0)]
     clf = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())
     
     # 在训练集上训练
     clf.fit(X_train_OE, y_train)
     
     # 输出训练集和测试集评分
     clf.score(X_train_OE, y_train), clf.score(X_test_OE, y_test)
     ```

3.   方法三：在交叉训练过程中，**每个模型的每个组内训练过程都单独进行超参数搜索**，然后再进行Stacking融合。该策略交叉训练过程会耗费大量的时间，并且于需要先确定几折然后再进行一级学习器的超参数搜索和优化，因此会使得我们一般无法再根据融合结果灵活调整Stacking的CV超参数（调整一次就需要重新训练各组模型、重新进行超参数优化，成本巨大）。并且，由于sklearn较高的封装程度，使得我们无法简单调用sklearn中的评估器来完成该过程，整个过程都需要手动编写代码实现。但是，由于这种策略能够显著提升交叉训练过程中每个模型的泛化能力（更严格的信息隔离）和多样性（超参数多样性），因此在大多数情况下都是能显著提升最终融合结果的。具体参见17.3.3中的交叉训练方法。

     <img src="https://cdn.jsdelivr.net/gh/louisyanglu/images/images/image-20221008113103211.png" alt="image-20221008113103211" style="zoom:50%;" />

就第二、三种方法的选择来说，如果时间允许，并且追求效果上的极致，建议考虑第三种训练策略，而如果时间有限，第二种训练策略也不失为一种能够保证效果的方案，并且大多数的建模情况下，我们都是要围绕单模进行超参数优化的，因此方案二的实践成本是很低的。实际上，在多数情况下我们看到的Stacking的交叉训练，其实都是采用的方案二，而很多方案二的训练结果也是比较可观的。

```python
# 一级学习器超参数优化评估器
lr_hyper = lr_cascade(lr_params_space)
tree_hyper = tree_cascade(tree_params_space)
RF_hyper = RF_cascade(RF_params_space)

estimators = [('lr', lr_hyper), ('tree', tree_hyper), ('rf', RF_hyper)]
# 交叉训练后输出
train_oof, test_predict = train_cross(X_train_OE, y_train, X_test_OE, estimators=estimators)
```

##### 17.4.4  **Stacking优化**——元学习器优化

>   就整个Stacking过程模型训练优化的讨论来说，相比一级学习器的训练和优化，更关键、影响更大的，其实是元学习器的选择与优化。我们发现，Stacking元学习器的训练过程极容易过拟合，究其原因，其实是oof训练数据学习难度较低导致。因此，元学习器的模型选择并不是越复杂越好，我们得出了以下基本结论：
>
>   1.  简单模型要比复杂模型效果更好：例如逻辑回归、决策树等模型作为元学习器，就会比随机森林等更加复杂的模型建模效果更好；
>   2.  手动限制模型过拟合往往能得到一个更好的结果：例如将逻辑回归模型中正则化项设置为l1正则化、或者限制决策树模型的结构复杂度，往往能够获得一个更好的建模结果；
>   3.  元学习器的超参数优化是能够提升元学习器的泛化能力的，在大多数情况下我们应该尽可能的对其进行超参数优化；
>   4.  除了元学习器应该尽可能选择抗过拟合较高的简单模型外，有效的元学习器（经过超参数优化后的元学习器）+Bagging有时也能一定的提升元学习器学习能力。
>
>   基于上述结论，Stacking过程中元学习器的训练策略分为两步：
>
>   1.   **单模优化训练**：分类问题中，选取逻辑回归、决策树等模型作为元学习器的备选模型，对其进行训练和超参数优化；如果是回归问题，则基础分类器则更多考虑贝叶斯回归、Lasso和岭回归；
>   2.   **单模重复交叉训练**：RepeatedKFold，每一轮均可使用优化器得到最优子模型超参数；
>   3.   **优化后模型的Bagging过程**：以超参数优化后的逻辑回归模型或决策树模型等模型作为基础模型进行Bagging过程，并对Bagging评估器进行超参数优化。

<img src="https://cdn.jsdelivr.net/gh/louisyanglu/images/images/image-20221008155028693.png" alt="image-20221008155028693" style="zoom:50%;" />

```python
lr = logit_threshold()
tree = DecisionTreeClassifier()
final_model_l = [lr, tree]

lr_final_param = [{'thr': np.arange(0.1, 1.1, 0.1).tolist(), 'penalty': ['l1'], 'C': np.arange(0.1, 1.1, 0.1).tolist(), 'solver': ['saga']}, 
                  {'thr': np.arange(0.1, 1.1, 0.1).tolist(), 'penalty': ['l2'], 'C': np.arange(0.1, 1.1, 0.1).tolist(), 'solver': ['lbfgs', 'newton-cg', 'sag', 'saga']}]

tree_final_param = {'max_depth': np.arange(2, 16, 1).tolist(), 
                    'min_samples_split': np.arange(1, 5, 1).tolist(), 
                    'min_samples_leaf': np.arange(1, 4, 1).tolist(), 
                    'max_leaf_nodes':np.arange(6, 30, 1).tolist()}

param_space_l = [lr_final_param, tree_final_param]

best_res_final, best_test_predict_final = final_model_opt(final_model_l, param_space_l, train_oof, y_train, test_predict)
```

1.   **内部的超参数优化**

     ```python
     # 设置超参数空间
     parameter_space = {"cv": range(1, 11), 
                        "stack_method": ['predict_proba', 'decision_function', 'predict'],
                        "passthrough": [True, False]}
     ```

2.   **元学习器模型选择**

     ```python
     # 设置超参数空间
     clf1 = DecisionTreeClassifier()
     clf2 = LogisticRegression()
     clf3 = RandomForestClassifier()
     
     parameter_space = {"cv": range(1, 11), 
                        "stack_method": ['predict_proba', 'decision_function', 'predict'],
                        "final_estimator": [clf1, clf2, clf3],
                        "passthrough": [True, False]}
     ```

     其实在Stacking的元学习器的选择中，并不是越复杂的模型效果越好，而是视具体情况而定，一般来说，如果一级学习器比此独立性越强，则元学习器学习能力越强越好，但如果一级学习器彼此独立型较弱，则元学习器则需要具备一定的天然抗过拟合特性，才能够获得一个更好的输出结果。

     当前的一级学习器尽管是经过了交叉训练，但sklearn自带交叉训练过程并不能在超参数层面进行信息隔离，因此实际效力有限，外加一级学习器都是在相同的数据集上进行模型训练，因此独立性是有限的，此时就需要一个抗过拟合较好的元学习器。而对于逻辑回归模型来说，首先其学习能力有限，其次sklearn的逻辑回归模型自带正则化项，因此在默认参数设置情况下，就能一定程度规避过拟合问题，因此该模型也是当前情况下拟合效果最好的元学习器。

     在元学习器的选择和优化的过程中，早些年的实践，人们往往倾向于“无脑”选择逻辑回归（回归问题选择贝叶斯回归），而近些年，随着实践应用程度的加深，以及越来越多的特征增强的手段出现，以初级Bagging和Boosting结合逻辑回归（或决策树模型）作为基础学习器的元学习器训练策略也逐渐展露头角。

3.   **元学习器自动超参数搜索**

     首先我们需要明确的是，我们**无法在Stacking评估器层面对元学习器的超参数进行搜索**，Stacking评估器层面只能优化Stacking评估器自己的超参数。要解决这个问题，我们必须把元学习器和Stacking评估器串联起来，然后联动调参，即主要调整元学习器的超参数，然后根据Stacking输出作为反馈，来不断修正元学习器的最佳超参数取值。很明显，这个过程需要修改Stacking评估器。

     ```python
     class Stacking_tree_Cascade(BaseEstimator, ClassifierMixin, TransformerMixin):
         
         def __init__(self, estimators, cv=None, passthrough='auto', max_depth=None, min_samples_split=2, min_samples_leaf=1, max_leaf_nodes=None):
             self.estimators = estimators
             self.cv = cv
             self.passthrough = passthrough
             self.max_depth = max_depth
             self.min_samples_split = min_samples_split
             self.min_samples_leaf = min_samples_leaf
             self.max_leaf_nodes = max_leaf_nodes
             self.final_estimator = DecisionTreeClassifier(max_depth=self.max_depth, 
                                                           min_samples_split=self.min_samples_split, 
                                                           min_samples_leaf=self.min_samples_leaf, 
                                                           max_leaf_nodes=self.max_leaf_nodes)
             
         def fit(self, X, y):
             SC = StackingClassifier(estimators = self.estimators, 
                                     final_estimator = self.final_estimator,
                                     cv = self.cv, 
                                     passthrough = self.passthrough)
     
             SC.fit(X, y)
             self.clf = SC
             self.classes_ = pd.Series(y).unique()
             return self
     
         def predict_proba(self, X):
             res_proba = self.clf.predict_proba(X)
             return res_proba
     
         def predict(self, X):
             res = self.clf.predict(X)
             return res
     
         def score(self, X, y):
             acc = accuracy_score(self.predict(X), y)
             return acc
         
     # 超参数空间    
     parameter_space =  {'max_depth': np.arange(2, 7, 1).tolist(), 
                         'min_samples_split': np.arange(2, 7, 1).tolist(), 
                         'min_samples_leaf': np.arange(2, 7, 1).tolist(), 
                         'max_leaf_nodes':np.arange(4, 10, 1).tolist(), 
                         'cv':np.arange(2, 6, 1).tolist()}
     
     # 实例化Stacking评估器
     STC = Stacking_tree_Cascade(estimators)
     STC_grid = GridSearchCV(STC, parameter_space, n_jobs=15)
     
     # 模型训练
     STC_grid.fit(X_train_OE, y_train)
     ```

4.   元学习器重复交叉训练

     在单独的基础分类器作为元学习器和Bagging作为元学习器二者之间，还存在一种中间状态，即有些情况下我们并不会直接对基础分类器进行Bagging，而是借助sklearn中交叉验证过程，对其进行多次训练（一般是进行5-10次训练），然后取其平均预测结果作为最终预测结果，以实现类似Bagging但弱于Bagging的过程。该过程也被称为元学习器的交叉训练，只不过元学习器的交叉训练的目标并不是为了得到OOF数据集，而是借助交叉训练实现类似Boostrap的过程，来提升元学习器的泛化能力。

     ```python
     res = np.zeros(test_predict.shape[0])
     
     folds = RepeatedKFold(n_splits=5, n_repeats=2)
     
     for trn_idx, val_idx in folds.split(train_oof, y_train):
         lr = LogisticRegression(penalty='l1',solver='saga')
         lr.fit(train_oof.loc[trn_idx], y_train.loc[trn_idx])
         res += lr.predict_proba(test_predict)[:, 1] / 10

5.   有的时候我们也可以考虑在多轮计算的时候直接带入网格搜索评估器而不是确定超参数的模型评估器，以提升每次训练的模型效果。

     ```python
     res = np.zeros(test_predict.shape[0])
     
     folds = RepeatedKFold(n_splits=5, n_repeats=2, random_state=12)
     
     for trn_idx, val_idx in folds.split(train_oof, y_train):
         lfg = GridSearchCV(estimator = logit_threshold(max_iter=int(1e6)),
                            param_grid = logistic_param,
                            scoring='accuracy',
                            n_jobs = 15)
         lfg.fit(train_oof.loc[trn_idx], y_train.loc[trn_idx])
         res += lfg.predict_proba(test_predict)[:, 1] / 10
         
     accuracy_score((res >= 0.5) * 1, y_test)

##### 17.4.5  Stacking优化——自动模型融合

<img src="https://cdn.jsdelivr.net/gh/louisyanglu/images/images/image-20221009212324752.png" alt="image-20221009212324752" style="zoom:50%;" />

```python
lr_hyper = lr_cascade(lr_params_space, max_evals=50)
tree_hyper = tree_cascade(tree_params_space)
RF_hyper = RF_cascade(RF_params_space, max_evals=1000)

estimators = [('lr', lr_hyper), ('tree', tree_hyper), ('rf', RF_hyper)]

train_oof, test_predict = train_cross(X_train_OE, y_train, X_test_OE, estimators=estimators)

lr = logit_threshold()
tree = DecisionTreeClassifier()
final_model_l = [lr, tree]
best_res_final, best_test_predict_final = final_model_opt(final_model_l, param_space_l, train_oof, y_train, test_predict)
```

##### 17.4.6  **Stacking优化**——**多层Stacking**

Stacking的本质就是围绕上一层模型输出结果进行学习，借此提升最终预测效果。而在这个过程中，元学习器本身也是可以输出概率预测结果的，也就是说，某个元学习器之后还可以再堆叠一层元学习器。而如果两层的堆叠能够提升单模效果，那么双层的堆叠则能够进一步提升学习能力，从而进一步提升模型效果。当然，伴随着Stacking结构更加复杂，融合的过拟合风险也会更高。

<img src="https://cdn.jsdelivr.net/gh/louisyanglu/images/images/image-20220920225821282.png" alt="image-20220920225821282" style="zoom:50%;" />

```python
# 先实例化一级元学习器
tree_final = DecisionTreeClassifier()
RF_final = RandomForestClassifier()

# 然后构建两层元学习器之间的Stacking评估器
final_layer = StackingClassifier(estimators=[('tree_final', tree_final), ('RF_final', RF_final)], 
                                 final_estimator=LogisticRegression(penalty='l1', solver='saga'))

# 然后构建一级学习器
multi_layer = StackingClassifier(estimators=estimators, final_estimator=final_layer)
```

#### 17.5  Blending

##### 17.5.1  基础实现

Blending融合的基本过程和Stacking融合较为类似，都是两层模型的基本架构，即都是一级学习器进行训练，然后一级学习器的训练结果带入元学习器进行学习和训练。而和Stacking有所不同的是，为了避免一组数据重复训练导致的过拟合，Blending会在训练集中进一步划分训练集和留出集，一般比例为5：5到9：1不等。其中训练集用于一级学习器的训练，然后一级学习器围绕留出集进行预测，预测结果拼接成类似Stacking中的oof数据集，再将其带入元学习器进行模型训练。至此，即完成了两层模型的训练。

<img src="https://cdn.jsdelivr.net/gh/louisyanglu/images/images/image-20221008213642678-20230319231820790.png" alt="image-20221008213642678" style="zoom:50%;" />

需要注意的是，尽管拆分数据能够避免数据的重复训练，但由于此时两层模型带入训练的数据都有所减少，因此每一层模型本身的准确率会有所下降。二在每个独立的模型准确率有所下降的情况下，是否在融合后还能有更好的效果，其实并不确定。也就是说，Blending方法并不一定能获得一个比Stacking更好的融合结果，在大多数情况下，只能说Blending也是一种很有潜力的融合过程。若是追求融合效果极限，往往需要两种方法都进行尝试，然后择优输出。

对于训练集和留出集的划分比例，一般来说是在5:5到9:1的范围内划分。训练集划分比例过高（留出集比例较低）则会导致元学习器偏差较大，而如果训练集划分比例较小（留出集比例较大），则会严重影响一级学习器的学习效果，而一级学习器是保障模型融合效果的核心，因此训练集比例较小对模型融合的结果是致命的。当然，在若不确定最佳比例情况下，通用做法是按照8:2的比例进行划分。

```python
lr_hyper = lr_cascade(lr_params_space)
tree_hyper = tree_cascade(tree_params_space)
RF_hyper = RF_cascade(RF_params_space)

estimators = [('lr', lr_hyper), ('tree', tree_hyper), ('rf', RF_hyper)]

train_oof_blending, test_predict_blending = train_cross(X_train_OE, y_train, X_test_OE, estimators=estimators, blending=True)

best_res_final, best_test_predict_final = final_model_opt(final_model_l, 
                                                          param_space_l, 
                                                          train_oof_blending.iloc[:, :-1], 
                                                          train_oof_blending.iloc[:, -1], 
                                                          test_predict_blending)
```

##### 17.5.2  Blending优化

1.   方案一：搜索最佳留出集划分比例

     就整个Blending的融合过程来说，其实也有非常多和Stacking类似的优化方法。例如一级学习器也可以交叉训练，然后围绕留出集进行预测然后取均值，再带入元学习器预测；同时，一级学习器的交叉训练过程也可以配合超参数优化，元学习器的预测也可以采用此前定义的final_model_opt流程等等。很明显，这部分功能的都可以借鉴或改写此前Stacking部分定义的函数来实现。并且，由于新的重要变量的加入——留出集的划分比例，由此也将衍生出一系列的**围绕划分比例优化**的策略。

     不过，要将这个思路落地成具体可执行的方案却并不简单，其困难之处并不在于代码层面难以实现，而是算力不足条件约束。如何找到合适的留出集的划分比例，对机器学习这类后验的技术来说，免不了需要海量的尝试，典型的方案就是将留出集划分比例视作超参数，带入优化器来搜索出一个可靠的结果。但是，一个Blending的过程动辄需要耗费半小时乃至数个小时，“海量的尝试”对于个人用户来说基本是个不可能实现的过程，哪怕是用相对较少尝试来估计最佳划分比例的贝叶斯优化，对于50%-90%这个区间的搜索任务来说，至少也需要100-500次的计算。因此，若要实现最佳划分比例搜索策略，就需要尽可能缩短单次Blending融合所需要的时间，例如可以考虑一级学习器在交叉训练过程中不再进行单独模型的超参数优化，此举尽管会降低单次Blending融合精度，但通过缩短单次Blending融合时间，前期可以帮助最外层优化器快速搜索得到一个最佳划分比例，然后再确定比例之后再训练一个效果更好Blending融合。

     ```python
     split_space = {'test_size': hp.uniform('test_size', 0.1, 0.5)}
     
     def split_res(params, train=True):
         test_size = params['test_size']
         train_oof_blending, test_predict_blending = train_cross(X_train_OE, 
                                                                 y_train, 
                                                                 X_test_OE,
                                                                 estimators, 
                                                                 blending=True, 
                                                                 test_size=test_size)
         lr = LogisticRegression().fit(train_oof_blending.iloc[:, :-1], train_oof_blending.iloc[:, -1])
         if train == True:
             res = -lr.score(train_oof_blending.iloc[:, :-1], train_oof_blending.iloc[:, -1])
         else:
             res = (train_oof_blending, test_predict_blending)
         return res
     
     def param_split_res(max_evals):
         params_best = fmin(fn = split_res,
                            space = split_space,
                            algo = tpe.suggest,
                            max_evals = max_evals, 
                            rstate=np.random.RandomState(11))    
         
         return params_best
     
     best_split = param_split_res(100)
     
     # 定义一级学习器
     lr_hyper = lr_cascade(lr_params_space)
     tree_hyper = tree_cascade(tree_params_space)
     RF_hyper = RF_cascade(RF_params_space)
     
     estimators = [('lr', lr_hyper), ('tree', tree_hyper), ('rf', RF_hyper)]
     
     train_oof_blending, test_predict_blending = train_cross(X_train_OE, 
                                                             y_train, 
                                                             X_test_OE, 
                                                             estimators=estimators, 
                                                             test_size=best_split,  # 最佳切分比例
                                                             blending=True)
     # 定义元学习器搜索空间
     lr_final_param = [{'thr': np.arange(0.1, 1.1, 0.1).tolist(), 'penalty': ['l1'], 'C': np.arange(0.1, 1.1, 0.1).tolist(), 'solver': ['saga']}, 
                       {'thr': np.arange(0.1, 1.1, 0.1).tolist(), 'penalty': ['l2'], 'C': np.arange(0.1, 1.1, 0.1).tolist(), 'solver': ['lbfgs', 'newton-cg', 'sag', 'saga']}]
     
     tree_final_param = {'max_depth': np.arange(2, 16, 1).tolist(), 
                         'min_samples_split': np.arange(1, 5, 1).tolist(), 
                         'min_samples_leaf': np.arange(1, 4, 1).tolist(), 
                         'max_leaf_nodes':np.arange(6, 30, 1).tolist()}
     
     param_space_l = [lr_final_param, tree_final_param]
     # 定义元学习器列表
     lr = logit_threshold()
     tree = DecisionTreeClassifier()
     final_model_l = [lr, tree]
     # 执行元学习器训练搜索
     best_res_final, best_test_predict_final = final_model_opt(final_model_l, 
                                                               param_space_l, 
                                                               train_oof_blending.iloc[:, :-1], 
                                                               train_oof_blending.iloc[:, -1], 
                                                               test_predict_blending)

2.   方案二：多次划分，构建基于Blending结果的（加权）平均融合

     除此之外，根据长期模型融合的经验，其实早就帮助我们奠定了对待差异性结果的另外一种不同观点，那就是：不同留出集比例造成的结果差异性，或许本身也是通往更好结果的阶梯。例如，我们其实也可以通过设置多组不同比例留出集数据、来训练多个不同的Blending融合过程，然后让这些训练好的Blending融合流程对相同的测试集进行预测，并最终围绕这些预测结果来进行（加权）平均融合，如此，就相当于是执行了多层的模型融合。例如我们可以设置5：5-9：1五组不同留出集划分的数据集、训练5个Blending融合流程、再对其结果进行（加权）平均融合。

     <img src="https://cdn.jsdelivr.net/gh/louisyanglu/images/images/image-20221019190652003.png" alt="image-20221019190652003" style="zoom:50%;" />

     相比方案一，第二个方案其实会更加省时省力，并且往往也能得到一个还不错的结果。从理论上来说，强而不同是保障（加权）平均融合效果之根本，在上述流程中，Blending融合结果是“强”的保证，而不同留出集比例的划分，又将严重影响Blending融合结果，因此也保障了“不同”，这也就是该方案具备可执行性的理论基础。

     ```python
     # 一阶段Blending融合过程
     # test_size=0.1时
     # 一级学习器交叉训练
     lr_hyper = lr_cascade(lr_params_space)
     tree_hyper = tree_cascade(tree_params_space)
     RF_hyper = RF_cascade(RF_params_space)
     
     estimators = [('lr', lr_hyper), ('tree', tree_hyper), ('rf', RF_hyper)]
     
     train_oof_blending, test_predict_blending = train_cross(X_train_OE, 
                                                             y_train, 
                                                             X_test_OE, 
                                                             estimators=estimators, 
                                                             test_size=0.1,
                                                             blending=True)
     # 元学习器训练与优化
     lr = logit_threshold()
     tree = DecisionTreeClassifier()
     final_model_l = [lr, tree]
     
     best_res_final1, best_test_predict_final1 = final_model_opt(final_model_l, 
                                                                 param_space_l, 
                                                                 train_oof_blending.iloc[:, :-1], 
                                                                 train_oof_blending.iloc[:, -1], 
                                                                 test_predict_blending)
     Blending_res = pd.DataFrame({'res1':best_test_predict_final1, 
                                  'res2':best_test_predict_final2, 
                                  'res3':best_test_predict_final3, 
                                  'res4':best_test_predict_final4, 
                                  'res5':best_test_predict_final5})
     # 二阶段平均融合&手动设置权重的加权融合
     pd.Series([best_res_final1, 
                best_res_final2, 
                best_res_final3, 
                best_res_final4, 
                best_res_final5], index=['best_res_final1', 
                                         'best_res_final2', 
                                         'best_res_final3', 
                                         'best_res_final4', 
                                         'best_res_final5'])
     Blending_res1 = ((Blending_res['res1'] * 4) + 
                      (Blending_res['res2'] * 5) + 
                      (Blending_res['res3'] * 2) + 
                      (Blending_res['res4'] * 3) + 
                      (Blending_res['res5'] * 1)) / 15
     ```

3.   方案三：此外，Blending融合也有属于自己的优势优化策略——**特征增强**策略，即在元学习器中加入留出集特征。我们曾尝试在Stacking过程进行类似的特征增强操作，但结果是放大了过拟合倾向。而相比之下，Blending融合过程中，由于一级学习器并没有直接学习留出集特征，因此这部分数据对于元学习器来说还是会有较大的学习价值的，甚至Still等人在2009年的Feature-weighted linear stacking. arXiv preprint arXiv:0911.0460.论文中表示，将留出集的特征和一级学习器在留出集上的预测结果进行多项式特征衍生，能有效提升元学习器的泛化能力。

#### 17.6  回归问题的模型融合

无论是分类问题还是回归问题，模型融合的方法大类和基本融合思想并无本质区别，并且都一定程度被过拟合问题所困扰。回归问题与分类问题有以下区别：

1.   首先是硬投票方法簇只能处理分类问题，包括硬投票、绝对多数票和排序融合法等方法，只适用于分类问题；
2.   其次，对于Stacking和Blending来说，回归问题的元学习器选取主要以**贝叶斯回归**为主，有时也会考虑**岭回归**和**LASSO**。

对于分类问题，融合一个更好的结果其实并不容易，往往会适得其反，而只有广泛尝试优化策略、并因地制宜进行调整，才能够获得一个更好的融合结果。但对于回归问题，可能并不存在这样的困扰。大多数回归问题在套用一个基础融合流程时就能获得一定程度的效果提升，并且很多优化方法也能起到立竿见影的效果。因此对于实践环节来说，就通过融合来提升效果这一点而言，回归问题要比分类问题更容易。

究其原因，其实是因为回归问题的数值预测给了第二阶段学习更大的学习空间。无论是平均法还是学习结合器法，由于数据的重复学习，过拟合问题始终是模型融合的“头号大敌”。且尽管分类问题大多数情况是围绕概率值进行连续性数值的预测和计算，但最终输出的预测结果仍然是离散变量，融合过程中更加丰富的数值多样性表现不一定能直接体现在最终的预测结果上。而回归问题则自始自终都是围绕连续性数值进行预测，哪怕融合结果有千分之一的数值提升，都能提升最终结果评估指标。此外，就建模难度而言，回归问题的建模难度往往高于分类问题，而更高的建模难度也给复杂的融合流程提供了更大的学习空间，适得一些在分类问题上容易过拟合的流程、在回归问题上反而能起到提高泛化能力的效果。

当然，效果更易提升并不代表回归问题整体模型融合执行流程变得更简单。实际上，对于回归问题来说，简单流程能提升效果、复杂流程更有可能提升更大。因此，面对回归问题，我们也需要反复多次尝试，训练构建多组模型融合结果来则优输出，并且如果是在测试集标签未知的情况下，也同样是需要多次线上提交来测试最终融合效果的。这一点并不会随着融合出效果的难易而发生变化。

##### 17.6.1  一级学习器集成学习超参优化

在大多数实际情况下，对于简单数据集，**极端随机树**往往会表现出非常强的预测能力，而对于复杂数据集，则整体性能会弱于随机森林，这也就是所谓的方差较小但偏差较大的模型的具体性能体现。也正是由于该特性，使得极端随机树具备了作为基础学习器进一步参与“集成”的可能性，在模型融合过程中该模型是非常值得尝试的一级学习器，而深度森林算法，则更是将其视作唯一的基础学习器。

```python
from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, GradientBoostingRegressor
from sklearn.metrics import mean_squared_error
# 1.训练单模
# 相比分类问题，回归问题中树的复杂度往往要高得多，因此回归随机森林中对于单独每个树的剪枝参数往往需要设置一个较大的搜索空间，这其实就相当于给单独基础分类器的复杂度设置了较大的容忍空间。

# 超参数搜索空间
RF_space = {'min_samples_leaf': hp.quniform('min_samples_leaf', 1, 20, 1), 
            'min_samples_split': hp.quniform('min_samples_split', 2, 20, 1), 
            'max_depth': hp.quniform('max_depth', 2, 50, 1), 
            'max_leaf_nodes': hp.quniform('max_leaf_nodes', 50, 300, 1), 
            'n_estimators': hp.quniform('n_estimators', 50, 500, 1), 
            'max_samples': hp.uniform('max_samples', 0.2, 0.8)}

def RF_param_objective(params, train=True):
    # 超参数读取
    min_samples_leaf = int(params['min_samples_leaf'])
    min_samples_split = int(params['min_samples_split'])
    max_depth = int(params['max_depth'])
    max_leaf_nodes = int(params['max_leaf_nodes'])
    n_estimators = int(params['n_estimators'])
    max_samples = params['max_samples']

    # 模型创建
    reg_RF = RandomForestRegressor(min_samples_leaf = min_samples_leaf, 
                                   min_samples_split = min_samples_split,
                                   max_depth = max_depth, 
                                   max_leaf_nodes = max_leaf_nodes, 
                                   n_estimators = n_estimators, 
                                   max_samples = max_samples)

    if train == True:
        res = -cross_val_score(reg_RF, X_train, y_train, scoring='neg_mean_squared_error', n_jobs=15).mean()
    else:
        res = reg_RF.fit(X_train, y_train)        
    return res

def RF_param_search(max_evals=500):
    params_best = fmin(RF_param_objective,
                       space = RF_space,
                       algo = tpe.suggest,
                       max_evals = max_evals)
    return params_best

RF_best_param = RF_param_search()
```

##### 17.6.2  大范围超参数搜索优化

经过超优化后的模型仍然存在一定过拟合问题，也是一个非常值得深度探讨的问题。我们知道此时模型参与搜索的部分超参数的取值是已经确定了的，但其他还有一些没有搜索的超参数，其默认取值是按照模型复杂度最高的标准进行的设置，因此这会导致模型在训练参数的过程仍然还是具备一定的过拟合风险。不过该问题并不会很大程度影响模型搜索效果——因为交叉验证能很好的得到一组和测试集较为接近的评分。因此，在以交叉验证结果作为模型泛化能力评估标准的时候，这种过拟合并不会影响超参数搜索优化过程；这种因为带入搜索的超参数不完全所导致的过拟合风险，主要体现在回归类模型的超参数搜索中，分类问题往往没有这种问题。并且相对简单的回归数据集问题尤其明显。

基于此，后续应该如何进行优化呢？

首先也是最容易想到的策略就是增加搜索的超参数，以此降低模型过拟合风险，并且同时增加各超参数搜索范围，以此提升模型泛化能力。这当然是理论上的最优方案，但实际执行难度较大，最核心的困难就在于算力不够。目前的数据集在当前搜索空间范围内迭代500次需要1小时时间，而如果增加超参数数量、并增加搜索空间，超参数优化计算所需时间将呈指数级上升。此外，对于部分模型的部分超参数甚至根本无法带入进行搜索，例如回归随机森林中的criterion参数，根据参数说明可知，当criterion取值为absolute_error时将极大程度影响计算效率、计算时间将大幅提升。在算力限制情况下，我们其实根本无法带入全参数并在超大空间内进行搜索，必须要舍弃部分参数，进而兼顾计算效率和预测结果。

```python 
max_features_range = ["auto", "sqrt", "log2", None] + np.arange(0.1, 1., 0.1).tolist()
# 超参数空间
RF_space = {'max_features': hp.choice('max_features', max_features_range),
            'n_estimators': hp.quniform('n_estimators', 200, 800, 1), 
            'max_samples': hp.uniform('max_samples', 0.2, 1),
            'min_samples_leaf': hp.quniform('min_samples_leaf', 1, 50, 1), 
            'min_samples_split': hp.quniform('min_samples_split', 2, 50, 1), 
            'max_depth': hp.quniform('max_depth', 20, 120, 1), 
            'max_leaf_nodes': hp.quniform('max_leaf_nodes', 200, 600, 1)}
# 目标函数
def RF_param_objective(params, train=True):    
    # 超参数读取
    min_samples_leaf = int(params['min_samples_leaf'])
    min_samples_split = int(params['min_samples_split'])
    max_depth = int(params['max_depth'])
    max_leaf_nodes = int(params['max_leaf_nodes'])
    n_estimators = int(params['n_estimators'])
    max_samples = params['max_samples']

    if train == True:
        max_features = params['max_features']
        
    else:
        max_features = max_features_range[params['max_features']]
        
    # 模型创建
    reg_RF = RandomForestRegressor(min_samples_leaf = min_samples_leaf, 
                                   min_samples_split = min_samples_split,
                                   max_depth = max_depth, 
                                   max_leaf_nodes = max_leaf_nodes, 
                                   n_estimators = n_estimators, 
                                   max_samples = max_samples,
                                   max_features = max_features,
                                   random_state=12)

    if train == True:
        res = -cross_val_score(reg_RF, X_train, y_train, scoring='neg_mean_squared_error', n_jobs=15).mean()
    else:
        res = reg_RF.fit(X_train, y_train)
    return res
# 参数搜索
def RF_param_search(max_evals=500):
    params_best = fmin(RF_param_objective,
                       space = RF_space,
                       algo = tpe.suggest,
                       max_evals = max_evals)
    return params_best

RF_best_param = RF_param_search(1000)

RF_reg_A = RF_param_objective(RF_best_param, train=False)
mean_squared_error(RF_reg_A.predict(X_train), y_train), mean_squared_error(RF_reg_A.predict(X_test), y_test)
```

真实企业级应用场景中（包括很多竞赛中）数据情况非常复杂，考虑到可能还需要进行特征衍生、以及融合环节还需要多次训练模型，计算时间将是无法承担的。因此，必须要考虑一种更加高效的模型训练流程。

##### 17.6.3  更高效的搜索流程

**直接舍弃基础学习器的超参数搜索**（比如单颗树相关的参数：max_depth、max_leaf_nodes等），**只搜索集成相关超参数**。这里需要注意的是，舍弃基础学习器的超参数搜索其实就等于带入基础学习器的默认超参数组，而基础学习器的默认超参数组是不会剪枝的、即默认执行最高模型复杂度的模型训练，每个基础学习器实际上是容易过拟合的，但是考虑到回归问题本身就要求更复杂的模型进行训练，且已被上述搜索过程验证，因此基础学习器选取默认超参数并不会对预测结果有较大的影响。并且除了基础学习器的超参数外、对模型泛化能力影响更大的继承超参数仍然是朝着泛化能力更强的方向进行搜索，外加舍弃了这部分超参数搜索，整体超参数搜索的速度将变得更快，这将有助于在更短的时间内快速搜索出一组更好的结果。

当我们舍弃了更多的基础学习器的超参数的时候，最终训练集的预测结果将会有更大的过拟合风险，因此在方案二的超参数搜索时，仍然需要坚持使用交叉验证结果作为模型泛化能力的评分标准。

```python
RF_space = {'max_features': hp.choice('max_features', max_features_range),
            'n_estimators': hp.quniform('n_estimators', 20, 700, 1), 
            'max_samples': hp.uniform('max_samples', 0.2, 1)}

def RF_param_objective(params, train=True):
    
    # 超参数读取
    n_estimators = int(params['n_estimators'])
    max_samples = params['max_samples']

    if train == True:
        max_features = params['max_features']
        
    else:
        max_features = max_features_range[params['max_features']]
        
    # 模型创建
    reg_RF = RandomForestRegressor(n_estimators = n_estimators, 
                                   max_samples = max_samples, 
                                   max_features = max_features,
                                   random_state=12)
    if train == True:
        res = -cross_val_score(reg_RF, X_train, y_train, scoring='neg_mean_squared_error', n_jobs=15).mean()
    else:
        res = reg_RF.fit(X_train, y_train)        
    return res

def RF_param_search(max_evals=500):
    params_best = fmin(RF_param_objective,
                       space = RF_space,
                       algo = tpe.suggest,
                       max_evals = max_evals)
    return params_best

RF_best_param = RF_param_search(50)

RF_reg_B1 = RF_param_objective(RF_best_param, train=False)
mean_squared_error(RF_reg_B1.predict(X_train), y_train), mean_squared_error(RF_reg_B1.predict(X_test), y_test)
```

首先需要介绍一个模型超参数优化过程中的基本矛盾，那就是手段和目的不匹配的问题。即模型优化的最终目的是为了让模型提升泛化能力，即尽可能学习全局规律而抛弃局部规律，但所采用的手段——超参数搜索其实是一种限制（或者增加）模型学习能力的策略，这二者并不完全匹配。无论是局部规律还是全局规律，都有难的规律和简单的规律。而超参数搜索无论是提高模型学习能力还是降低模型学习能力，都必然会同时学习到或者损失掉一些全局规律和局部规律。因此，并非限制模型学习能力，损失掉的、没学到的规律就一定是局部规律，就一定有助于模型解决过拟合问题；反之也一样，并不是提升模型学习能力，就一定能学到全局规律，有可能也会学到局部规律，从而降低模型在测试集上的评分。这点在实践过程中屡见不鲜。相信大家在实践过程中也遇到过不少类似的情况。

但超参数搜索为何还是有效的呢？因为超参数搜索能够在通过调配模型学习能力，最终让模型获得一个最佳的学习能力——能最大程度同时捕获适用于训练集和测试集的规律，因而提升模型的泛化能力，也就是提升模型对测试集的预测能力。但是，从理论上来说，要做到这点必须要对模型进行全超参数的高精度搜索才行。但是全参数大范围高精度搜索其实是非常费时费力的，稍有不慎就可能得不到这个最佳的模型，反而可能会得到一个学习能力不足、泛化能力不够的模型。

那要如何改善这点呢？当然，与其说是改善，不如说是算力不够时“两权相害取其轻”的结果——相比通过限制搜索空间来提高搜索效率，有的时候适度的放开模型的学习能力，哪怕让模型学到了一些局部规律，只要不严重影响测试集预测结果、不影响模型整体泛化能力，其实也没有太大问题。对于高效搜索流程（方案B）来说，由于不对基础模型的超参数进行限制，因此其学习能力是非常强的，但由于我们对其集成超参数进行了搜索和优化，因此仍然一定程度上对其学习能力进行了调整，在有限的调整空间下，我们无法获得类似大范围超参数搜索优化（方案A）获得的严谨结果，但仍然保证了其能够有效学习全局规律，因此最终预测集上结果有所提升。但由于还有很多不受控的超参数在影响模型的学习能力，因此模型在训练集的训练过程中也学习了非常多局部规律，导致其但从训练集上来看过拟合风险偏高。但就模型泛化能力、也就是对新数据的预测能力来说（交叉验证结果），方案A和方案B并无本质区别。

既然方案A和方案B其实都是超参数不完全的搜索流程，并且二者表现出了不同的泛化能力，那要如何才能确定搜索哪几个超参数才能达到更好效果呢？

首先我们需要确定一点的是，从理论层面来说，超参数搜索最有效的方法一定是全参数大范围高精度搜索，如此得到的模型一定是能够最大程度学习全局规律的模型。但遗憾的是，在实际执行过程中，尤其是回归类问题，受限于当前算力条件，该方案几乎没有可执行性。因此需要考虑挑选出部分超参数进行搜索，而只要是挑选部分超参数出来进行搜索，其实就已经是不满足理论最优解的情况了，而具体要选哪些超参数出来搜索，也不存在理论最优解。因此，关于超参数的选取，其实也是需要多次尝试并且不断积累经验的。

总的来说，根据长期实践经验总结，集成相关超参数肯定需要进行搜索的，例如随机森林中的max_features、n_estimators、max_samples等。此外对于基础学习器的超参数来说，可以优先尝试max_depth、max_leaf_nodes这两个参数，该参数对决策树模型剪枝影响巨大。当然，是否要加入max_depth、max_leaf_nodes，甚至是其他基础分类器超参数进行搜索，可以通过少量次数迭代测试效果再决定。

其实不仅是超参数搜索，在机器学习的很多技术实践不是对理论完美复刻，而是基于实际情况，在理论的基础上、结合实际经验，寻找更优的实现方法。例如此前我们一直强调过拟合会威胁模型泛化能力，但这里发现适度放宽模型学习能力，容忍一定过拟合倾向，在借助交叉验证平均分为判别条件情况下，反而能提升模型的泛化能力，因此无比要很多时候活学活用，才能起到更好的效果。在实践过程中我们不是一定追求一个完美的流程，而是追求一个更高效更准确的最终结果。正所谓黑猫白猫、抓住老鼠就是好猫。

##### 17.6.4  高效搜索流程的优化

方法一：在搜索得到一组最优超参数后，通过交叉训练的方式同时输出多组测试集的预测结果，然后求均值作为最终的预测结果；

```python
RF_test_predict = 0
RF_train_predict = 0

kf = KFold(n_splits=5, shuffle=True, random_state=12)

for train_part_index, eval_index in kf.split(X_train, y_train):
    # 在训练集上训练
    X_train_part = X_train.loc[train_part_index]
    y_train_part = y_train[train_part_index]
    RF_reg_B1.fit(X_train_part, y_train_part)  # 超参优化后的模型
    RF_train_predict += RF_reg_B1.predict(X_train) / 5
    RF_test_predict += RF_reg_B1.predict(X_test) / 5
mean_squared_error(RF_train_predict, y_train)
mean_squared_error(RF_test_predict, y_test)
```

方法二：在超参数搜索过程中，不再使用验证集的平均得分作为搜索依据，换成验证集拼接而成的预测数据和标签之间的MSE作为搜索依据。

```python
RF_space = {'max_features': hp.choice('max_features', max_features_range),
            'n_estimators': hp.quniform('n_estimators', 20, 700, 1), 
            'max_samples': hp.uniform('max_samples', 0.2, 1)}

def RF_param_objective(params, train=True):    
    # 超参数读取
    n_estimators = int(params['n_estimators'])
    max_samples = params['max_samples']

    if train == True:
        max_features = params['max_features']
        
    else:
        max_features = max_features_range[params['max_features']]
        
    # 模型创建
    reg_RF = RandomForestRegressor(n_estimators = n_estimators, 
                                   max_samples = max_samples, 
                                   max_features = max_features,
                                   random_state=12, 
                                   n_jobs=15)

    oof_series = pd.Series(np.empty(X_train.shape[0]))
    
    if train == True:
        kf = KFold(n_splits=5, shuffle=True, random_state=12)
        for train_part_index, eval_index in kf.split(X_train, y_train):
            # 在训练集上训练
            X_train_part = X_train.loc[train_part_index]
            y_train_part = y_train[train_part_index]
            reg_RF.fit(X_train_part, y_train_part)
            X_eval_part = X_train.loc[eval_index]
            # 将验证集上预测结果拼接入oof数据集
            oof_series.loc[eval_index] = reg_RF.predict(X_eval_part)
    
        res = mean_squared_error(oof_series, y_train)
    
    else:
        res = reg_RF.fit(X_train, y_train)        
    return res

def RF_param_search(max_evals=500):
    params_best = fmin(RF_param_objective,
                       space = RF_space,
                       algo = tpe.suggest,
                       max_evals = max_evals)
    return params_best

RF_best_param = RF_param_search(50)
RF_reg_B2 = RF_param_objective(RF_best_param, train=False)
mean_squared_error(RF_reg_B2.predict(X_train), y_train), mean_squared_error(RF_reg_B2.predict(X_test), y_test)
```

##### 17.6.5  模型融合——基础结合器法

1.   **平均法**

     平均融合法，该方法的实践过程非常简单，只需要对三个模型的输出结果进行均值计算即可

     ```python
     from sklearn.ensemble import VotingRegressor

2.   **基于经验的加权平均法**

     按模型效果，可以给这三个模型分别分配3、2、1的权重进行融合。

3.   **基于TPE搜索的加权平均法**

     在此前的分类问题融合过程中，基于TPE权重搜索的加权平均融合在实际执行过程中容易出现过拟合问题，也就是会出现训练集上得分上升、但测试集上得分反而下降的情况。为了解决这个问题，我们提出了三种解决方案：

     -   其一是用交叉验证的融合结果代替原始融合结果，也就是借助更有可信度的验证集的平均得分代替训练集上得分，进行权重的筛选；

         ```python
         # 定义超参数空间
         params_space = {'weight1': hp.uniform("weight1",0,1),
                         'weight2': hp.uniform("weight2",0,1),
                         'weight3': hp.uniform("weight3",0,1)}
         # 定义目标函数
         def hyperopt_objective_weight(params, train=True):
             weight1 = params['weight1']
             weight2 = params['weight2']
             weight3 = params['weight3']
             
             weights = [weight1, weight2, weight3]
             
             VR_weight_search = VotingRegressor(estimators, weights=weights)
         
             if train == True:
                 val_score = cross_val_score(VR_weight_search, 
                                             X_train, 
                                             y_train, 
                                             scoring='neg_mean_squared_error', 
                                             n_jobs=15,
                                             cv=5).mean()
                 res = -val_score
             else:
                 VR_weight_search = VotingRegressor(estimators, 
                                                    weights=weights).fit(X_train, y_train)
                 res = VR_weight_search
             return res
         # 定义优化函数
         def param_hyperopt_weight(max_evals):
             params_best = fmin(fn = hyperopt_objective_weight,
                                space = params_space,
                                algo = tpe.suggest,
                                max_evals = max_evals)    
             return params_best
         
         params_best = param_hyperopt_weight(50)
         VR = hyperopt_objective_weight(params_best, train=False)
         mean_squared_error(VR.predict(X_train), y_train), mean_squared_error(VR.predict(X_test), y_test)

     -   其二则是借助经验法得到的权重组合，对搜索空间进行裁剪，此举不仅能加快迭代速度，更能帮助搜索过程跳出“伪”最优解陷阱；

         ```python
         # 定义超参数空间
         params_space = {'weight1': hp.uniform("weight1",0,0.05),
                         'weight2': hp.uniform("weight2",0.05,0.1),
                         'weight3': hp.uniform("weight3",0.5,1)}
         params_best = param_hyperopt_weight(50)
         VR = hyperopt_objective_weight(params_best, train=False)
         mean_squared_error(VR.predict(X_train), y_train), mean_squared_error(VR.predict(X_test), y_test)

     -   其三则是在模型训练阶段就进行交叉训练，然后用验证集拼接而成的训练集（train_oof）代替原始训练集，并以train_oof的融合结果作为超参数筛选依据，进行权重筛选，此时由于train_oof数据都是间接得出，因此该数据集上的融合结果可信度更高，最终帮助搜索过程提高权重结果的泛化能力。

         ```python
         train_oof, test_predict = train_cross(X_train, y_train, X_test, estimators, regress=True)
         # 定义超参数空间
         params_space = {'weight1': hp.uniform("weight1",0,1),
                         'weight2': hp.uniform("weight2",0,1),
                         'weight3': hp.uniform("weight3",0,1)}
         # 定义目标函数
         def hyperopt_objective_weight(params, train=True):
             weight1 = params['weight1']
             weight2 = params['weight2']
             weight3 = params['weight3']
             
             weights = np.array([weight1, weight2, weight3])
             
             if train == True:
                 res_train = (train_oof.iloc[:, :3] * weights).sum(1) / weights.sum()
                 MSE_res = mean_squared_error(res_train, y_train)
                 res = MSE_res
             else:
                 res = weights
             return res
         # 定义优化函数
         def param_hyperopt_weight(max_evals):
             params_best = fmin(fn = hyperopt_objective_weight,
                                space = params_space,
                                algo = tpe.suggest,
                                max_evals = max_evals)    
             return params_best
         params_best = param_hyperopt_weight(200)
         best_weights = hyperopt_objective_weight(params_best, train=False)
         res_test = (test_predict.iloc[:, :3] * best_weights).sum(1) / best_weights.sum()
         MSE_res = mean_squared_error(res_test, y_test)
         ```

##### 17.6.6  模型融合——学习结合器法

无论是回归问题还是分类问题、无论是Stacking还是Blending，元学习器的选择都是类似的——为避免过拟合问题，元学习器往往需要选择模型结构简单、预测效力一般的模型。之前的分类问题讲解中，我们重点推荐逻辑回归模型或者结构非常简单的树模型作为元学习器，而在回归问题Stacking融合中，则往往使用线性回归模型或者贝叶斯回归作为元学习器。而如果是更复杂的树模型或者是集成算法，作为元学习器则会不可避免的出现过拟合的问题，并且和分类问题类似，这种过拟合问题是无法通过超参数优化来解决的。

sklearn中的贝叶斯回归是提供了四个超参数选项的，分别是alpha_1、alpha_2、lambda_1、lambda_2，默认超参数取值都是1e-6。而由于Python本身计算精度的问题，建模过程中这四个超参数对模型的影响非常不可控，甚至无法通过超参数优化寻找到最有超参数组。因此，大多数时候，当我们采用线性回归和贝叶斯回归作为元学习器进行Stacking时，并不需要要进行任何形式的超参数调整（线性回归是因为没有超参数、而贝叶斯回归则是因为超参数优化效果不大）。

其实贝叶斯回归模型超参数优化无效的原因，是在于对于同一个数据集，不同的超参数取值有可能会导向相同的训练集结果，从而让超参数优化函数失去判断的标准，哪怕这些不同取值的超参数会对测试集产生不同的影响，但由于训练集上表现相同，因此优化函数是无法判断哪组超参数最优的，因此优化效果很不稳定。这个是贝叶斯回归存在的问题，但贝叶斯回归也有自己的优势，相比线性回归，贝叶斯回归不会因为共线性问题导致模型效果下降，因此整体表现比线性回归更加稳健。

1.   **Stacking**

     实际上，基于交叉训练的加权平均融合和以线性方程作为元学习器的Stacking融合本质上非常类似，都是利用train_oof的特征乘以某种系数作为最终预测结果。只不过线性回归和贝叶斯回归允许在加权求和后增加一个常数项。

     <img src="https://cdn.jsdelivr.net/gh/louisyanglu/images/images/image-20221103152633511.png" alt="image-20221103152633511" style="zoom:40%;" />

     正是因为很多时候线性回归和贝叶斯回归作为元学习器，并不能和加权平均融合形成算法结构层面的差异，并且由于线性回归和贝叶斯回归没有超参数优化的必要，因此回归问题的Stacking融合的关键，就在于能否借助Bagging对其进行元学习器的优化。

     ```python
     # 设置超参数空间
     parameter_space = {
         "n_estimators": range(10, 21), 
         "max_samples": np.arange(0.1, 1.1, 0.1).tolist()}
     
     # 实例化模型与评估器
     bagging_final = BaggingRegressor(base_estimator=BayesianRidge(), random_state=1)
     
     BG = GridSearchCV(bagging_final, parameter_space, n_jobs=15)
     
     # 模型训练
     BG.fit(train_oof.iloc[:, :3], y_train)

2.   **Blending**

     <img src="https://cdn.jsdelivr.net/gh/louisyanglu/images/images/Blending%E6%A8%A1%E5%9E%8B%E8%9E%8D%E5%90%88%E6%B5%81%E7%A8%8B%20(2).jpeg" alt="Blending模型融合流程 (2)" style="zoom:50%;" />

